[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "데이터 분석 방법론",
    "section": "",
    "text": "Preface\n이 사이트는 데이터 분석 방법론 강의 온라인 강의 노트입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "notes/intro.html#학습-내용",
    "href": "notes/intro.html#학습-내용",
    "title": "1  서론",
    "section": "1.1 학습 내용",
    "text": "1.1 학습 내용\n이 교과서는 다양한 형태를 가진 자료를 분석하는 통계적 방법들의 이론과 응용을 살펴보기 위한 것입니다.\n이 교과서에서는 다음과 같은 주제를 다룰 것입니다.\n\n교차표에서의 통계적 분석방법\n범주형 자료와 발생횟수를 따르는 자료에 대한 모형 구축과 추론\n일반화 선형모형에서의 추론\n반복측정자료와 군집자료에 대한 분석 방법",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#r-언어",
    "href": "notes/intro.html#r-언어",
    "title": "1  서론",
    "section": "1.2 R 언어",
    "text": "1.2 R 언어\n이 교과서에서는 통계 방법들의 실습을 위하여 R 프로그램을 사용합니다. R 프로그램이 익숙하지 않는 학생들은 R 프로그램에 대한 기초적인 내용을 먼저 숙지하느 것을 추천합니다. 참고로 저자의 R 기초 강의 사이트에서 R 프로그램에 대한 기초적인 내용을 배울 수 있습니다.\n이 강의에서 사용하는 R 패키지는 다음과 같다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#참고도서",
    "href": "notes/intro.html#참고도서",
    "title": "1  서론",
    "section": "1.3 참고도서",
    "text": "1.3 참고도서\n\nFaraway (2016)\nAgresti (2007)\nAgresti (2012)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#유용한-사이트",
    "href": "notes/intro.html#유용한-사이트",
    "title": "1  서론",
    "section": "1.4 유용한 사이트",
    "text": "1.4 유용한 사이트\n\nData sets for “An Introduction to Categorical Data Analysis”\nR codes for “An Introduction to Categorical Data Analysis”\n\n\n\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data Analysis. John Wiley & Sons, Ltd.\n\n\n———. 2012. Categorical data analysis. Vol 792. John Wiley & Sons.\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/association.html#필요한-패키지",
    "href": "notes/association.html#필요한-패키지",
    "title": "2  연관성의 측도",
    "section": "2.1 필요한 패키지",
    "text": "2.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#이항변수",
    "href": "notes/association.html#이항변수",
    "title": "2  연관성의 측도",
    "section": "2.2 이항변수",
    "text": "2.2 이항변수\n통계학에서 관측값은 값이 가지는 특성에 따라서 연속형 변수(continuous variable)과 범주형 변수(categorical variable)로 나눈다.\n결과가 2개인 범주형 변수인 이항변수(binary variable)는 매우 중요한 역할을 한다. 그 이유는 두 개의 선택 중에서 하나를 선택해 야할 의사결정이 실제로 대부분을 차지하고 있기 때문이다.\n예를 들어서 코로나 19에 감염된 환자가 병원에서 치료를 받고 있다고 가정해보자. 환자는 병원에서 여러 가지 검사를 수행하면서 다양한 자료를 수집한다. 예를 들어 환자는 수시로 체온을 재고 항체검사, 혈액검사 등을 받을 것이다. 다양한 검사 등에서 나온 자료는 연속형 또는 범주형 자료로 구성될 것이다.\n하지만 의사가 가장 중요하게 결정할 사항은 환자가 계속 치료를 필요로 하는지 아닌지 결정해야 한다. 즉, 여러 가지 검사를 고려하여 최종적으로 의사는 환자가 더 치료가 필요한지 아닌 지를 결정해야 한다. 의사의 결정을 이항변수 \\(Y\\)로 다음과 같이 표현할 수 있다..\n\\[\nY =\n\\begin{cases}\n1 & \\text{ if patient still needs treatment} \\\\\n0 & \\text{ if patient dose not need treatment any more (GO HOME!)}\n\\end{cases}\n\\]\n실제 임상에서는 이러한 두 개의 가능한 선택 중에 하나를 선택하는 결정이 빈번하게 일어나며 이러한 결정은 대부분 중요한 임상적 결정이다. 예를 들어 다음과 같은 의사결정들은 이항변수로 표현할 수 있다.\n\n환자는 약을 복용해야 하는가?\n환자는 입원을 해야 하는가?\n환자는 중환자실로 가야 하는가?\n환자는 퇴원해도 되는가?\n\n또는 환자의 상태(outcome)가 이항변수로 표현될 수 있다.\n\n환자는 치료가 되었는가?\n환자가 사망하였는가?\n\n이제 코로나 19 치료제의 효과를 알아보기 위한 임상실험을 수행하는 경우를 생각해보자. 통상적으로 임상실험에서는 두 개의 집단을 비교하며 가장 많이 사용하는 두 개의 집단은 실제 치료(drug)를 받은 사람들과 위약(placebo)을 받은 사람들이다. 즉 치료를 받은 사람과 받지 않는 사람들의 효과를 비교하는 것이 임상실험의 목적이다. 이러한 경우 앞에서 논의한 의사 결정과 마찬가지로 한 환자가 받은 치료의 종류를 이항변수 \\(X\\)로 나타낼 수 있다.\n\\[\nX=\n\\begin{cases}\n1 & \\text{ if patient receives drug} \\\\\n0 & \\text{ if treatment receives placebo}\n\\end{cases}\n\\]",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#분할표와-연관성의-측도",
    "href": "notes/association.html#분할표와-연관성의-측도",
    "title": "2  연관성의 측도",
    "section": "2.3 분할표와 연관성의 측도",
    "text": "2.3 분할표와 연관성의 측도\n\n2.3.1 분할표\n이제 앞에서 말한 두 개의 변수 \\(X\\) 와 \\(Y\\) 의 관계에 대해서 생각해 보자. 실험에서 사람들은 코로나 19에 대한 치료약의 효과에 관심이 있다. 코로나 19 환자가 치료약을 처치 받으면 치료약을 이용하지 않는 환자보다 빨리 치료되거나 사망할 가능성이 낮은 지가 주요 관심사이다. 즉, 치료약이 환자의 회복 속도나 사망과 연관(association)이 있는지 알고 싶은 것이며, 특히 실험이 매우 정교하게 설계된 경우는 치료약이 환자의 회복이나 사망에 영향을 미치는 원인이 되는지(cause-effect relation) 파악하고 싶은 것이다.\n\n먼저 코로나 19에 대한 치료약의 효과에 대한 임상실험에 \\(n\\) 명의 환자들이 실험에 참가 했다고 가정하자.\n치료약이 효과가 있는지에 대한 결과(\\(Y\\))는 치료를 시작하여 정해진 기간 내에 사망하였는지에 대한 사건으로 결정하였다.\n\n\\[\nY =\n\\begin{cases}\n1 & \\text{ if patient is dead within D days } \\\\\n0 & \\text{ otherwise}\n\\end{cases}\n\\]\n코로나 19에 대한 치료약의 효과에 대한 임상실험의 결과를 다음과 같은 분할표(contingency table)로 요약할 수 있다.\n\n\n\n표 2.1: \\(2 \\times 2\\) 분할표\n\n\n\n\n\n치료/결과\n사망 (\\(Y=1\\))\n생존 (\\(Y=0\\))\n합계\n\n\n\n\n위약 (\\(X=0\\))\n\\(n_{11}\\)\n\\(n_{12}\\)\n\\(n_{1+}\\)\n\n\n치료약 (\\(X=1\\))\n\\(n_{21}\\)\n\\(n_{22}\\)\n\\(n_{2+}\\)\n\n\n합계\n\\(n_{+1}\\)\n\\(n_{+2}\\)\n\\(n\\)\n\n\n\n\n\n\n많은 임상실험이나 의학연구의 결과들을 위와 같은 \\(2 \\times 2\\) 분할표로 요약할 수 있다. 이제 우리의 관심은 분할표를 통해서 임상실험의 결과를 어떻게 통계적으로 추론할 수 있는지이다.\n\n\n\n\n\n\n노트\n\n\n\n분할표에서 연관성의 측도를 계산하는 경우 성공의 기준(이항변수로 표현하면 \\(Y=1\\))에 따라서 계산을 수행해야 한다. 어떤 경우는 사망이나 악화와 같은 위험한 사건이 성공 사건이 될 수 있으며 어떤 경우는 생존이나 회복과 같은 좋은 사건이 성공이 될 수 있다.\n또한 기준이 되는 그룹(이항변수 \\(X\\))에 따라서 연관성의 측도 계산할 때 분자와 분모에 해당하는 그룹을 적절하게 선택해야 한다.\n분할표에서 연관성의 측도를 계산하는 경우 분석의 의도와 목적에 맞게 성공 사건과 기준그룹을 정의하고 그에 따라서 연관성의 측도를 계산해야 한다.\n\n\n\n\n2.3.2 상대위험\n\\(2 \\times 2\\) 분할표 표 2.1 에서 두 개의 처리군, 즉 치료약을 받은 집단과 위약을 받은 집단의 효과를 비교할 때 가장 많이 사용되는 측도(measure)는 상대위험(relative risk, risk ratio, prevalnce ratio;RR)이다.\n주어진 집단의 위험율을 그 집단에 속한 환자의 수에서 사망한 사람의 비율이다. 분할표 표 2.1 에서 위약 집단의 위험율은 \\(n_{11}/n_{1+}\\) 이며 이는 치료를 받지 않는 경우에 나타나는 기준점인 위험율(baseline risk)을 의미한다. 치료약 집단의 위험율은 \\(n_{21}/n_{2+}\\) 이다. 통상적으로 위험율은 비율(proportion, percent)로 나타내며 발생률(rate,예를 들어 인구 1000명당 X명)로 나타내기도 한다.\n상대위험은 두 위험율의 비율로서 다음과 같이 정의한다.\n\\[\\begin{equation}\nRR = \\frac{n_{11}/n_{1+}}{n_{21}/n_{2+}} = \\frac{ \\tfrac{n_{11}}{n_{11} + n_{12}}} { \\tfrac{n_{21}}{n_{21} + n_{22}}}\n\\end{equation}\\]\n상대위험이 1보다 크면 분자에 위치한 집단이 위험(위의 예제에서는 위험이 사망을 의미한다)에 처할 가능성이 분모에 위치한 집단보다 \\(RR\\) 배 높다는 것을 의미한다. 상대위험이 1이면 두 집단에 대한 위험이 동일하다는 것을 의미한다.\n예를 들어 특정한 코로나 치료제의 효과를 실험하는 임상실험에서 다음과 결과를 얻었다.\n\n\n\n표 2.2: 코로나 치료제 실험 결과\n\n\n\n\n\n치료/결과\n사망 (\\(Y=1\\))\n생존 (\\(Y=0\\))\n합계\n\n\n\n\n위약 (\\(X=0\\))\n\\(10\\)\n\\(1212\\)\n\\(1222\\)\n\n\n치료약 (\\(X=1\\))\n\\(5\\)\n\\(2355\\)\n\\(2360\\)\n\n\n합계\n\\(15\\)\n\\(3567\\)\n\\(3582\\)\n\n\n\n\n\n\n상대위험은 다음과 같이 계산된다.\n\\[ RR = \\frac{10/1222}{5/2360} = 3.8625 \\approx 4 \\]\n상대위험이 약 4 배란 의미는 치료약을 받은 집단보다 위약집단이 사망할 가능성이 약 4배 높다는 것이다.\n\n\n\n\n\n\n노트\n\n\n\n우리는 두 집단의 비율을 비교할 때 두 비율의 차이를 이용하는 방법을 자주 사용한다. 두 집단의 비율이 각각 \\(p_1\\), \\(p_2\\) 라면 두 비율의 차이는 \\(p_1 - p_2\\) 이며 이는 우리가 평상 적으로 사용하는 비율의 비교 측도이다.\n예를 들어 대통령 후보들의 지지율과 차이는 많은 언론에서 사용하고 있으며 기초 통계학에서 두 모집단의 비교를 위한 가설 검정에서도 비율의 차이를 이용하였다.\n위의 코로나 치료제의 효과를 비교하는 실험에서 치료집단과 위약집단의 사망률 차이를 측도로 사용하면 어떨까?\n\n\n\n\n2.3.3 기여위험과 백신효과\n기여위험(attributable proportion, attributable risk percent, AR)은 두 그룹의 위험에 대한 비교를 위한 다른 측도이다. 기여위험은 특정한 성격을 가진 집단(exposed group)이 위험에 처한 전체 집단에서 차지하는 비율을 백분율로 나타낸다.\n\\[\\begin{equation}\nAR = \\frac{ (n_{11}/n_{1+}) - (n_{21}/n_{2+})} {n_{11}/n_{1+} } \\times 100\n\\end{equation}\\]\n예를 들어 비흡연자(unexposed group)와 흡연자(exposed group)의 폐암에 대한 위험을 비교하는 경우를 생각해 보자.비흡연자의 폐암으로 인한 사망률이 연간 1000명 당 0.07명이고 흡연자는 1000명당 0.57명이라고 하면\n일단 상대위험은 약 8배이다.\n\\[  RR = 0.57/0.07 = 8.1428 \\]\n두 집단의 비교를 기여위험으로 나타내면 다음과 같다.\n\\[ AR = \\frac{0.57-0.07}{0.57} \\times (100) = 87.7\\% \\approx 88 \\%\\]\n만약 흡연이 폐암을 일으키는 원인이고 두 집단의 다른 요인이 유사하다고 가정하면, 기여위험이 약 88% 라는 것은 모든 폐암 환자(위험에 처한 전체 집단)의 88% 가 흡연에 의한 것이라고 해석할 수 있다.\n최근에 코로나 19에 대한 백신과 치료제의 임상실험에서 효과를 발표하는 경우 위에서 언급한 상대위험을 사용하지 않고 백신효과(Vaccine efficacy, vaccine effectiveness; VE) 라는 백분율을 사용한다. 백신효과는 기본적으로 기여위험과 동일한 측도이다.\n예를 들어 위의 예제에서 치료제의 효과를 백신효과(VE)로 계산하면 다음과 같다.\n\\[ VE = \\left [ \\frac{10/1222 - 5/2360}{10/1222} \\right ]\\times 100 =74.1101\\% \\]\n백신효과가 74% 란 의미는 치료제를 사용하면 사용하지 않는 경우보다 사망을 74% 줄일 수 있다고 해석할 수 있다.\n간단한 예로서 코로나19로 인한 치명율(사망자/확진자)을 비교한다고 가정하자. 백신을 맞은 그룹의 치명율이 1%이고 백신을 맞지 않는 그룹의 치명율이 2% 백신효과는 50%이다.\n\n\n2.3.4 오즈비\n오드(odd)는 가능성을 나타내는 측도로서 전통적으로 도박에서 유래된 측도이다.\n우리가 주사위를 던져서 1과 2가나오면 성공, 다른 숫자가 나오면 실패라고 하는 경우 성공의 확률은 \\(2/6 =0.3333\\) 으로 계산한다. 확률을 계산하는 경우는 분모에 전체 사건의 수를 사용한다.\n위의 주사위 예제로 오드를 계산하면 \\(2/4 =0.5\\) 가 된다. 즉, 오드는 분모에 성공을 제외한 실패의 사건을 수를 사용한다. 만약 오드가 1이면 무슨 의미인가? 오드가 1이면 성공하는 사건의 수가 실패하는 사건의 수가 동일하다는 의미이다. 게임에서 이길 확률이 \\(1/2\\) 이면 공정한 게임이며 이 경우 오드는 1 이다.\n전통적으로 오드는 확률의 개념이 나오기 전에 가능성의 측도로 오랫동안 사용되어 왔으며 도박에서 상대방이 1번 이길 때 내가 이기는 평균적인 횟수를 의미한다.\n\\[ odd = \\frac{\\text{number of events for success}}{\\text{number of events for failure}} \\]\n예를 들어 위의 코로나 치료제 실험에서 성공을 사망할 사건이라고 하면 위약군의 오드는 \\(n_{11}/n_{12} =10/1212\\) 이고 치료군의 오드는 \\(n_{21}/n_{22} = 5/2355\\) 이다.\n두 집단을 비교하는 측도 중 하나는 오즈비(odds ratio; OR)가 있다. 오즈비는 두 그룹의 오드들의 비율로 정의된다. 오즈비가 1이면 두 그룹에서 성공 사건의 가능성이 같다는 것이다.\n\\[ OR = \\frac{n_{11}/n_{12}}{n_{21}/n_{22}} = \\frac{n_{11} n_{22}}{n_{12} n_{21}} \\]\n코로나 치료제 실험에서의 오즈비는 \\((10/1212)/(5/2355) =3.8861\\) 이다.\n오즈비는 상대위험이나 기여위험에 비하여 의미 있는 해석이 어렵다. 오즈비가 1이면 두 집단이 성공의 가능성이 같다(또는 두 요인의 연관성이 없다)는 것으로 해석이 쉽다. 하지만 예를 들어 오즈비가 1 보다 큰 경우(또는 작은 경우) 두 집단의 차이를 의미 있게 해석하는 것이 어렵다.\n오즈비는 향후 학습할 통계적 가설검정에서 중요한 모수(parameter)로 사용되며 특히 실험의 방법이 사례-대조 연구와 같은 특별한 방법을 사용하는 경우 오즈비가 중요한 역할을 하게 된다.\n\n예를 들어 다음과 같은 분할표에서 비율의 차이, 상대위험, 오즈비를 구하여 비교해 보자.\n\n\n\n표 2.3: \\(2 \\times 2\\) 분할표 예제\n\n\n\n\n\n처리 /결과\n성공 (\\(Y=1\\))\n실패 (\\(Y=0\\))\n합계\n\n\n\n\n0 (\\(X=0\\))\n\\(6\\)\n\\(4\\)\n\\(10\\)\n\n\n1 (\\(X=1\\))\n\\(4\\)\n\\(6\\)\n\\(10\\)\n\n\n합계\n\\(10\\)\n\\(10\\)\n\\(20\\)\n\n\n\n\n\n\n비율의 차이(DP)은 다음과 같이 계산된다.\n\\[ DP(0/1) =  6/10 - 4/10 = 0.2 \\]\n상대위험은 다음과 같이 계산된다.\n\\[ RR(0/1) = \\frac{6/10}{4/10} = \\frac{6}{4} = 1.5 \\]\n오즈비는 다음과 같이 계산된다.\n\\[ OR(0/1) = \\frac{6/4}{4/6} = \\frac{(6)(6)}{(4)(4)} = 2.25 \\]",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#신뢰구간",
    "href": "notes/association.html#신뢰구간",
    "title": "2  연관성의 측도",
    "section": "2.4 신뢰구간",
    "text": "2.4 신뢰구간\n상대위험과 오즈비는 분할표에서 연관성을 나타내는 하나의 측도, 즉 점추정량(point estimation) 이다. 하나의 숫자로 표현되는 점추정은 표본으로 부터 발생한 불확실성을 반영하지 못한다. 따라서 점추정량을 보완하기 위하여 신뢰구간(confidence interval)을 제시할 수 있다.\n상대위험과 오즈비는 표본비율 또는 셀 도수의 함수로 나타난다. 하지만 함수의 형태가 비율로서 비선형이기 때문에 상대위험과 오즈비의 근사적인 표준오차(standard error)는 쉽게 구할 수 없다.\n다항분포를 가정하고 로그 오즈비의 점근적 분산을 다음과 같이 유도할 수 있다.\n\\[ v_1 =V ( \\log OR)   \\approx \\frac{1}{n_{11}} + \\frac{1}{n_{12}} + \\frac{1}{n_{21}} + \\frac{1}{n_{22}} \\]\n따라서 로그 오즈비의 \\(100(1-\\alpha)\\) % 근사 신뢰구간을 다음과 같이 구할 수 있다.\n\\[\\begin{equation*}\n   \\log OR \\pm z_{\\alpha/2} \\sqrt{v_1}\n\\end{equation*}\\]\n위의 신뢰구간을 오즈비로 역변환하면 오즈비 \\(OR\\) 의 \\(100(1-\\alpha)\\) % 근사 신뢰구간을 다음과 같다.\n\\[\n   ( OR \\times \\exp [ - z_{\\alpha/2} \\sqrt{v_1}], ~~OR \\times \\exp [  z_{\\alpha/2} \\sqrt{v_1}] )\n\\tag{2.1}\\]\n상대위험(RR)의 신뢰구간도 오즈비의 신뢰구간을 유도하는 방법과 유사하게 델타 방법을 사용하며 다음과 같이 구할 수 있다.\n\\[\n   ( RR \\times \\exp [ - z_{\\alpha/2} \\sqrt{v_2}], ~~OR \\times \\exp [  z_{\\alpha/2} \\sqrt{v_2}] )\n\\tag{2.2}\\]\n위의 식 식 2.2 에서 \\(v_2\\) 는 다음과 같이 계산한다.\n\\[ v_2 =V ( \\log RR)   \\approx \\frac{1-n_{11}/n_{1+}}{n_{11}} + \\frac{1-n_{21}/n_{2+}}{n_{21}} \\]\n\n2.4.1 예제: 아스피린 임상실험\n소량의 아스피린 복용이 심장병으로 인한 위험을 줄이는데 효과가 있는지 알아보고자 임상실험을 실시하였다. 22,701명의 남성을 임의화(randomization) 을 통해서 두 그룹으로 나눈 후, 한 그룹은 매일 일정량의 아스피린을 복용시키고 다른 그룹은 위약(palcebo)를 복용하게 한 후 약 5년간 심근경색이 일어나는지 알아보았다. 임상실험의 결과는 아래 표와 같다.\n\n\n\n표 2.4: 아스피린 임상실험 결과\n\n\n\n\n\n\n심근경색 발생\n심근경색 없음\n합\n\n\n\n\n아스피린\n\\(139\\)\n\\(10,898\\)\n\\(11,037\\)\n\n\n위약\n\\(239\\)\n\\(10,795\\)\n\\(11,034\\)\n\n\n\n\n\n\n위약 집단과 아스피린 집단의 상대위험은 다음과 같다.\n\\[ RR = \\frac{139/11037}{239/11034} = 0.581 \\]\n상대위험을 보면 1보다 작으므로 아스피린을 복용한 집단이 위약 집단에 비해서 심근 경색이 일어날 위험이 적어진 다는 것을 알 수 있다.\n상대위험의 95% 근사 신뢰구간은 다음과 같이 계산한다.\n먼저 다음 \\(v_2\\) 를 계산하면\n\\[ v_2 = \\frac{1-n_{11}/n_{1+}}{n_{11}} + \\frac{1-n_{21}/n_{2+}}{n_{21}}  =\n\\frac{1-139/11037}{139} + \\frac{1-239/11034}{239} = 0.011 \\]\n상대위험의 신뢰구간은 다음과 같다.\n\\[(0.581 \\times \\exp[-1.96\\sqrt{0.011}], 0.581 \\times \\exp[1.96\\sqrt{0.011}])\n= ( 0.473, 0.715)\\]\n위의 신뢰구간은 1을 포함하지 않으므로 상대위험이 1 과 유의한 차이가 있다고 할 수 있다. 결론적으로 아스피린의 복용은 심근경색의 발생을 감소시킨다고 할 수 있다.\n이제 epiR 패키지를 사용하여 위에서 분석한 내용을 다시 구해보자.\n먼저 위의 임상실험 자료를 R 의 matrix 형태로 저장한다.\n\nex1dat &lt;- matrix( c(139, 10898, 239, 10795), 2, 2, byrow=TRUE)\nex1dat\n\n     [,1]  [,2]\n[1,]  139 10898\n[2,]  239 10795\n\n\n이제 함수 epi.2by2를 이용하여 상대위험과 싱대구간을 구해보자. 임의화를 사용한 임상실험 자료인 경우 method = \"cross.sectional\" 으로 지정한다. 관심이 있는 사건(심근경색, outcome)의 도수가 첫 번째 열(column)에 있으니 outcome = \"as.columns\"이라고 지정한다.\n아래 결과에 Prevalence ratio라고 나오는 것이 상대위험이다.\n\nepi.2by2(dat = ex1dat, method = \"cross.sectional\", conf.level = 0.95, units = 100, \n   interpret = FALSE, outcome = \"as.columns\")\n\n             Outcome +    Outcome -      Total               Prev risk *\nExposed +          139        10898      11037       1.26 (1.06 to 1.49)\nExposed -          239        10795      11034       2.17 (1.90 to 2.46)\nTotal              378        21693      22071       1.71 (1.55 to 1.89)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nPrev risk ratio                                0.58 (0.47, 0.72)\nPrev odds ratio                                0.58 (0.47, 0.71)\nAttrib prev in the exposed *                   -0.91 (-1.25, -0.56)\nAttrib fraction in the exposed (%)            -71.99 (-111.63, -39.78)\nAttrib prev in the population *                -0.45 (-0.77, -0.13)\nAttrib fraction in the population (%)         -26.47 (-36.51, -17.18)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 26.944 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#casecontrol",
    "href": "notes/association.html#casecontrol",
    "title": "2  연관성의 측도",
    "section": "2.5 사례-대조 연구",
    "text": "2.5 사례-대조 연구\n심장발작을 일으킨 환자와 그렇지 않은 사람들을 각각 214명씩 조사하여 과거에 약물남용을 한 경력이 있는지 조사한 사례-대조 연구의 자료이다.\n\n\n\n표 2.5: 약물 남용 사례-대조 연구 결과\n\n\n\n\n\n\n심장 발작 발생\n심장발작 없음\n\n\n\n\n약물남용 유\n\\(73\\)\n\\(18\\)\n\n\n약물남용 무\n\\(141\\)\n\\(196\\)\n\n\n합\n214\n214\n\n\n\n\n\n\n이 연구의 목표는 약물남용과 심장발작의 연관성이 있는지를 알아보는 것이다. 이제 다음과 같은 사건들을 정의해 보자.\n\n\\(H+\\): 심장발작이 발생했다.\n\\(H-\\): 심장발작이 발생하지 않았다.\n\\(D+\\): 약물남용을 했다.\n\\(D-\\): 약물남용을 하지 않았다.\n\n위에서 정의된 사건들을 고려할 때 사례-대조 연구의 자료에서 다음과 같은 조건부 확률에 대한 추정값을 구할 수 있다.\n\\[\\begin{align*}\nP(\\textrm{약물남용을 했다} | \\textrm{심장발작이 발생했다}) & =P(D+|H+) = \\frac{73}{214} \\\\\nP(\\textrm{약물남용을 하지 않았다} | \\textrm{심장발작이 발생했다}) & =P(D-|H+) = 1- P(D+|H+) = \\frac{141}{214} \\\\\n  & \\\\\nP(\\textrm{약물남용을 했다} | \\textrm{심장발작이 발생하지 않았다}) & =P(D+|H-) = \\frac{18}{214} \\\\\n  P(\\textrm{약물남용을 하지 않았다} | \\textrm{심장발작이 발생하지 않았다}) & =P(D-|H-) = 1- P(D+|H-) = \\frac{196}{214}\n\\end{align*}\\]\n\n2.5.1 사례대조 연구의 목표와 가설\n연구에서 비교하고 싶은 비율은 위에서 추정한 확률이 아니고 조건과 결과가 바뀐 다음과 같은 조건부 확률이다. \\[\\begin{align*}\nP( \\textrm{심장발작이 발생했다} | \\textrm{약물남용을 했다} ) & = P(H+|D+) \\\\\nP( \\textrm{심장발작이 발생했다} | \\textrm{약물남용을 하지 않았다} ) & = P(H+|D-) \\\\\n\\end{align*}\\]\n즉 연구의 목표는 다음과 같은 가설을 검정하는 것이다.\n\\[\nH_0: P(H+|D+) = P(H+|D-)  ~~~\\text{ vs } ~~~H_1: P(H+|D+) \\ne P(H+|D-)\n\\tag{2.3}\\]\n전체 모집단을 약물남용을 한 사람들과 하지 않은 사람들로 두 집단으로 나누었을 때 두 집단에 대한 심장발작의 확률이 같은지 다른지 비교하고 싶은 것이다.\n위의 식에서 보듯이 추정하고 싶은 확률인 \\(P(H+|D+)\\)와 \\(P(H+|D-)\\)를 추정하려면 전체 모집단에 대한 심장발작 발병률 \\(P(H+)\\)와 약물남용의 비율 \\(P(D+)\\)를 알아야 한다. 즉\n\\[\\begin{align*}\nP(H+|D+) & = \\frac{ P(H+ \\cap D+)} { P(D+)} \\\\\n          & = \\frac{ P(D+|H+) P(H+)} { P(D+)} \\\\\n          & \\approx  (73/214) \\frac{ P(H+)} { P(D+)} \\\\\n\\end{align*}\\]\n위의 식은 다음의 조건부 확률 공식을 각 단계마다 적용한 결과이다.\n\\[ P(A \\cap B) = P(A|B)P(B) = P(B|A) P(A) \\]\n사례-대조 연구의 자료만으로는 모집단에 대한 심장발작 발병률 \\(P(H+)\\)와 약물남용의 비율 \\(P(D+)\\)을 구할 수 없다. 또한 다른 외부의 자료가 있다 하더라도 약물남용의 비율을 정확하게 추정하는 것은 매우 어렵다.\n\n\n2.5.2 오즈비의 비교\n이러한 문제는 두 집단의 비율의 차이나 상대위험을 비교하지 않고 오즈비를 구하여 비교하면 심장발작 발병률와 약물남용의 비율을 추정하지 않고 사례-대조 연구의 자료만으로 추론이 가능하다.\n다음의 가설은 두 비율의 비교를 오즈비로 표현한 것이다.\n\\[\nH_0: \\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)} =1  ~~~\\text{ vs } ~~~H_1:\n\\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)} \\ne 1\n\\tag{2.4}\\]\n위의 가설 식 2.4 는 단순한 비율을 비교하는 가설 식 2.3 과 동일한 가설이다.\n가설 식 2.4 에서 나타는 오즈비는 심장발작 발병률와 약물남용의 비율을 이용하지 않고 사례-대조 연구에서 추정할 수 있는 조건부 확률만으로 추정할 수 있다.\n\\[\\begin{align*}\n\\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)}  \n   & =  \\frac{[P(H+|D+)P(D+)]/[P(H-|D+)P(D+)]}{[P(H+|D-)P(D-)] / [P(H-|D-)P(D-)]} \\\\\n   & =  \\frac{P(H+ \\cap D+)/P(H- \\cap D+)}{P(H+ \\cap D-) / P(H- \\cap D-)}\\\\\n   & =  \\frac{[P(D+|H+)P(H+)]/ [P(D+|H-) P(H-)]} {[P( D-|H+)P(H+)] / [P(D-|H-)P(H-)]}\\\\\n   & =  \\frac{P(D+|H+)/ P(D+|H-)} {P( D-|H+) / P(D-|H-)} \\\\\n   &=   \\frac{(73/214)/ (142/214)} {(18/214)/ (196/214)} \\\\\n   & = \\frac{(73)(196)}{(141)(18)} \\\\\n   & = 5.64\n\\end{align*}\\]\n결론적으로 사례-대조 연구에서는 연구의 목표에 대한 가설 검정을 비율의 차이나 상대위험으로 표현하여 수행할 수 없다. 하지만 오즈비를 검정하는 것으로 가설을 세우면 자료에서 쉽게 유도할 수 있는 오즈비로 가설 검정을 쉽게 수행할 수 있다.\n\n\n2.5.3 예제: 약물남용 사례-대조 연구\n심작발작을 일으킨 환자와 그렇지 않은 사람들을 각각 214명씩 조사하여 과거에 약물남용을 한 경력이 있느지 조사한 사례-대조 연구(case-control study) 의 결과가 표 표 2.5 에 있다.\n사례-대조 연구는 사례(case)가 발견되면, 즉 위의 연구와 같이 심장발작이 일어난 환자가 발생하면 그 환자와 유사한 나이와 성별 등을 가진 일반사람을 찾아 매칭하여 환자와 일반인의 과거 경력을 조사하는 후향적인 연구(restrspective study)이다. 반대로 앞의 예제에서 본 임의화를 이용한 임상실험은 전향적 연구(prospective study)이다.\n이러한 사례-대조 연구에서는 상대위험을 이용하여 연관성을 알아낼 수 없다. 하지만 사례-대조 연구에서 상대위험 대신 오즈비를 이용하여 연관성을 추론할 수 있다.\n위의 심장발작에 대한 사례-대조 연구의 결과에서 오즈비와 그 신뢰구간을 구해보자.\n먼저 오즈비는 다음과 같다.\n\\[ OR = \\frac{(73)(196)}{(18)(141)} = 5.64 \\]\n위의 결과는 심장발작이 일어난 집단에서 약물남용을 한 환자들의 오즈가 심장발작이 일어나지 않은 집단에서 약물남용을 한 사람들의 오즈에 비해 5.6배 크다는 것을 알 수 있으며 이는 1보다 상당히 크다.\n오즈비의 95% 근사 신뢰구간은 다음과 같이 계산한다.\n먼저 다음 \\(v_1\\) 를 계산하면\n\\[ v_1 =V ( \\log OR)   \\approx \\frac{1}{n_{11}} + \\frac{1}{n_{12}} + \\frac{1}{n_{21}} + \\frac{1}{n_{22}} = \\frac{1}{73} + \\frac{1}{18} + \\frac{1}{141} + \\frac{1}{196} =0.08\\]\n오즈비의 신뢰구간은 다음과 같다.\n\\[(5.64 \\times \\exp[-1.96\\sqrt{0.08}], 5.64 \\times \\exp[1.96\\sqrt{0.08}])\n= (3.222, 9.863)\\]\n위의 신뢰구간을 보면 1을 포함하지 않으므로 약물남용이 심장발작의 위험을 높인다고 말할 수 있다.\n이제 epiR 패키지를 사용하여 위에서 분석한 내용을 다시 구해보자.\n먼저 위의 사례-대조 연구 자료를 R 의 matrix 형태로 저장한다.\n\nex2dat &lt;- matrix( c(73,18,141,196), 2, 2, byrow=TRUE)\nex2dat\n\n     [,1] [,2]\n[1,]   73   18\n[2,]  141  196\n\n\n이제 함수 epi.2by2를 이용하여 오즈비과 신뢰구간을 구해보자. 사례-대조 연구의 자료인 경우 method = \"case.control\" 으로 저장한다. 사례-대조 연구로 지정하면 상대위험이 출력되지 않는다. 관심이 있는 사건(심장발작, outcome)의 도수가 첫 번째 열(column)에 있으니 outcome = \"as.columns\"이라고 지정한다.\n\nepi.2by2(dat = ex2dat, method = \"case.control\", conf.level = 0.95, units = 100, \n   interpret = FALSE, outcome = \"as.columns\")\n\n             Outcome +    Outcome -      Total                       Odds\nExposed +           73           18         91        4.06 (2.50 to 7.27)\nExposed -          141          196        337        0.72 (0.57 to 0.89)\nTotal              214          214        428        1.00 (0.83 to 1.21)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nExposure odds ratio                            5.64 (3.22, 9.86)\nAttrib fraction (est) in the exposed (%)      82.19 (68.26, 90.44)\nAttrib fraction (est) in the population (%)   28.06 (20.13, 35.21)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 42.218 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#필요한-패키지",
    "href": "notes/association-test.html#필요한-패키지",
    "title": "3  연관성의 검정",
    "section": "3.1 필요한 패키지",
    "text": "3.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#카이제곱-검정",
    "href": "notes/association-test.html#카이제곱-검정",
    "title": "3  연관성의 검정",
    "section": "3.2 카이제곱 검정",
    "text": "3.2 카이제곱 검정\n일단 2개의 이항변수 \\(X\\) 와 \\(Y\\) 를 고려하고 가능한 결과의 조합과 그 확률은 다음과 같은 \\(2 \\times 2\\) 분할표로 나타낼 수 있다.\n\n\n\n그림 3.1: 2 x 2 분할표\n\n\n\n\n\n\n일반적으로 \\(2 \\times 2\\) 분할표에서 다음과 같은 두 가지 가설이 가능하다.\n\n동질성 검정(homogeneuty test)\n변수 \\(X\\) 가 단순하게 독립 집단을 나누는 변수인 경우 (예를 들어 실험약 집단과 위약 집단) 두 그룹 간에 이항변수 \\(Y\\)의 성공확률이 같은지 검정하는 경우이다. 실험약 집단과 위약 집단에서 심장병이 발병할 확률이 같은지 검정을 수행할 때 귀무가설은 다음과 같다.\n\n\\[ H_0: p_{1j} = p_{2j} = p_j \\]\n\n독립성 검정(independent test)\n변수 \\(X\\) 와 \\(Y\\) 가 모두 확률변수인 경우 두 변수가 독립인지 검정하는 경우이다. 예를 들어 흡연(\\(X\\))과 심근경색(\\(Y\\))의 관계를 연구하는 경우 두 사건이 모두 확률적인 사건이라고 보고 다음과 같이 독립에 대한 가설을 고려한다.\n\n\\[ H_0: p_{ij} = p_{i+} p_{+j} \\]\n다음과 같이 \\(n\\) 개의 관측값으로 구성된 \\(2 \\times 2\\) 분할표에서 동질성과 독립성 가설을 검정하는 방법은 동일하며 따라서 굳이 두 가지 가설을 엄격하게 구별할 이유는 없다. 만약 귀무가설이 기각되면 두 변수의 연과성은 유의하다고 결론을 내린다.\n\n\n\n그림 3.2: 2 x 2 분할표: 관측 도수\n\n\n\n\n\n\n동질성과 독립성에 대한 검정은 다음과 같은 카이제곱 통계량을 사용한다.\n\\[\n\\chi^2 = \\sum_{i=1}^2 \\sum_{j=1}^2 \\frac{(O_{ij} - E_{ij})^2}{E_ij}  \n\\tag{3.1}\\]\n위의 카이제곱 통계량에서 \\(O_{ij} = n_{ij}\\) 는 각 셀의 관측도수이며 \\(E_{ij}\\)는 귀무가설 하에서의 셀 도수의 예측값이다.\n동질성 검정을 고려할 때 만약 귀무가설이 참이라면 확률 \\(p_{1j} =p_{2j}=p_j\\) 는 다음과 같이 추정할 수 있다.\n\\[ \\hat p_{j} = \\frac{n_{+j}}{n} \\]\n따라서 셀 \\((i,j)\\) 에 대한 기데 돗수 \\(E_{ij}\\) 는 다음과 같이 계산된다.\n\\[\nE_{ij} =n_{i+} \\hat p_j =\\frac{n_{i+} n_{+j}}{n}\n\\tag{3.2}\\]\n귀무가설 하에서 표본의 크기가 충분히 크면 식 식 3.1 의 카이제곱 검정통계량 \\(\\chi^2\\) 는 자유도가 1인 카이제곱 분포를 따른다. 그러므로 이 사실을 이용하여 p-값을 계산하거나 기각역을 구하여 검정한다.\n일반적인 \\(I \\times J\\) 분할표도 동일한 방법으로 가설검정을 할 수 있다. 카이제곱 통계량을 구하는 방법은 \\(2 \\times 2\\) 분할표와 유사하다. 다만 귀무가설이 참인 경우 검정통계량은 자유도가 \\((I-1)(J-1)\\) 인 카이제곱 분포를 따른다.\n\\[\n\\chi^2 = \\sum_{i=1}^I \\sum_{j=1}^J \\frac{(O_{ij} - E_{ij})^2}{E_ij}  \n\\]\n이제 실제 분할표에서 카이제곱 검정을 수행해 보자. 아스피린 임상실험 결과가 주어진 표 표 2.4 에서 아스피린의 횩과사 없는 경우, 즉 귀무가설이 참인 경우 다음과 같이 심근경색의 유무에 대한 예측 확률을 구할 수 있다.\n\\[ \\hat p_1 = \\frac{n_{+1}}{n} = \\frac{139+239}{22071} = 0.0171 \\] \\[\\hat p_2 = \\frac{n_{+2}}{n} = \\frac{10898+10795}{22071} = 0.9829 \\]\n이제 각 셀의 기대도수를 식 식 3.2 에 의하여 계산할 수 있다. 예를 들어 \\(E_{11}\\) 은 다음과 같이 계산된다.\n\\[ E_{11} = \\frac{n_{1+}n_{+1}}{n} =  n_{1+} \\hat p_1 = (11037)(0.0171) = 189.03 \\]\n각 셀에 대한 기대도수 \\(E_{ij}\\) 를 구하고 식 식 3.1 의 카이제곱 통계량을 구하면 다음과 같다.\n\\[\\begin{align*}\n\\chi^2 & = \\frac{(139-189.03)^2}{189.03} +  \\frac{(10898-10848.00)^2}{10848.00}  \\\\\n& \\quad + \\frac{(239-188.97)^2}{188.97} +  \\frac{(10795-10845.03)^2}{10845.03}  \\\\\n& = 26.94\n\\end{align*}\\]\n자유도가 1인 카이제곱 분포의 상위 5% 백분위수 \\(3.84\\) 이다. 위에서 구한 카이제곱 통계량의 값이 \\(26.94\\) 로서 \\(3.84\\) 보다 크므로 귀무가설을 기각한다. 즉 아스프린과 위약을 복용한 두 그룹 사이에는 심근경색이 일어날 비율에 유의한 차이가 있다.\nR 에서도 카이제곱 검정을 쉽게 수행할 수 있다. 앞에서 표 표 2.4 의 자료를 행렬의 형태로 저장하였는데 함수 chisq.test() 를 사용하면 결과를 쉽게 구할 수 있다.\n\nex1dat &lt;- matrix( c(139, 10898, 239, 10795), 2, 2, byrow=TRUE)\nex1dat\n\n     [,1]  [,2]\n[1,]  139 10898\n[2,]  239 10795\n\n\n\nchisq.test(ex1dat)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  ex1dat\nX-squared = 26.408, df = 1, p-value = 2.764e-07\n\n\n분할표에서의 기대도수 \\(E_{ij}\\) 는 다음과 같이 얻을 수 있다.\n\nchisq.test(ex1dat)$expected\n\n         [,1]     [,2]\n[1,] 189.0257 10847.97\n[2,] 188.9743 10845.03",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#코크란-맨텔-헨젤-검정",
    "href": "notes/association-test.html#코크란-맨텔-헨젤-검정",
    "title": "3  연관성의 검정",
    "section": "3.3 코크란-맨텔-헨젤 검정",
    "text": "3.3 코크란-맨텔-헨젤 검정\n임상실험이나 의학연구는 여러 나라 또는 여러 병원들에서 진행되는 경우가 있다. 이러한 경우 국가나 병원의 고유한 특성에 따라서 실험의 결과가 다르게 나타날 수 있다. 이렇게 그룹에 의한 효과를 그룹 효과 또는 층(strata)에 의한 효과라고 한다. 예를 들어 진통제에 대한 효과는 그 나라의 문화나 관습에 따라서 효과의 차이가 나타날 수 있다. 또한 여러 개의 변원에서 연그ㅜ가 동시에 진행된다면 병원의 규모, 위치, 환자들의 특성에 따라서 치료 효과의 차이가 나타날 수 있다.\n이렇게 그룹에 따른 차이가 예상되는 경우 그룹의 효과를 제어하면서 처리 효과의 차이를 검정하는 방법이 필요하다. 이렇게 여러 개의 층으로 구성된 독립집단에서 얻은 자료에서 층에 의한 횩과를 통제하면서 동질성 또는 독립성 검정을 수행하는 방법을 코크란-맨텔-헨젤 검정 (Cochran-Mantel-Haenzel test)라고 한다.\n아래와 같이 \\(K\\) 개의 독립집단(또는 층)에서 각각 얻은 \\(K\\) 개의 \\(2 \\times2\\) 분할표가 있다고 하자.\n\n\n\n그림 3.3: K 개의 2 x 2 분할표\n\n\n\n\n\n\n\\(K\\) 개의 독립집단이 있고 성공의 확률이 \\(p_1\\), 실패의 학률이 \\(p_2\\) 라고 한다면 처리의 효과를 전체적으로 비교하는 가설은 다음과 같다.\n\\[ H_0: p_1 =p_2 \\quad \\text{sv.} \\quad H_1: p_1 \\ne p_2 \\]\n이제 귀무가설의 가정 하에서 각 분할표에서 \\(n_{k11}\\) 에 대한 기대도수 \\(\\mu_{k11}\\) 와 그 분산 \\(v_{k11}\\) 을 다음과 같이 계산한다.\n\\[\n\\mu_{k11} = E(n_{k11} | H_0) = \\frac{ n_{k1+} n_{k+1} }{ n_k}\n\\]\n\\[\nv_{k11} = V ( n_{k11} | H_0)  = \\frac{ n_{k1+} n_{k2+} n_{k+1} n_{k+2} }{n^2_k (n_k-1)}\n\\]\n이제 가설검정을 위한 통계량 \\(Q_{CMH}\\) 은 다음과 같다.\n\\[\nQ_{CMH} = \\frac{ \\left [  \\sum_{k=1}^K  (n_{k11} - \\mu_{k11}) \\right ]^2 }{\\sum_{k=1}^K v_{k11}}\n\\tag{3.3}\\]\n귀무가설이 참인 경우 검정통계량 \\(Q_{CMH}\\) 은 자유도가 \\(1\\) 인 카이제곱 분포를 따른다.\n이제 Agresti (2012) 의 6.3절에 있는 다기관 임상시험(multi-center clinical trial) 의 예제를 살펴보자. 아래 표는 모두 8개의 독립적인 병원에서 감염 치료제에 대한 효과에 대한 실험을 실시하여 얻은 자료이다.\n\n\n\n그림 3.4: 8개 병원의 임상실험 결과\n\n\n\n\n\n\n마지막 병원을 제외한 7개의 병원에서 치료제의 효과가 긍정적으로 나타났다. 여기서 주목할 점은 병원에 따라서 연관성의 강도가 매우 다르게 나타날 수 있다는 것이다.\n이제 각 병원을 층(strata)로 고려하고 병원의 효과를 제어하면서 식 식 3.3 의 검정 통계량 \\(Q_{CMH}\\) 를 이용하여 치료제의 효과가 있는지 검정해보자. 검정은 아래와 같이 R 프로그램을 이용한다. 함수 mantelhaen.test() 는 코크란-맨텔-헨젤 검정을 수행하는 함수이다.\n\nbeitler &lt;- c(11,10,25,27,16,22,4,10,14,7,5,12,2,1,14,16,6,0,11,12,1,0,10,10,1,1,4,8,4,6,2,1)\nbeitler &lt;- array(beitler, dim=c(2,2,8))\nbeitler\n\n, , 1\n\n     [,1] [,2]\n[1,]   11   25\n[2,]   10   27\n\n, , 2\n\n     [,1] [,2]\n[1,]   16    4\n[2,]   22   10\n\n, , 3\n\n     [,1] [,2]\n[1,]   14    5\n[2,]    7   12\n\n, , 4\n\n     [,1] [,2]\n[1,]    2   14\n[2,]    1   16\n\n, , 5\n\n     [,1] [,2]\n[1,]    6   11\n[2,]    0   12\n\n, , 6\n\n     [,1] [,2]\n[1,]    1   10\n[2,]    0   10\n\n, , 7\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    1    8\n\n, , 8\n\n     [,1] [,2]\n[1,]    4    2\n[2,]    6    1\n\nmantelhaen.test(beitler, correct=FALSE)\n\n\n    Mantel-Haenszel chi-squared test without continuity correction\n\ndata:  beitler\nMantel-Haenszel X-squared = 6.3841, df = 1, p-value = 0.01151\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 1.177590 3.869174\nsample estimates:\ncommon odds ratio \n         2.134549 \n\n\n검정 통계량 \\(Q_{CMH}\\)의 값이 \\(6.3841\\) 이고 p-값은 \\(0.0115\\) 이므로 귀무가설을 기각한다.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#맥나마-검정",
    "href": "notes/association-test.html#맥나마-검정",
    "title": "3  연관성의 검정",
    "section": "3.4 맥나마 검정",
    "text": "3.4 맥나마 검정\n연속형 변수에서 짝지은 자료를 비교할 때 사용하는 방법이 대응 t-검정(paired t-test) 또는 짝표본 t-검정이다. 예를 들어 천식환자가 A약을 먹고 폐활량을 측정하고 일정 기간이 지나서 같은 환자가 B약을 먹고 폐활량을 측정하면 두 관측값은 독립이 아나다. 따라서 이러한 경우 독립 t-검정이 아닌 대응 t-검정을 시용한다.\n이제 이산형 변수가 짝으로 나타나는 경우를 생각해보자. 예를 들어 눈병 치료에 사용되는 A약과 B약의 효과를비교하기 위하여 각각의 약을 환자의 오른쪽 눈과 왼쪽 눈에 처치를 하고 치료의 여부를 관측하였다고 하자.\n\n\n\n그림 3.5: 짝표본 실험에 의한 2 x 2 분할표\n\n\n\n\n\n\n위의 표에서 \\(n_{11}\\) 은 A약과 B약의 효과가 모두 나타난 환자의 도수이다. \\(n_{12}\\) 은 A약은 효과가 있고 B약은 효과가 없는 환자의 도수이다. 이러한 자료는 앞에서 배운 카이제곱 검정을 적용할 수 없다.\n이제 일반적으로 짝표본에서 나온 자료가 다음 표와 같이 얻어졌다고 가정하자.\n\n\n\n그림 3.6: 짝표본 실험에 의한 2 x 2 분할표\n\n\n\n\n\n\n이제 조건 1 에서 성공의 확률을 \\(p_1\\) 이라고 하고 조건 2에서 성공의 확률을 \\(p_2\\) 라고 하면 짝표본에서 얻어진 분할표 그림 3.6 에서 관심있는 가설은 다음과 같다.\n\\[ H_0: p_1 =p_2 \\quad \\text{sv.} \\quad H_1: p_1 \\ne p_2 \\]\n분할표 그림 3.6 에서 \\(p_1\\) 과 \\(p_2\\)의 추정량은 다음과 같다.\n\\[ \\hat p_1 = \\frac{n_{1+}}{n}, \\quad \\hat p_2 = \\frac{n_{+1}}{n} \\]\n\\(p_1\\) 과 \\(p_2\\)의 추정량의 차이는 두 조건에 따른 결과가 일치하지 않는 도수 \\(n_{12}\\)와 \\(n_{21}\\)의 차이에 의존한다.\n\\[ \\hat p_1 -\\hat p_2 = \\frac{n_{1+}}{n} - \\frac{n_{+1}}{n} =\n\\frac{n_{11} + n_{12}}{n} - \\frac{n_{11} + n_{21}}{n} = \\frac{n_{12} - n_{21}}{n}\n\\]\n맥나마 검정(McNemar Test)는 도수 \\(n_{12}\\)와 \\(n_{21}\\)에 의거하여 두 확률이 같은지 검정하는 방법을 제시하였다. 맥나마 검정을 위한 통계량은 다음과 같다.\n\\[\nQ_{M} = \\frac{ (n_{12}-n_{21})^2}{n_{12} + n_{21}}\n\\tag{3.4}\\]\n맥나마 검정 통계량 \\(Q_{M}\\)은 귀무가설 하에서 근사적으로 자유도가 1인 카이제곱 분포를 따른다.\n다음은 1600명 영국 시민들의 수상에 대한 지지 여부를 두 개의 연속된 여론 조사에서 수집한 자료이다 (Agresti 2012 의 10장 참조). 이제 두 시점에서 수상에 대한 지지율이 같은지 아닌지 R 을 이용하여 맥나마 검정을 해보자. 맥나마 검정은 함수 mcnemar.test()를 사용하여 수행할 수 있다.\n\n\n\n그림 3.7: 영국시민의 수상에 대한 지지도 조사 자료\n\n\n\n\n\n\n\nex3dat &lt;- matrix(c(794,150,86,570),byrow=T,ncol=2)\nex3dat\n\n     [,1] [,2]\n[1,]  794  150\n[2,]   86  570\n\nmcnemar.test(ex3dat ,correct=F)\n\n\n    McNemar's Chi-squared test\n\ndata:  ex3dat\nMcNemar's chi-squared = 17.356, df = 1, p-value = 3.099e-05\n\n\n검정의 p-값이 매우 작으므로 귀무가설을 기각한다. 두 시점에서 수상에 대한 지지율이 하락했다고 할 수 있다. 참고로 첫 번째 조사에서의 지지율의 추정치는 \\(\\hat p_1=944/1600= 0.59\\) 이고 두 번째 조사에서의 지지율의 추정치는 \\(\\hat p_2=880/1600= 0.55\\) 이다. 또한 의견을 바꾸지 않은 사람의 비율은 \\((794+570)/1600=0.8225\\)로 대부분의 시민들이 지지 의견을 바꾸지 않았다.\n\n\n\n\nAgresti, Alan. 2012. Categorical data analysis. Vol 792. John Wiley & Sons.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/diagnose.html#민감도와-특이도",
    "href": "notes/diagnose.html#민감도와-특이도",
    "title": "4  진단의 평가",
    "section": "4.1 민감도와 특이도",
    "text": "4.1 민감도와 특이도\n진단 기법을 평가하는 경우 다음과 같은 두 질문에 대해서 생각해 보아야 한다.\n\n양성인 사람을 얼마나 잘 양성으로 판단하는가?\n음성인 사람을 얼마나 잘 음성으로 판단하는가?\n\n양성인 사람을 얼마나 잘 양성으로 판단하는지에 대한 평가 기준이 민감도(sensitivity) 이고 음성인 사람을 얼마나 잘 음성으로 판단하는지에 대한 평가 기준이 특이도(specificity) 이다. 민감도와 특이도의 정도는 확률로서 나타낼 수 있다.\n진단 기법에 대한 실험 연구를 수행하면 그 결과는 \\(2 \\times 2\\) 분할표로 다음과 같이 요약할 수 있다. 일반적으로 진단 기법의 효과를 측정하는 실험은 대상자에 대한 질병의 유무를 알고 시작한다.\n\n\n\n표 4.1: 진단 기법의 실험 결과\n\n\n\n\n\n진단(T) / 질병(D)\n양성 (\\(D+\\))\n음성 (\\(D-\\))\n\n\n\n\n양성 (\\(T+\\))\n\\(TP\\)\n\\(FP\\)\n\n\n음성 (\\(T-\\))\n\\(FN\\)\n\\(TN\\)\n\n\n\n\n\n\n위의 표에서 각 셀에 해당하는 진단 결과는 다음과 같이 나타낼 수 있다.\n\n\\(TP\\) : True Positive\n\\(FP\\) : False Positive\n\\(FN\\) : False Nagative\n\\(TN\\) : True Negative\n\n이제 분할표 표 4.1 에서 민감도와 특이도는 다음과 같이 정의된다.\n\\[\\begin{align}\n\\text{Sensitivity}(민감도) & = \\frac{TP}{TP+FN} \\\\\n\\text{Specificity}(특이도) & = \\frac{TN}{FP+TN}\n\\end{align}\\]\n다음은 코로나 바이러스 검사법에 대한 여러 연구에서 나온 민감도와 특이도 결과를 보여 준다 (Butler-Laporte 기타 (2021)).\n\n\n\n그림 4.1: 코로나 검사의 민감도와 특이도\n\n\n\n\n\n\n예제로서 그림 그림 4.1 에 제시한 종합적인 결과(pooled counts)를 이용하여 민감도와 특이도를 구해보자.\n\n\n\n표 4.2: 코로나 바이러스 검사법의 결과\n\n\n\n\n\n진단(T) / 질병(D)\n양성 (\\(D+\\))\n음성 (\\(D-\\))\n\n\n\n\n양성 (\\(T+\\))\n\\(664\\)\n\\(157\\)\n\n\n음성 (\\(T-\\))\n\\(120\\)\n\\(4981\\)\n\n\n\n\n\n\n민감도와 특이도는 다음과 같이 구할 수 있다.\n\\[\\begin{align*}\n\\text{Sensitivity} & = \\frac{664}{664+120} =  0.8469 \\\\\n\\text{Specificity} & = \\frac{4891}{157+4891} =  0.9689\n\\end{align*}\\]\n위에서 구한 민감도와 특이도는 Butler-Laporte 기타 (2021) 에서 제시한 민감도(83.2%), 특이도(99.2%) 와 유사하지만 약간의 차이가 있다. 그 이유는 Butler-Laporte 기타 (2021) 는 모든 실험 결과를 단순하게 더한 것이 아니라 메타분석(meta analysis)을 사용하여 얻은 결과이기 때문이다. 메타분석은 같은 주제에 대한 여러 개의 독립적인 연구 결과들을 결합하여 결론을 추론하는 연구 방법이다.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>진단의 평가</span>"
    ]
  },
  {
    "objectID": "notes/diagnose.html#양성예측도와-음성예측도",
    "href": "notes/diagnose.html#양성예측도와-음성예측도",
    "title": "4  진단의 평가",
    "section": "4.2 양성예측도와 음성예측도",
    "text": "4.2 양성예측도와 음성예측도\n앞에서 살펴본 민감도와 특이도를 구하는 실험에서는 실험 대상자가 질병이 있는지 없는지 알고 있다. 하지만 실제 검사는 진단을 받는 사람이 질병이 있는지 모르는 상태에서 진행된다.\n따라서 우리가 정말 관심 있는 확률은 양성으로 진단된 사람이 실제로 양성인지?에 대한 확률이다.\n양성으로 판정되었을 때 실제로 병에 걸렸을 확률을 양성예측도(\\(PV+\\)) (predicted value of positive test, predictive value positive) 라고 부르며 음성으로 판정되었을 때 실제로 병에 걸리지 않았을 확률을 음성예측도(\\(PV-\\)) (predicted value of negative test, predicted value negative) 라고 부른다. 양성예측도와 음성예측도는 조건부 확률로 표현할 수 있다.\n\\[\\begin{align}\nPV+ & = P( D+ | T+) \\\\\nPV- & = P( D- | T-)\n\\end{align}\\]\n이제 앞에서 살펴본 민감도와 특이도도 다음과 같이 조건부 확률로 나타낼 수 있다.\n\\[\\begin{align}\n\\text{Sensitivity} & =  P(T+|D+) \\\\\n\\text{Specificity} & =  P(T-|D-)\n\\end{align}\\]\n이제 실제로 중요한 양성예측도와 음성예측도를 민감도와 특이도를 이용하여 유도해 보자. 두 확률은 사건과 조건이 바뀐 확률이기 때문에 베이즈 정리(Bayes’ Theorem)을 이용하여 구할 수 있다.\n일단 양성예측도를 구하는 식을 베이즈 정리를 적용하여 유도해 보자.\n\\[\nP( D+ | T+)  = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) +  P(T+|D-)P(D-)}\n\\]\n위의 식에서 나타나는 확률 \\(P(D+)\\) 는 모집단에서 질병에 걸린 사람들의 비율을 의미하며 이를 유병률(prevalence) 이라고 부른다. 즉 양성예측도를 구하려면 질병의 유병률을 알아야 한다.\n다시 식을 정리해 보면 양성예측도에 대한 공식은 다음과 같다.\n\\[\\begin{align}\nP( D+ | T+)  & = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) +  P(T+|D-)P(D-)} \\\\\n         & = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) + [1- P(T-|D-)][1-P(D+)]} \\\\\n         & = \\frac{(민감도)(유병률)}{(민감도)(유병률) + (1-특이도)(1-유병률)}\n\\end{align}\\]\n비슷한 계산 방법으로 음성예측도는 다음과 같이 주어진다.\n\\[\\begin{align}\nP( D - | T -)  & = \\frac{ P(T -|D -)P(D -)} {  P(T-|D-)P(D-) +  P(T-|D+)P(D+)} \\\\\n         & = \\frac{ P(T-|D-)[1-P(D+)]} {  P(T-|D-)[1-P(D+)] + [1- P(T+|D-)] P(D+)} \\\\\n         & = \\frac{(특이도)(1- 유병률)}{(특이도)(1-유병률) + (1-민감도)(유병률)}\n\\end{align}\\]\n이제 표 표 4.2 의 결과를 이용하여 코로나 검사의 양성예측도와 음성예측도를 구해보자.\n코로나 유병률은 나라마다 다르고 추정하기도 힘들다. 따라서 쉽게 현재 까지 누적환자수를 전체 인구로 나눈 단순한 비율을 유병률로 사용해 보자(주의! 우리가 여기서 사용한 비율은 실제 유병률을 계산하는 방법과 다르다). 2021년 현재 누적 환자 수가 274,415 명이고 2020년 기준 총인구는 51,829,136 명이므로 유병률을 \\(274415/51829136= 0.0053\\) 이라고 하자.\n이제 표 표 4.2 의 결과를 이용하면 코로나 검사의 양성예측도와 음성예측도는 다음과 같이 추정할 수 있다.\n\\[\\begin{align*}\nP( D+ | T+)  & = \\frac{(민감도)(유병률)}{(민감도)(유병률) + (1-특이도)(1-유병률)} \\\\\n     & = \\frac{(0.8469 )(0.0053)}{(0.8469 )(0.0053) + (1-0.9689)(1-0.0053)} \\\\\n     & = 0.1267\n\\end{align*}\\]\n\n(0.8469 )*(0.0053)/((0.8469 )*(0.0053) + (1-0.9689)*(1-0.0053))\n\n[1] 0.1267108\n\n\n\\[\\begin{align}\nP( D - | T -)  & = \\frac{(특이도)(1- 유병률)}{(특이도)(1-유병률) + (1-민감도)(유병률)}\\\\\n& = \\frac{(0.9689)(1- 0.0053)}{(0.9689)(1-0.0053) + (1-0.8469)(0.0053)} \\\\\n& = 0.9992\n\\end{align}\\]\n\n(0.9689)*(1- 0.0053)/((0.9689)*(1-0.0053) + (1-0.8469)*(0.0053))\n\n[1] 0.9991588\n\n\n사실 코로나 유병률은 정확하게 알 수도 없고 시간에 따라 변할 것이다. 이제 다양한 유병률에 따라서 양성예측도와 음성예측도가 어떻게 변하는지 계산해 보자.\n\ncalpred &lt;- function(prev, sen, spe){\n    pred.pos &lt;- sen*prev/(sen*prev + (1-spe)*(1-prev))\n  pred.neg &lt;- spe*(1-prev)/(spe*(1-prev) + (1-sen)*(prev))\n  res &lt;- data.frame(sen, spe, prev, pred.pos, pred.neg)\n  colnames(res) &lt;- c(\"Sensitivity\", \"SPecificity\",\"Prevalnce\", \"Pred. Post.\", \"Pred. Nega.\")\n  res\n}\n\npreval.range &lt;- seq(0, 0.02, 0.002)\ncalpred(preval.range ,0.8469, 0.9689 )\n\n   Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1       0.8469      0.9689     0.000  0.00000000   1.0000000\n2       0.8469      0.9689     0.002  0.05174816   0.9996834\n3       0.8469      0.9689     0.004  0.09858220   0.9993658\n4       0.8469      0.9689     0.006  0.14117039   0.9990471\n5       0.8469      0.9689     0.008  0.18006506   0.9987273\n6       0.8469      0.9689     0.010  0.21572673   0.9984064\n7       0.8469      0.9689     0.012  0.24854242   0.9980845\n8       0.8469      0.9689     0.014  0.27883973   0.9977614\n9       0.8469      0.9689     0.016  0.30689786   0.9974372\n10      0.8469      0.9689     0.018  0.33295620   0.9971120\n11      0.8469      0.9689     0.020  0.35722119   0.9967856\n\n\n\ncalpred(0.0053, 0.8469, 0.9689  )\n\n  Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1      0.8469      0.9689    0.0053   0.1267108   0.9991588\n\n\n\n\n\n\nButler-Laporte, Guillaume, Alexander Lawandi, Ian Schiller, Mandy Yao, Nandini Dendukuri, Emily G McDonald, 와/과 Todd C Lee. 2021. “Comparison of saliva and nasopharyngeal swab nucleic acid amplification testing for detection of SARS-CoV-2: a systematic review and meta-analysis”. JAMA Intern Med 181 (3): 353–58.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>진단의 평가</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#필요한-패키지",
    "href": "notes/logistic.html#필요한-패키지",
    "title": "5  로지스틱 회귀모형",
    "section": "5.1 필요한 패키지",
    "text": "5.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#이항변수-예제",
    "href": "notes/logistic.html#이항변수-예제",
    "title": "5  로지스틱 회귀모형",
    "section": "5.2 이항변수: 예제",
    "text": "5.2 이항변수: 예제\n먼저 R을 이용한 로지스틱 회귀분석을 소개하기 위하여 다음의 예제를 이용하고자 한다.\n\n5.2.1 챌린져호 O-ring 자료\n1986년 미국우주항공국(NASA)이 발사한 우주왕복선 챌린져호(Spache Shuttle Challenger)가 로켓 엔진에 주요부품인 O-rings의 손상으로 인하여 공중에서 폭팔하는 사고가 일어났다. 다음 데이타는 미국우주항공국이 챌린져호를 발사하기 전에 실험을 통하여 얻은자료이다. 디음의 자료는 교과서의 R package faraway에서 orings에서 볼 수 있다.\n\n#data(orings)\norings %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\ntemp\ndamage\n\n\n\n\n53\n5\n\n\n57\n1\n\n\n58\n1\n\n\n63\n1\n\n\n66\n0\n\n\n67\n0\n\n\n67\n0\n\n\n67\n0\n\n\n68\n0\n\n\n69\n0\n\n\n70\n1\n\n\n70\n0\n\n\n70\n1\n\n\n70\n0\n\n\n72\n0\n\n\n73\n0\n\n\n75\n0\n\n\n75\n1\n\n\n76\n0\n\n\n76\n0\n\n\n78\n0\n\n\n79\n0\n\n\n81\n0\n\n\n\n\n\n\n\n위의 자료에서 temp는 실험에서 적용된 온도(화씨 F)이고 damage는 각 실험마다 6개의 링중에서 손상된 개수를 나타낸다. 참고로 1986년 챌린져호가 발사될 때의 온도는 31F 였다.\n먼저 그림을 통하여 온도의 변화에 따른 손상비율을 살펴보자.\n\nplot(damage/6 ~ temp, orings, xlim=c(25,85), ylim = c(0,1), xlab=\"Temperature\", ylab=\"Prob of damage\")\n\n\n\n\n\n\n5.2.2 강풍에 의한 나무 피해 자료\n1999년 미국 Misnnesota주의 Boundary Waters Canoe Area Wilderness (BWCAW)에서 심한 폭풍으로 생긴 강한 바람에 의해 쓰러진 나무들에 대한 자료를 수집하였다. 이 자료는 Weisberg (2014) (R package alr4) 에 수록된 자료이다.\n연구의 목적은 폭풍이 나무의 생존에 미치는 영향을 알아보는 것이다. 666 그루의 나무들에 대하여 나무가 바람에 의해 쓰러저 죽었는지 여부, 나무의 종, 나무의 지름, 폭풍의 국지적인 강도에 대한 자료를 수집하였다.\n\nd: Tree diameter, in cm\ns : Proportion of basal area killed for the four species balsam fir, cedar, paper birch and blue spruse, a measure of local severity of the storm.\nspp : Tree species, a factor with 9 levels\ny : 1 if the tree died, 0 if it survived\n\n\nhead(Blowdown) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ns\ny\nspp\n\n\n\n\n9\n0.0217509\n0\nbalsam fir\n\n\n14\n0.0217509\n0\nbalsam fir\n\n\n18\n0.0217509\n0\nbalsam fir\n\n\n23\n0.0217509\n0\nbalsam fir\n\n\n9\n0.0217509\n0\nbalsam fir\n\n\n16\n0.0217509\n0\nbalsam fir\n\n\n\n\n\n\n\n반응변수 \\(y\\) 를 쓰러진 나무는 \\(y=1\\)로하고 살아남은 나무를 \\(y=0\\)으로 코딩하였다. 나무의 상태 y에 나무의 지름 d이 미치는 영향을 살펴보려고 한다.\n수집된 자료중에서 나무의 종류가 black spruce인 자료만를 분석하기로 한다. 아래 코드는 black spruce인 자료만를 모아서 데이터프레임 BlowBS_raw 를 만드는 것이다.\n\nBlowBS_raw &lt;- Blowdown %&gt;% dplyr::filter(spp=='black spruce')\n\ndim(BlowBS_raw)\n\n[1] 659   4\n\nhead(BlowBS_raw) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ns\ny\nspp\n\n\n\n\n9\n0.0242120\n0\nblack spruce\n\n\n11\n0.0305947\n0\nblack spruce\n\n\n9\n0.0305947\n0\nblack spruce\n\n\n9\n0.0341815\n0\nblack spruce\n\n\n5\n0.0341815\n0\nblack spruce\n\n\n8\n0.0341815\n0\nblack spruce\n\n\n\n\n\n\n\n아래 그림은 쓰러진 나무와 살아남은 나무들의 지름의 분포를 비교한 것이다. 이를 통하여 지름이 큰 나무가 살아남을 확률이 더 커짐을 알수 있다.\n\nsm.density.compare(BlowBS_raw$d, BlowBS_raw$y,lty=c(1,2), xlab=\"D\")\nlegend(30,.1,legend=c(\"Y=0\",\"Y=1\"),lty=c(1,2))\n\n\n\n\n\nsm.density.compare(log(BlowBS_raw$d), BlowBS_raw$y,lty=c(1,2), xlab=\"log(D)\")\nlegend(3.2,.9,legend=c(\"Y=0\",\"Y=1\"),lty=c(1,2))\n\n\n\n\n또한 R package alr4 에 수록된 데이터셋 BlowBS 는 위에서 본 O-rings 예제와 동일하게 black spruce인 자료만 모아서 전체 횟수와 성공의 횟수로 요약된 자료이다.\n\nhead(BlowBS) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ndied\nm\n\n\n\n\n5.0\n6\n88\n\n\n5.5\n1\n2\n\n\n6.0\n6\n91\n\n\n6.5\n1\n1\n\n\n7.0\n17\n90\n\n\n7.5\n1\n1\n\n\n\n\n\n\n\n\nd :Tree diameter, in cm\ndied : Number of trees of this value of d that died (blowdown)\nm : number of trees of this size class measured\n\n이제 데이터셋 BlowBS 를 이용하여 나무의 지름과 나무 피해의 관계에 대해서 살펴보자.\n\nplot( died/m~ d, BlowBS, ylim = c(0,1), xlab=\"D\", ylab=\"Prob of Blow Down\")\n\n\n\n\n나무의 지름 \\(d\\)을 \\(\\log(d)\\)로 변환하여 예측변수(predictor) \\(x\\)로 하려고 한다.\n\nplot( died/m~ I(log(d)), BlowBS, ylim = c(0,1), xlab=\"log(D)\", ylab=\"Prob of Blow Down\")\n\n\n\n\n나무의 상태 \\(y\\)는 두 가지의 반응 결과를 가지는 이항변수이고 그 평균 \\(E(y)\\)는 0과 1사이의 값을 가지는 확률이지만 나무의 지름 \\(x=\\log(D)\\)는 연속형 변수이다.\n이러한 경우에 회귀분석의 모형은 어떻게 세울까?에 대하여 생각해보자.\n\\[ 0 \\le E(y|x) = p(x) \\le 1, \\quad \\quad -\\infty &lt; \\beta_0 + \\beta_1 x &lt; \\infty \\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#로지스틱-회귀모형",
    "href": "notes/logistic.html#로지스틱-회귀모형",
    "title": "5  로지스틱 회귀모형",
    "section": "5.3 로지스틱 회귀모형",
    "text": "5.3 로지스틱 회귀모형\n\n5.3.1 이항변수와 연결함수\n일반적으로 지금까지 배워온 회귀분석의 확률 모형에서는 반응변수 \\(y\\)는 연속형 확률변수이다. 따라서 예측변수 \\(x\\)의 값과 반응변수의 관계를 다음과 같은 회귀식으로 설명한다.\n\\[ E(y|x) =  \\beta_0 + \\beta_1 x  \\tag{5.1}\\]\n하지만 앞에서 살펴본 예제에서와 같이 반응변수의 값이 연속형 변수가 아니라 두 개의 가능한 결과만을 가지는 이항변수라면 위에서 주어진 회귀식은 적절하지 못하다.\n\\[\ny =\n\\begin{cases}\n1 & \\text{ with probabilty } p \\\\\n0 & \\text{ with probabilty } 1-p\n\\end{cases}\n\\]\n왜냐하면 반응변수의 기대값이 0과 1사이의 확률로 나타나기 때문이다.\n\\[ E(y|x) = 1\\cdot P(y=1|x) + 0 \\cdot P(y=0|x) = P(y=1|x) \\]\n따라서 반응변수의 기대값의 범위와 예측변수가 있는 선형예측식(linear predictor) \\(\\beta_0 + \\beta_1 x\\)의 범위가 일치하지 않아서 선형회귀식 식 5.1 을 그대로 사용할 수 없다.\n\n\n\n\n범위의 불일치\n\n\n\n\n\n위의 문제를 해결하기 위한 방법중의 하나는 다음과 같은 함수 \\(m\\)를 생각하여 변환된 선형예측식의 범위를 \\([0,1]\\)로 만드는 것이다.\n\\[ m:\\Re \\rightarrow [0,1]  \\quad \\text{and } \\quad m(x) \\text{ is monotone function}. \\]\n따라서 다음과 같은 이항변수를 반응변수로 하는 새로운 회귀식을 만들 수있다.\n\\[  E(y|x) = m(\\beta_0 + \\beta_1 x)  \\tag{5.2}\\]\n주로 쓰이는 변환함수로 다음과 같은 로지스틱 함수(logistic function)가 있다.\n\\[ m(x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) }  \\tag{5.3}\\]\n반응변수가 베르누이 분포를 따를 때 위의 로지스틱홤수를 사용하는 회귀식을 로지스틱 회귀식이라고 한다.\n\\[\nP(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\{ 1+ \\exp[-(\\beta_0 + \\beta_1 x)] \\}^{-1}\n\\tag{5.4}\\]\n위의 로지스틱 회귀식을 다시 역으로 정리하면 다음과 같은 식을 얻을 수 있다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] = \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x\n\\tag{5.5}\\]\n식 식 5.5 에서 나타난 함수 \\(g\\),\n\\[ g(p)=\\log \\frac{p}{1-p} \\]\n를 로짓함수(logit function) 라고 부르며 이는 로지스틱 함수의 역함수로서 0과 1 사이의 값을 가지는 확률을 실수 전체로 변환하는 함수로서 선형 예측식의 범위와 일치하게 한다.\n\n\n\n\n로지스틱 연결함수\n\n\n\n\n\n이렇게 관측값의 평균 (베르누이분포에서는 성공확률)과 선형예측식의 관계를 설정하는 함수를 연결함수(link function) 라고 하며 \\(g\\) 라고 표시한다.\n\\[\ng[E(y|x)] = g[p(x)] =  \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x\n\\tag{5.6}\\]\n따라서 로짓함수는 연결함수의 하나이며 다른 종류의 연결함수도 생각할 수 있다. 예를 들어 \\(\\Phi(x)=P(Z \\le x)\\)를 표준정규분포의 분포함수라 한다면 다음과 같은 연결함수를 생각할 수 있고 이를 probit 함수라고 부른다.\n\\[ g[p(x)] = \\Phi^{-1}(p(x)) = \\beta_0 + \\beta_1 x \\]\n만약 예측변수가 하나가 아닌 \\(p\\)개라면, 즉 예측변수 \\({\\pmb x}=(x_1,x_2,\\dots,x_{p})^t\\) 에 대한 로지스틱 회귀모형은 다음과 같이 확장할 수 있다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1 | x)} \\right  ] = \\pmb x^t \\pmb \\beta = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_2 +  \\dots \\beta_p x_{p}\n\\]\n\n\n5.3.2 예제\n위의 o-ring 예제(섹션 5.2.1)에서 성공(\\(y=1\\))은 O-ring이 손상된 경우이며 주어진 온도 \\(x\\)에서의 손상확률을 \\(p=(Y=1|x)=p(x)\\)라고 하면 다음과 같은 로지스틱회귀식을 생각할 수 있다.\n\\[ \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x \\]\n다음과 같은 함수 glm을 이용하여 위의 로지스틱 회귀식을 적합할 수 있다.\n\nlogit1 &lt;- glm(cbind(damage,6-damage) ~ temp, family=binomial, orings)\nsummary(logit1)\n\n\nCall:\nglm(formula = cbind(damage, 6 - damage) ~ temp, family = binomial, \n    data = orings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 11.66299    3.29626   3.538 0.000403 ***\ntemp        -0.21623    0.05318  -4.066 4.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.898  on 22  degrees of freedom\nResidual deviance: 16.912  on 21  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 6\n\ncoef(logit1)\n\n(Intercept)        temp \n 11.6629897  -0.2162337 \n\n\n위의 결과에서 회귀식 기울기의 추정치는 \\(\\hat \\beta=\\) -0.2162337이다. 따라서 다음과 같은 회귀식을 얻을 수 있다.\n\\[ \\log \\frac{p(x)}{1-p(x)}=11.6629897+ (-0.2162337) x \\] 위의 회귀식을 이용하여 추정된 고장확률을 그림으로 그려보면 다음과 같다.\n여기서 ilogit은 로짓함수의 역함수를 계산해주며 다음과 같이 주어진 회귀식을 이용하여 확률을 계산한다.\n\\[ P(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\frac{1}{ 1+ \\exp[-(11.6629897+ (-0.2162337) x)] }\\]\n\nplot(damage/6 ~ temp, orings, xlim=c(25,85), ylim = c(0,1), xlab=\"Temperature\", ylab=\"Prob of damage\")\nx &lt;- seq(25,85,1)\nlines(x,ilogit(coef(logit1)[1]+coef(logit1)[2]*x))\n\n\n\n\n또한 온도가 31F인 경우 고장확률의 추정값은 \\(\\hat p =\\) 0.9930342이며 R 에서 다음과 같이 계산한다.\n\nx &lt;- 31\nilogit(coef(logit1)[1]+coef(logit1)[2]*x)\n\n(Intercept) \n  0.9930342 \n\n\n이제 강풍에 의한 나무의 피해에 대한 예제(섹션 5.2.2)에 대하여 로지스틱 회귀식을 적합해보자.나무의 상태 \\(y\\) 가 이항 변수이고 나무의 지름 \\(x=\\log(d)\\)을 예측변수로 하는 로지스틱회귀 모형을 고려하고 추정해보면 다음과 같은 회귀식을 얻는다\n\nlogit2 &lt;- glm(y~ I(log(d)),family=binomial(),data=BlowBS_raw)\nsummary(logit2)\n\n\nCall:\nglm(formula = y ~ I(log(d)), family = binomial(), data = BlowBS_raw)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -7.8925     0.6325  -12.48   &lt;2e-16 ***\nI(log(d))     3.2643     0.2761   11.82   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 856.21  on 658  degrees of freedom\nResidual deviance: 655.24  on 657  degrees of freedom\nAIC: 659.24\n\nNumber of Fisher Scoring iterations: 4\n\n\n\\[ \\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ]  =-7.892464+ (3.2642653) x \\] 위의 회귀식을 이용하여 추정된 나무가 부러져서 피해를 입을 확률은 다음과 같다.\n\\[ P(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\frac{1}{ 1+ \\exp[-(-7.892464+ (3.2642653) x)] }\\] 이제 나무의 지름에 변화에 대하여 나무가 부러져서 피해를 입을 확률의 추정값을 그림으로 그려보자.\n\nplot( died/m~ I(log(d)), BlowBS, ylim = c(0,1), xlab=\"log(D)\", ylab=\"Prob of Blow Down\")\nx &lt;- seq(0,3.5,0.1)\nlines(x,ilogit(coef(logit2)[1]+coef(logit2)[2]*x))\n\n\n\n\n\n\n5.3.3 회귀계수의 해석\n일반적인 회귀분석의 모형 식 5.1 에서 계수 \\(\\beta_1\\)은 기울기로서 예측변수 \\(x\\)의 단위가 1 증가할 때 반응변수의 평균이 \\(\\beta_1\\)만큼 증가하는 것으로 해석할 수 있다. 하지만 로지스틱 회귀모형 식 5.4 에서는 이러한 해석을 할 수 없다.\n로지스틱 회귀모형에서 기울기 \\(\\beta_1\\)의 의미를 알아보기 위하여 예측변수 \\(x\\) 에 대한 베르누이 변수 \\(y\\)의 성공 확률 \\(P(y=1|x)\\)에 대한 오드(odd)를 정의하자.\n\\[ odd(x) = \\frac{P(y=1|x)}{1-P(y=1|x)} \\]\n이제 단순 로지스틱 회귀식 식 5.5 을 생각하고 예측변수 \\(x\\)를 0과 1의 값을 가지는 이항변수로 가정한다.\n\\(x=1\\) 인 경우는\n\\[  \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}  = \\exp( \\beta_0 + \\beta_1)  \\]\n이며 \\(x=0\\) 인 경우는\n\\[ \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} = \\exp(\\beta_0)   \\]\n위에서 주어진 두 개의 오드, 즉 \\(x=1\\)인 경우와 \\(x=0\\)인 경우의 두 오드의 비(odd ratio)를 구하면 다음과 같다.\n\\[   \\frac{ \\frac{P(y=1|x=1)}{1-P(y=1|x=1)} } {\\frac{P(y=1|x=0)}{1-P(y=1|x=0)}}  = \\exp (\\beta_1) \\]\n이는 다시 쓰면\n\\[   \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}   = \\exp (\\beta_1) \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} \\]\n위의 식에서 볼 떄 예측변수 \\(x\\)가 1 의 값을 가질 때 반응 변수의 오드가 예측변수 \\(x\\)가 0일 경우의 오드의 \\(\\exp (\\beta_1)\\)배로 변하는 것을 알 수 있다.\n따라서 \\(\\exp (\\beta_1)\\)는 반응변수의 오드의 증가량으로 볼 수 있다. 이는 두 성공확률의 오즈비가 \\(\\exp (\\beta_1)\\)을 말한다. 위의 식에 로그를 취하면 다음과 같은 관계를 얻는다.\n\\[  \\log   \\left [ \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}  / \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} \\right ]  = \\beta_1 \\]\n즉 오즈비의 로그값이 단순 로지스틱 회귀식에서 기울기 \\(\\beta_1\\)으로 나타난다.\n간단한 예제를 통하여 오즈비와 로지스틱 회귀의 기울기의 관계를 명확히 해보자. 100명의 사람들을 55세 이상의 사람(\\(x=1\\))과 55세 미만의 사람(\\(x=0\\))의 그룹으로 나누었을 떄 각 그룹에서 만성심장질환(CHD)가 있는 사람(\\(y=1\\))과 없는 사람(\\(y=0\\))의 수가 표 표 5.1 에 주어져있다.\n\n\n\n표 5.1: 나이와 만성심장질환의 관계\n\n\n\n\n\nCHD/나이\n나이 \\(\\ge 55\\) (\\(x=1\\))\n나이 \\(&lt; 55\\) (\\(x=0\\))\n합계\n\n\n\n\nCHD 있음 \\(y=1\\)\n21\n22\n43\n\n\nCHD 없음 \\(y=0\\)\n6\n51\n57\n\n\n합계\n27\n73\n100\n\n\n\n\n\n\n여기서 나이에 대한 CHD 유무의 오즈비는 다음과 같이 계산된다.\n\\[ \\text{Odds Ratio } = \\frac{ \\tfrac{21/27}{6/27}}{ \\tfrac{22/73}{51/73}} =  \\frac{(21)(51)}{(6)(22)} = 8.11 \\]\n위의 표 표 5.1 의 자료를 이용하여 로지스틱회귀를 적합시키면 결과가 아래와 같고 회귀계수 \\(\\beta_1\\)의 추정값은 오즈비의 로그값임을 알 수 있다.\n\\[ \\hat \\beta_1 = \\log (8.11) = 2.094  \\]\n표 표 5.1 의 자료에 대하여 로지스틱 회귀모형은 다음과 같이 적합할 수 있다.\n\nyes &lt;- c(21,22)\nno  &lt;- c(6,51)\nx &lt;- c (1,0)\nm1 &lt;- glm( cbind(yes,no) ~ x, family=binomial() )\nsummary(m1)\n\n\nCall:\nglm(formula = cbind(yes, no) ~ x, family = binomial())\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.8408     0.2551  -3.296  0.00098 ***\nx             2.0935     0.5285   3.961 7.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1.8704e+01  on 1  degrees of freedom\nResidual deviance: 1.4211e-14  on 0  degrees of freedom\nAIC: 11.987\n\nNumber of Fisher Scoring iterations: 3",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#추정과-검정",
    "href": "notes/logistic.html#추정과-검정",
    "title": "5  로지스틱 회귀모형",
    "section": "5.4 추정과 검정",
    "text": "5.4 추정과 검정\n\n5.4.1 이항분포와 가능도 함수\n주어진 예측변수 \\(x_i\\)에서 실행횟수가 \\(m_i\\)인 이항분포\\(B(m_i, p(x_i))\\)를 생각하자. \\(m_i\\)의 시행 중에 성공의 횟수가 \\(y_i\\)라고 하면 \\(y_i\\)의 확률밀도함수는 다음과 같다.\n\\[ {{m_i}\\choose{y_i}} {p(x_i)}^{y_i} [(1-p(x_i)]^{m_i-y_i} \\]\n그리고 \\(y_i\\)의 평균과 분산은 다음과 같다.\n\\[ E(y_i | x_i ) = m_i p(x_i), \\quad \\quad Var(y_i | x_i) = m_i p(x_i) [1-p(x_i)] , \\quad i=1,2,\\dots,n \\]\n이항분포를 위한 로지스틱 회귀방정식은 선형예측식과 성공의 확률의 관계를 다음과 같이 정한다.\n\\[ \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] =  \\beta_0 + \\beta_1 x_{i}  \\]\n서로 독립인 관측값 \\((y_1,y_2,\\dots,y_n)\\)의 가능도함수(likelihood function) \\(L\\)은 이항분포들의 결합확률밀도함수와 같고 아래와 같이 주어지며\n\\[ L = \\prod_{i=1}^n f(y_i|p(x_i)) = \\prod_{i=1}^n \\left [  {{m_i}\\choose{y_i}} \\right] {p(x_i)}^y_i {(1-p(x_i))}^{m-y_i}\n\\]\n로그가능도함수(log likelihood function) \\(l\\) 은 다음과 같이 나타낼 수 있다.\n\\[\\begin{align}\nl  & = \\log L \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log p(x_i) + \\sum_i (m_i -y_i) \\log [1-p(x_i)]  \\notag  \\\\\n   & = c(\\pmb y,\\pmb m) + \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)]  \\end{align}\\]\n결론적으로\n\\[ l(\\pmb \\mu|\\pmb y)  = \\log L(\\pmb \\mu|\\pmb y) =  c(\\pmb y,\\pmb m) + \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)]   \\tag{5.7}\\]\n위의 로그가능도함수에서 볼 수 있듯이 충분통계량인 성공의 횟수 \\(y_i\\)와 곱으로 나타내어진 함수가 로짓함수이며 이렇게 가능도함수에서 얻어진 결합함수를 자연 연결함수(natural link function)이라고 한다.\n회귀계수의 추정량은 최대가능도 추정법을 이용하여 구할 수 있으며 로그 가능도 함수가 회귀계수에 대하여 비선형이므로 반복을 이용한 계산법에 의하여 추정량을 얻을 수 있다.\n\\[ \\max_{\\pmb \\beta } \\log L = \\max_{\\pmb \\beta } \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)] \\]\n\n\n5.4.2 편차\n선형모형에서 잔차제곱합(residual sum of square; SSE)에 대한 의미를 살펴보고 이를 일반화 선형모형에 확장하는 개념인 편차(deviance)의 정의를 알아보자.\n먼저 다음과 같은 선형회귀식을 고려한다.\n\\[ y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots \\beta_p x_{pi} + e_i , \\quad i=1,2,\\dots,n \\]\n여기서 오차항 \\(e_i\\)를 서로 독립이며 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규분포를 따른다고 가정하고 (\\(\\sigma^2\\)는 알고있다고 가정하자) 각 관측변수의 평균을 다음과 같이 \\(\\mu_i\\)로 하자.\n\\[   \\mu_i =E(y_i|x_i)= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots +\\beta_p x_{pi} \\]\n서로 독립인 관측변수 \\(y_i\\)의 분포는 정규분포를 따르므로\n\\[ y_i \\sim N(\\mu_i,\\sigma^2)   \\]\n관측치 \\(\\pmb y=(y_1,y_2,\\dots,y_n)^t\\)의 로그가능도함수는 다음과 같이 나타낼 수 있다.\n\\[ l(\\pmb \\mu|\\pmb y) = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu_i)^2 \\]\n예측변수 \\(x_1,x_2,\\dots,x_p\\)를 고려한 선형회귀모형에서 각 반응변수 평균의 예측식은 다음과 같다.\n\\[ \\hat \\mu_i = \\hat \\beta_0 + \\hat \\beta_1 x_{1i} + \\hat \\beta_2 x_{2i} + \\dots +\\hat \\beta_p x_{pi} \\equiv \\hat y_i \\]\n이 때 선형회귀모형의 로그가능도함수의 최대값는 다음과 같다.\n\\[\\begin{align*}\nl(\\hat{\\pmb \\mu}|\\pmb y) & = l_{regession}(\\hat {\\pmb \\beta}|y) \\\\\n& = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat \\mu_i)^2  \\\\\n  &= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2  \\\\\n   &= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} SSE\n\\end{align*}\\]\n이제 위의 선형회귀모형에서 예측변수 \\(x_1,x_2,\\dots,x_p\\)를 고려하지 않는 포화 모형을 생각해보자.\n\\[ y_i = \\beta_{0i} +e_i \\quad \\text{or} \\quad E(y_i) = \\beta_{0i} \\]\n이러한 포화 모형은 \\(n\\)개의 반응변수의 평균을 \\(n\\)개의 모수를 가진 모형으로 추정하는 것으로 위와 같은 모형을 포화 모형(saturated model)이라고 한다. 포화 모형에서 모수 \\(\\beta_{0i}\\)의 최소제곱 추정량(또는 최대가능도 추정량)는 관측값 \\(y_i\\)임을 쉽게 알수 있다.\n\\[ \\min_{\\beta_{0i}} \\sum_{i=1}^n (y_i -\\beta_{0i})^2 \\quad \\Rightarrow \\hat \\beta_{0i} = y_i, \\quad i=1,2,\\dots,n\n\\]\n포화 모형의 의미는 우리가 생각할 수 있는 모형 중에 가장 큰 모형으로 포화모형보다 큰 모형을 생각할 수 없다. 위에서 언급한 바와 같이 \\(n\\)개의 관측값에 대하여 모수의 수가 \\(n\\)개보다 큰 모형을 생각하면 유일한 모수의 추정이 불가능하다.\n선형회귀모형에서 포화모형은 \\(\\hat \\beta_{0i}=y_i\\)이며 로그가능도함수의 최대값은 \\(l(\\pmb y | \\pmb y)\\)로 표시하며 다음과 같다.\n\\[\\begin{align*}\nl(\\pmb y | \\pmb y) & = l_{saturated}(\\hat {\\pmb \\beta_{0}} | y) \\\\\n& = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat \\beta_{0i})^2  \\\\\n&= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - y_i)^2  \\\\\n   &= C -\\frac{n}{2} \\log \\sigma^2 + 0\n\\end{align*}\\]\n포화모형은 설정할 수 있는 최대의 모수를 가진 가장 큰 모형이므로 우리가 생각할 수 있는 모형 중에서 관측값을 예측하는 예측력은 가장 좋다는 것을 알 수 있다(하지만 과적합모형이다).\n따라서 예측변수 \\(\\pmb x\\)들을 사용하는 선형회귀모형의 예측력이 포화모형이 가지는 예측력에 가까우면 좋은 모형이라고 생각할 수 있다. 반응변수의 평균을 예측하는 예측력은 로그가능도함수의 크기로서 나타낼 수 있다. 포화모형과 선형회귀모형의 로그가능도함수를 비교하면 포화모형의 로그가능도함수가 크다는 것을 알수 있고 (why?) 두 로그가능도함수의 의 차이를 비교하면 다음과 같다.\n\\[\nl(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) = l_{saturated}(\\hat {\\pmb \\beta_{0}} | y) -l_{regession}(\\hat {\\pmb \\beta}|y) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2 = \\frac{1}{2\\sigma^2}  SSE\n\\]\n위의 식을 가능도 함수의 비율로 다음과 같이 나타낼 수 있다.\n\\[ 2 \\log \\frac{L_{saturated}}{L_{regession}} =\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2 = \\frac{1}{\\sigma^2}  SSE  \\]\n따라서 포화모형과 로그가능도함수의의 차이가 작다는 것은 선형회귀모형의 잔차제곱합(SSE)이 작다는 것을 의미한다. 보통 잔차제곱합이 작으면 선형회귀모형의 예측력이 좋은 모형이며 이는 선형회귀모형의 가능도함수가 포화모형의 가능도함수에 가깝다는 의미이다.\n이렇게 모형의 예측능력을 평가하는 측도로서 편차(deviance)를 포화모형과 고려한 회귀모형의 로그가능도함수의 차이에 2를 곱한 양으로 정의한다. 따라서 편차는 작을 수록 좋다.\n\\[ deviance \\equiv D(\\pmb y;\\hat {\\pmb \\mu}) = 2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] = 2 \\log \\frac{L_{saturated}}{L_{regession}}\n\\tag{5.8}\\]\n정규분포인 경우 편차는 다음과 같이 주어진다.\n\\[\nD(\\pmb y;\\hat {\\pmb \\mu}) = 2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] =\n\\frac{1}{\\sigma^2}  SSE \\]\n이제 이항분포들에서 나온 관측값에 대한 포화모형을 생각해 보자.\n\\[ y_i \\sim B(m_i, p_i(x_i)), \\quad i=1,2,\\dots,n \\]\n위의 모형에서 포화모형은 어떤 모형일까? 포화모형은 \\(n\\)개의 관측변수의 평균, 여기서 \\(E(y_i/m_i) = p(\\pmb x_i)\\)를 \\(n\\)개의 관측치 \\(y_i\\)를 이용하여 추정한 모형으로서 각 성공확률은 해당하는 관측된 성공의 비율에 의해 추정된다. 즉,\n\\[ \\hat p(x_i) = \\frac{y_i}{m_i} \\]\n이러한 경우의 로그가능도함수의 값은 다음과 같이 주어진다.\n\\[\\begin{align*}\nl(\\pmb y | \\pmb y)  & =l_{saturated} \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log \\hat p(x_i) + \\sum_i (m_i -y_i) \\log (1- \\hat p(x_i))  \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log  \\frac{y_i}{m_i} + \\sum_i (m_i -y_i) \\log (1- \\frac{y_i}{m_i})\n\\end{align*}\\]\n따라서 위에서 주어진 포화함수의 로그가능도함수에서 로지스틱회귀식의 로그가능도함수 식 5.7 를 빼고 2를 곱해서 편차를 정의할 수 있다.\n\\[\\begin{align*}\nD(\\pmb y;\\hat {\\pmb \\mu}) &=  2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] \\\\\n&= 2 ( l_{saturated}-l_{regession})  \\\\\n   & = 2 \\left [\\sum_i y_i \\log  \\frac{y_i}{m_i} + \\sum_i (m_i -y_i) \\log (1- \\frac{y_i}{m_i})\n    -\\sum_i y_i \\log \\hat p(x_i) - \\sum_i (m_i -y_i) \\log (1-\\hat p(x_i)) \\right ]\\\\\n   & = 2\\left  [\\sum_i y_i \\log \\frac{y_i}{m_i \\hat p(x_i) } + \\sum_i (m_i -y_i) \\log \\frac{1-y_i/m_i}{1-\\hat p(x_i)}\\right ] \\\\\n   & = 2\\left [\\sum_i y_i \\log  \\frac{y_i}{m_i \\hat p(x_i) } + \\sum_i (m_i -y_i) \\log \\frac{m_i-y_i}{m_i- m_i \\hat p(x_i)} \\right ] \\\\\n   & = 2\\left  [\\sum_i y_i \\log   \\frac{y_i}{\\hat y_i } + \\sum_i (m_i -y_i) \\log \\frac{m_i-y_i}{m_i- \\hat y_i } \\right ]\\\\\n\\end{align*}\\]\n위에서 \\(\\hat y_i = m_i \\hat p(x_i)\\)으로 로지스틱 회귀에서 성공의 횟수의 평균에 대한 예측값이다.\n위의 논의에서 알 수 있듯이 로지스틱 회귀에서의 편차는 선형회귀 분석에서 잔차 제곱합 SSE의 의미로 해석할 수 있으며 작을 수록 모형의 예측력이 좋다는 것을 알 수 있다.\n\n\n\n\n\n\n편차의 점근적 분포\n\n\n\n편차는 표본의 개수 \\(m_i\\)가 충분히 크고 회귀식이 옳다는 가정 하에서 자유도가 \\(n-p\\) 인 카이제곱분포를 따른다. 여기서 \\(p\\)는 회귀계수 벡터 \\(\\pmb \\beta\\)의 크기이다.\n\\[  D(\\pmb y;\\hat {\\pmb \\mu}) \\sim \\chi^2_{n-p} \\]\n여기서 \\(n= \\sum_i m_i\\) 이고 \\(p\\) 는 회귀계수의 갯수이다.\n\n\n정규분포와 이항분포의 편차를 비교하면 정규분포의 편차에는 산포를 나타내는 모수 \\(\\sigma^2\\) 이 포함되어 있지만 이항분포의 편차에는 다른 모수가 나타나지 않는다. 식 식 5.8 에서 주어진 편차를 척도 모수(scaled parameter) 또는 산포 모수(dispersion parameter) \\(\\phi\\) 를 곱해준 값을 척도화 편차(scaled deviance) \\(D^*(\\pmb y;\\hat {\\pmb \\mu})\\) 라고 부른다.\n\\[ D^*(\\pmb y;\\hat {\\pmb \\mu}) = \\phi D(\\pmb y;\\hat {\\pmb \\mu})  \\tag{5.9}\\]\n정규분포에서 산포 모수가 분산 \\(\\phi=\\sigma^2\\) 이므로 척도화 편차는 잔차제곱합 \\(D^*(\\pmb y;\\hat {\\pmb \\mu}) = SSE\\) 가 되며 이항분포에서는 편차와 척도화 편차가 같다.\n이제 다시 o-ring 의 예제(섹션 5.2.1)에 대한 로지스틱 회귀식의ㅣ 결과를 보자.\n\nsummary(logit1)\n\n\nCall:\nglm(formula = cbind(damage, 6 - damage) ~ temp, family = binomial, \n    data = orings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 11.66299    3.29626   3.538 0.000403 ***\ntemp        -0.21623    0.05318  -4.066 4.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.898  on 22  degrees of freedom\nResidual deviance: 16.912  on 21  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 6\n\n\n마지막에 Residual deviance 는 다음과 같이 절편과 하나의 예측 변수(온도)를 포함한 회귀식에 대한 편차의 값과 자유도를 나타내는 것이다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] =\\beta_0 + \\beta_1 x \\quad \\rightarrow D(\\pmb y;\\hat {\\pmb \\mu}) = 16.9122785\n\\]\n\ndeviance(logit1)\n\n[1] 16.91228\n\ndf.residual(logit1)\n\n[1] 21\n\n\n위에서 언급하였듯이 모형이 옪다는 가정하에서 편차 \\(D(\\pmb y;\\hat {\\pmb \\mu})\\) 는 자유도가 21 인 \\(\\chi^2\\)-분포를 따르므로 아래에서 구한 \\(P(\\chi^2 \\ge 16.9122785 )\\) 가 크게 나오는 것은 모형이 적절하다는 의미이다.\n\npchisq(deviance(logit1), df.residual(logit1),lower=FALSE)\n\n[1] 0.7164099\n\n\n또한 Null deviance 는 다음과 같이 절편만 포함한 회귀식에 대한 편차의 값과 자유도를 나타내는 것이다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] =\\beta_0\n\\]\n\n\n5.4.3 검정과 모형의 선택\n로지스틱 회귀모형에서 하나의 회귀 계수가 유의한 지에 대한 다음 검정은\n\\[ H_0 : \\beta_i =0 \\quad vs. \\quad H_1: \\beta_i \\ne 0 \\] 다음과 같은 표준화된 통계량을 이용하여 정규분포 검정을적용할 수 있다.\n\\[ z = \\frac{ \\hat \\beta_i}{SE(\\hat \\beta_i)} \\] 또한 회귀 계수 \\(\\beta_i\\) 에 대한 \\((1-\\alpha)100\\%\\) 신뢰구간은 다음과 같이 구할 수 있다.\n\\[  [ \\hat \\beta_i - z_{\\alpha/2 } SE(\\hat \\beta_i) , `` \\hat \\beta_i + z_{\\alpha/2 } SE(\\hat \\beta_i) ] \\]\n위의 o-ring 예제(섹션 5.2.1)에서 온도에 대한 회귀 계수의 \\(95\\%\\) 신뢰구간은 다음과 같이 MASS 패키지의 함수 confint를 이용해서 구한다.\n\nconfint(logit1)\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept)  5.575195 18.737598\ntemp        -0.332657 -0.120179\n\n\n이제 회귀모형에서 고려하는 다음과 같은 가설 검정을 고려해 보자.\n\\[ H_0 : \\text{ reduced model} \\quad vs. \\quad H_1: \\text{full model}  \\tag{5.10}\\]\n로지스틱 회귀에서 편차(deviance)의 차이를 이용하여 두 개의 모형 중 하나를 선택하는 방법을 살펴보자.\n다음과 같이 서로 다른 모형과 그에 대한 가설을 생각해 보자. \\[\nH_0: g[p(x)]  = {\\pmb x}_1^t {\\pmb \\beta}_1 \\quad \\text{vs.} \\quad H_1: g[p(x)] = {\\pmb x_1}^t {\\pmb \\beta}_1+ {\\pmb x}_2^t {\\pmb \\beta}_2\n\\]\n가설을 달리 표현하면 다음과 같이 쓸 수 있다.\n\\[\nH_0: {\\pmb \\beta}_2 =0  \\quad \\text{vs.} \\quad H_1: {\\pmb \\beta}_2 \\ne 0\n\\] 위의 가설에서 \\(dim(\\pmb \\beta_1) = p\\), \\(dim(\\pmb \\beta_2) = q\\) 라고 하면 대립가설 \\(H_1\\)의 모형이 귀무가설 \\(H_0\\)의 모형보다 큰 모형이다.\n만약 축소모형(reduced moldel, \\(H_0\\))에 대한 잔차 편차(Residual Deviance)를 \\(D_0\\) 라고 하고 큰 모형(full model, \\(H_1\\))에 대한 잔차 편차를 \\(D_1\\) 라고 하면 귀무가설이 참인 경우 두 편차의 차이 \\(D_0 - D_1\\) 은 근사적으로 자유도가 \\(q\\) 인 카이제곱분포를 따른다. 여기서 자유도 \\(q\\) 는 두 모형의 회귀계수의 갯수 차이 $(p+q)-p=q이다. 이러한 두 편차의 차이의 점근적 분포 가능도비검정 이론에 의하여 유도할 수 있다.\n\\[ D= D_0 - D_1 \\]\n두 모형에 대한 모수의 개수의 차이 \\(q\\)인 경우 귀무가설이 참일 때 deviance의 차인 \\(D= D_0 - D_1\\) 통계량은 자유도가 \\(q\\)인 \\(\\chi^2\\)-분포를 따른다. 따라서 유의수준 \\(\\alpha\\)에서 \\(D\\) 통계량이 \\(\\chi^2_\\alpha(q)\\)보다 크면 귀무가설을 기각한다.\n편차 차이를 이용하여 검정하는방법은 가능도비 검정(likelihood ratio test)과 동일한 검정이다.\n다음 자료는27명의 암환자들에 대한 암의 호전(remission of cancer)이며 종속변수 \\(y\\)는 remiss로 1이면 암이 호전되었다는 표시이다. 나머지 6개의 변수는 환자의 특성을 나타내는 독립변수이다.\n\ncancer &lt;- read.table(\"remission.txt\",header=T, sep=\"\")\ncancer %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nid\nremiss\ncell\nsmear\ninfil\nli\nblast\ntemp\n\n\n\n\n1\n1\n0.80\n0.83\n0.66\n1.9\n1.100\n0.996\n\n\n2\n1\n0.90\n0.36\n0.32\n1.4\n0.740\n0.992\n\n\n3\n0\n0.80\n0.88\n0.70\n0.8\n0.176\n0.982\n\n\n4\n0\n1.00\n0.87\n0.87\n0.7\n1.053\n0.986\n\n\n5\n1\n0.90\n0.75\n0.68\n1.3\n0.519\n0.980\n\n\n6\n0\n1.00\n0.65\n0.65\n0.6\n0.519\n0.982\n\n\n7\n1\n0.95\n0.97\n0.92\n1.0\n1.230\n0.992\n\n\n8\n0\n0.95\n0.87\n0.83\n1.9\n1.354\n1.020\n\n\n9\n0\n1.00\n0.45\n0.45\n0.8\n0.322\n0.999\n\n\n10\n0\n0.95\n0.36\n0.34\n0.5\n0.000\n1.038\n\n\n11\n0\n0.85\n0.39\n0.33\n0.7\n0.279\n0.988\n\n\n12\n0\n0.70\n0.76\n0.53\n1.2\n0.146\n0.982\n\n\n13\n0\n0.80\n0.46\n0.37\n0.4\n0.380\n1.006\n\n\n14\n0\n0.20\n0.39\n0.08\n0.8\n0.114\n0.990\n\n\n15\n0\n1.00\n0.90\n0.90\n1.1\n1.037\n0.990\n\n\n16\n1\n1.00\n0.84\n0.84\n1.9\n2.064\n1.020\n\n\n17\n0\n0.65\n0.42\n0.27\n0.5\n0.114\n1.014\n\n\n18\n0\n1.00\n0.75\n0.75\n1.0\n1.322\n1.004\n\n\n19\n0\n0.50\n0.44\n0.22\n0.6\n0.114\n0.990\n\n\n20\n1\n1.00\n0.63\n0.63\n1.1\n1.072\n0.986\n\n\n21\n0\n1.00\n0.33\n0.33\n0.4\n0.176\n1.010\n\n\n22\n0\n0.90\n0.93\n0.84\n0.6\n1.591\n1.020\n\n\n23\n1\n1.00\n0.58\n0.58\n1.0\n0.531\n1.002\n\n\n24\n0\n0.95\n0.32\n0.30\n1.6\n0.886\n0.988\n\n\n25\n1\n1.00\n0.60\n0.60\n1.7\n0.964\n0.990\n\n\n26\n1\n1.00\n0.69\n0.69\n0.9\n0.398\n0.986\n\n\n27\n0\n1.00\n0.73\n0.73\n0.7\n0.398\n0.986\n\n\n\n\n\n\n\n\n\n\n\n\n\n노트\n\n\n\nR에서 함수 glm 을 사용하여 로지스틱 회귀모형을 적합하는 경우 반응변수의 값이 2개인 경우 어떤 것이 성공을 의미하는 것인지 알려주어야 한다.\nR에서는 반응변수의 값의 순서를 비교하여 마지막 순서를 성공으로 인식한다. 따라서 반응변수 y 의 값이 0과 1인 경우 y=1 인 사건을 성공이라고 인식하게 된다.\n만약 반응변수의 값이 0 과 1 이 아닌 문자로 되어있는 경우 함수 factor() 의 level= 명령어를 이용하여 순서를 정해 주는 것이 좋다.\n\n\n다음은 6개의 독립변수를 모두 적합한 완전모형(full model)의 추정 결과이다.\n\nlogit3_L &lt;- glm(remiss~cell + smear + infil + li + blast + temp,family=binomial,data=cancer)\nsummary(logit3_L)\n\n\nCall:\nglm(formula = remiss ~ cell + smear + infil + li + blast + temp, \n    family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  58.0385    71.2364   0.815   0.4152  \ncell         24.6615    47.8377   0.516   0.6062  \nsmear        19.2936    57.9500   0.333   0.7392  \ninfil       -19.6013    61.6815  -0.318   0.7507  \nli            3.8960     2.3371   1.667   0.0955 .\nblast         0.1511     2.2786   0.066   0.9471  \ntemp        -87.4339    67.5735  -1.294   0.1957  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 21.751  on 20  degrees of freedom\nAIC: 35.751\n\nNumber of Fisher Scoring iterations: 8\n\n\n위의 회귀분석 결과를 보면 변수들 중 세 개의 변수 li, temp , cell 만 포함한 축소된 모형(reduced model)을 생각해보자.\n\nlogit3_S &lt;- glm(remiss~cell + li + temp,family=binomial,data=cancer)\nsummary(logit3_S)\n\n\nCall:\nglm(formula = remiss ~ cell + li + temp, family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   67.634     56.888   1.189   0.2345  \ncell           9.652      7.751   1.245   0.2130  \nli             3.867      1.778   2.175   0.0297 *\ntemp         -82.074     61.712  -1.330   0.1835  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 21.953  on 23  degrees of freedom\nAIC: 29.953\n\nNumber of Fisher Scoring iterations: 7\n\n\n위에서 적합한 두개의 모형이 유의한 차이가 있는지 위에서 논의한 편차의 차이를 이용하여 검정해 보자. 다음과 같은 가설을 검정하는 검정은 다음과 같이 anova함수로 수행할 수 있다.\n앞에서 두 모형을 적합한 결과에서 잔차 편차(Residual deviance)의 차이를 이용하여 검정을 실시하였다.\n\nanova(logit3_S, logit3_L,test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: remiss ~ cell + li + temp\nModel 2: remiss ~ cell + smear + infil + li + blast + temp\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1        23     21.953                     \n2        20     21.751  3  0.20272   0.9771\n\n\n위의 anova 함수의 결과를 보면 p-vlaue가 0.9771497로 매우 크며 귀무가설 \\(H_0\\)를 기각하지 못한다. 따라서 3개의 독립변수만 가진 축소된 모형을 선택할 수 있다.\n다시 하나의 독립변수 li 만 가지는 축소모형을 고려해 보자.\n\nlogit3_S2 &lt;- glm(remiss~li,family=binomial,data=cancer)\nsummary(logit3_S2)\n\n\nCall:\nglm(formula = remiss ~ li, family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   -3.777      1.379  -2.740  0.00615 **\nli             2.897      1.187   2.441  0.01464 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 26.073  on 25  degrees of freedom\nAIC: 30.073\n\nNumber of Fisher Scoring iterations: 4\n\n\n완전모형과의 차이에 대한검정을 실시하며 다음과 같은 결과가 나오고 cencer remission 자료는 사실상 변수 li만으로도 충분히 설명할 수 있다는 결론이다.\n\nanova(logit3_S2, logit3_L,test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: remiss ~ li\nModel 2: remiss ~ cell + smear + infil + li + blast + temp\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1        25     26.073                     \n2        20     21.751  5   4.3223    0.504\n\n\n모형을 선택하는 경우 AIC(Akaike Information Criteria)를 자주 이용한다. AIC는 다음과 같이 정의되며\n\\[ AIC = -2*log(\\text{Likelihood}) +2*(\\text{number of parameter}) \\] 모형의 AIC값이 작을수록 좋은 모형이다.\n\nAIC(logit3_L, logit3_S, logit3_S2)\n\n          df      AIC\nlogit3_L   7 35.75065\nlogit3_S   4 29.95337\nlogit3_S2  2 30.07296\n\n\n위에서 나타난 AIC로 모형을 선택한다면 독립변수가 3개(li, temp , cell )인 모형이 가장 좋은 모형이다. AIC는 모형에 위에서 주어진 두 번째 항에서 독립변수의 수(number of parameter)를 더해주므로 모형이 복잡할수록 그 값이 증가하여 모형의 선택에서 벌칙(penalty)를 주는 것으로 이해할 수 있다.\nAIC는 로그우도함수와 모형의 자유도로 직접 계산할 수 있다.\n\nAIC(logit3_S)\n\n[1] 29.95337\n\n# value of log likelihood\nas.numeric(logLik(logit3_S))\n\n[1] -10.97668\n\n#number of parameter = 3+1\nattr(logLik(logit3_S),\"df\")\n\n[1] 4\n\n#AIC\n-2*as.numeric(logLik(logit3_S))+2*attr(logLik(logit3_S),\"df\")\n\n[1] 29.95337\n\n\n위에서 모형의 자유도는 독립변수의 개수 3개와 절편 1개를 더해서 4개가 된다.\n\n\n5.4.4 적합도 검정\n모형의 적합도를 측정하는 통계량으로 편차(deviance)뿐만 아니라 \\(\\chi^2\\)-통계량도 매우 유용하다. \\(\\chi^2\\)-통계량은 다음과 같이 주어진다.\n\\[ \\chi^2 = \\sum_{i=1}^n \\frac{ (y_i - m_i \\hat p(x_i))^2 }{m_i \\hat p(x_i)[1-\\hat p(x_i)]}  \\tag{5.11}\\]\n위의 식은 다음과 같은 표준화된 피어슨 잔차 \\(r_i\\) 의 제곱합과 같다.\n\\[ r_i = \\frac{ y_i - m_i \\hat p(x_i)}{\\sqrt{var(\\hat y_i)}} \\] 자료의 수가 많으면 \\(\\chi^2\\)-통계량은 \\(\\chi^2\\) 분포를 따른다.\n\\(\\chi^2\\)-통계량은 다음과 같이 계산할 수 있다.\n\nsum(residuals(logit1,type=\"pearson\")^2)\n\n[1] 28.06738",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#과산포",
    "href": "notes/logistic.html#과산포",
    "title": "5  로지스틱 회귀모형",
    "section": "5.5 과산포",
    "text": "5.5 과산포\n\n5.5.1 과산포의 개요\n로지스틱 회귀식을 적합한 뒤에 주어진 모형이 적절한 모형이라고 판단되지만 잔차 편차(residual devince) \\(D\\)가 기대 이상으로 너무 커서 서로 상충되는 결론이 나오면 다음과 같은 원인을 의심할 수 있다.\n\n중요한 예측변수 \\(x\\)가 모형에 포함되지 않았거나 예측함수 \\(\\eta={\\pmb x}^t {\\pmb \\beta}\\)가 잘못 설정된 경우\n이상점(outlier)이 있는 경우\n반복수의 수가 매우 적은 경우\n분포의 가정이 맞지 않는 경우 - 독립이 아닌 경우, 군집효과(cluster effect)\n\n반응변수 \\(y\\)가 이항분포 \\(B(m,p)\\) 를 따르면 그 평균과 분산은 다음과 같이 주어진다.\n\\[ E(y) = mp \\quad \\text{ and } \\quad Var(y) = mp(1-p) \\]\n자료의 확률 구조가 이항분포의 평균과 분산에 대한 가정과 맞지 않는 경우를 분산의 크기에 따라 과산포(overdispersion) 또는 underdispersion이라고 한다.\n\noverdispersion if \\(Var(y) &gt; mp(1-p)\\)\nunderdispersion if \\(Var(y) &lt; mp(1-p)\\)\n\n예를 들어 모집단이 몇 개의 군집으로 이루져 있다면 군집효과로 발생한 성질때문에 관측치의 분산이 이항분포의 분산보다 큰 경우가 생기게 된다. 이러한 경우를 overdispersion이라고 한다.\n군집 효과는 다음과 같은 이유로 발생할 수 있다.\n\n군집간 의 분포가 서로 다른 경우\n관측값이 서로 독립이 아닌 경우\n\n표본의 개수를 \\(n\\)이라고 하고 군집의 크기를 \\(k\\) 라 하면 군집의 개수는 \\(l=n/k\\) 이 된다.\n\n\\(i\\)번째 군집에서 성공의 회수 \\(z_i\\)는 이항분포 \\(B(k,p_i)\\)를 따른다고 하자.\n이 때, 성공의 확률 \\(p_i\\)를 평균이 \\(E(p_i)=p\\)이고 분산이 \\(Var(p_i)=\\tau^2 p(1-p)\\)인 확률변수라고 가정하자.\n이제 총 성공의 횟수 \\(y =z_1+\\dots+z_k\\)의 분포를 살펴보면\n\n\\[ E(y) = \\sum_i E(Z_i) = \\sum_i kp= mp \\]\n로서 평균은 보통의 경우와 같지만 분산은 다음과 같이 overidspersion이 나타난다.\n\\[\\begin{align*}\nVar(y) & = \\sum_i Var(z_i) \\\\\n  &= \\sum_i \\left [ E(Var(z_i|p_i)) + Var(E(z_i|p_i) \\right ] \\\\\n  &= \\sum_i \\left [ E kp_i(1-p_i) + Var(kp_i) \\right ] \\\\\n  & = \\sum_i \\left [ kE(p_i) - kE(p_i^2) + k^2\\tau^2 p(1-p) \\right ] \\\\\n  & = \\sum_i \\left [ kp - k\\{ \\tau^2 p(1-p) + p^2\\}  + k^2\\tau^2 p(1-p) \\right ] \\\\\n  & = \\sum_i \\left [ kp - k\\{ \\tau^2 p(1-p) + p^2\\}  + k^2\\tau^2 p(1-p) \\right ] \\\\\n   & = [1+\\tau^2(k-1)]kp(1-p)\n\\end{align*}\\]\n즉 \\(1+\\tau^2(k-1)\\)의 값이 1보다 크기 때문에 반응변수가 독립인 경우의 분산 \\(kp(1-p)\\)보다 커진다. \\(1+\\tau^2(k-1)\\) 의 값을 산포모수(dispersion parameter) 라고 부른다.\n\n\n\n\n\n\n산포모수\n\n\n\n이항변수에 대한 로지스틱회위에서 다음과 같이 분산이 이항분포의 이론적 분산 \\(kp(1-p)\\) 보다 크게 크게 나타나는 경우 그 계수를 산포모수(dispersion parameter, \\(\\sigma^2\\)) 이라고 부른다.\n\\[Var(y) = \\sigma^2 mp(1-p) &gt; kp(1-p)\\] 산포모수(\\(\\sigma^2\\))는 과산포가 없으면 1 이고 과산포가 존재하면 1 보다 큰 값을 가진다.\n\n\n산포모수는 식 식 5.11 에 주어진 \\(\\chi^2\\)-통계량에 의해 추정될 수 있다.\n\\[ \\hat \\sigma^2 = \\chi^2/(n-p) \\] 주의할 점은 overidspersion이 있다 하더라도 회귀계수의 추정치 \\(\\beta\\)의 추정에는 영향을 미치지 않는다.\n위와 같이 overidspersion이 있다고 판단되는 경우에는 추가로 산포모수(dispersion parameter) \\(\\sigma^2\\)를 고려하고 이를 추정하여 회귀계수 \\(\\beta\\)의 분산 계산 시 다음과 같이 추가해서 계산한다.\n\\[ Var(\\hat {\\pmb \\beta}) = \\hat \\sigma^2(X'\\hat W X)^{-1} \\]\n\n\n5.5.2 예제\n부교재 Faraway (2016) 의 2.11 절에 소개된 자료를 이용하여 과산포에 대한 예제를 살펴보자.\n데이터 trouegg 는 5개의 장소와 4개의 시번에서 관측한 송어(trout) 알의 생존에 대한 자료이다. 데이터를 구성하는 변수의 이름과 의미는 다음과 같다.\n\nsurvive: the number of surviving eggs\ntotal: the number of eggs in the box\nlocation : the location in the stream with levels 1 2 3 4 5\nperiod : the number of weeks after placement that the box was withdrawn levels 4 7 8 11\n\n다음은 데이터 trouegg 이다.\n\ntroutegg %&gt;% dplyr::arrange(location, period) %&gt;% dplyr::relocate(`location`, `period`, `survive`, `total`) %&gt;%\n kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\n\nlocation\nperiod\nsurvive\ntotal\n\n\n\n\n1\n1\n4\n89\n94\n\n\n6\n1\n7\n94\n98\n\n\n11\n1\n8\n77\n86\n\n\n16\n1\n11\n141\n155\n\n\n2\n2\n4\n106\n108\n\n\n7\n2\n7\n91\n106\n\n\n12\n2\n8\n87\n96\n\n\n17\n2\n11\n104\n122\n\n\n3\n3\n4\n119\n123\n\n\n8\n3\n7\n100\n130\n\n\n13\n3\n8\n88\n119\n\n\n18\n3\n11\n91\n125\n\n\n4\n4\n4\n104\n104\n\n\n9\n4\n7\n80\n97\n\n\n14\n4\n8\n67\n99\n\n\n19\n4\n11\n111\n132\n\n\n5\n5\n4\n49\n93\n\n\n10\n5\n7\n11\n113\n\n\n15\n5\n8\n18\n88\n\n\n20\n5\n11\n0\n138\n\n\n\n\n\n\n\n\nsummary(troutegg)\n\n    survive           total        location period\n Min.   :  0.00   Min.   : 86.00   1:4      4 :5  \n 1st Qu.: 74.50   1st Qu.: 96.75   2:4      7 :5  \n Median : 90.00   Median :107.00   3:4      8 :5  \n Mean   : 81.35   Mean   :111.30   4:4      11:5  \n 3rd Qu.:104.00   3rd Qu.:123.50   5:4            \n Max.   :141.00   Max.   :155.00                  \n\n\n이제 자료 troutegg 에 로지스틱 회귀식을 다음과 같이 적합해보자.\n\nbmod &lt;- glm(cbind(survive,total-survive) ~      location+period,         family=binomial,troutegg)\nsummary(bmod)\n\n\nCall:\nglm(formula = cbind(survive, total - survive) ~ location + period, \n    family = binomial, data = troutegg)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.6358     0.2813  16.479  &lt; 2e-16 ***\nlocation2    -0.4168     0.2461  -1.694   0.0903 .  \nlocation3    -1.2421     0.2194  -5.660 1.51e-08 ***\nlocation4    -0.9509     0.2288  -4.157 3.23e-05 ***\nlocation5    -4.6138     0.2502 -18.439  &lt; 2e-16 ***\nperiod7      -2.1702     0.2384  -9.103  &lt; 2e-16 ***\nperiod8      -2.3256     0.2429  -9.573  &lt; 2e-16 ***\nperiod11     -2.4500     0.2341 -10.466  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1021.469  on 19  degrees of freedom\nResidual deviance:   64.495  on 12  degrees of freedom\nAIC: 157.03\n\nNumber of Fisher Scoring iterations: 5\n\n\n앞의 예제와 같이 결과의 잔차 편차가 \\(\\chi^2\\)-분포를 기준으로 얼마나 큰지 살펴보자.\n\npchisq(deviance(bmod), df.residual(bmod),lower=FALSE)\n\n[1] 3.379416e-09\n\n\n잔차 편차가 매우 큰 것을 알 수 있으며 산포모수 \\(\\sigma^2\\) 는 식 식 5.11 에 주어진 것 처럼 다음과 같이 추정될 수 있다.\n\nsigma2 &lt;- sum(residuals(bmod,type=\"pearson\")^2) /12\nsigma2\n\n[1] 5.330322\n\n\n위에서 구한 산포 모수가 크다는 것은 다음과 같이 o-ring 자료에 대한 로지스틱 회귀의 산포 모수와 비교하면 알 수 있다.\n\nsigma2 &lt;- sum(residuals(logit1,type=\"pearson\")^2) /21\nsigma2\n\n[1] 1.336542\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth. Hoboken NJ: Wiley. http://z.umn.edu/alr4ed.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#필요한-패키지",
    "href": "notes/poisson.html#필요한-패키지",
    "title": "6  포아송 회귀모형",
    "section": "6.1 필요한 패키지",
    "text": "6.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(pscl)\nlibrary(here)",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#포아송-분포",
    "href": "notes/poisson.html#포아송-분포",
    "title": "6  포아송 회귀모형",
    "section": "6.2 포아송 분포",
    "text": "6.2 포아송 분포\n반응변수 \\(y\\)가 어떤 사건이 일어난 횟수(count)라면 주로 포아송분포를 확률 모형으로 사용한다.\n\\[\nP(Y=y) = f(y|\\mu)= \\frac{ e^{-\\mu} \\mu^y }{y!}, \\quad y=0,1,2,\\dots\n\\tag{6.1}\\]\n포아송 분포는 다음과 같은 중요한 특성을 가지고 있다.\n\n만약에 어떤 사건이 일어난 횟수가 몇 가지 가능한 수들 중에 하나라면 (예: \\(0 \\le y \\le M\\)) 포아송분포를 이항분포의 근사(approximation)로 생각할 수 있다. 만약 \\(n\\)이크고 성공확률 \\(p\\)가 작으면 이항분포는 평균이 \\(\\mu=np\\)인 포아송 분포와 매우 가깝기 때문에 가능한 횟수가 제한되었다 하더라도 포아송 분포를 적용할 수 있다.\n사건의 일어난 횟수가 주어진 시간의 길이에 비례하고 다른 사건과 독립이면 포아송 분포를 따른다. 또한 포아송 분포는 두 개의 사건이 일어날 때 시간 간격이 지수분포(exponential distribution)을 따른다면 주어진 시간 간격동안 일어난 사건의 횟수는 포아송 분포를 따른다.\n\\(y_i\\)가 서로 독립이고 평균이 \\(\\mu_i\\)인 포아송분포를 따른다면 합 \\(\\sum_i y_i\\)는 평균이 \\(\\sum_i \\mu_i\\)인 포아송분포를 따른다",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#포아송-회귀모형",
    "href": "notes/poisson.html#포아송-회귀모형",
    "title": "6  포아송 회귀모형",
    "section": "6.3 포아송 회귀모형",
    "text": "6.3 포아송 회귀모형\n이러한 포아송 분포에서 나온 반응변수(횟수 \\(y\\))에 대하여 설명변수 \\(x\\)의 영향에 대한 회귀분석을 포아송 회귀모형이라고 한다.\n포아송 분포의 평균 \\(\\mu\\)는 양의 실수이고 선형예측식 \\(\\eta= \\pmb x^t \\pmb \\beta\\)의 범위는 실수이기 때문에 로그함수를 연결함수(link function)으로 이용하여 회귀식을 세운다.\n\\[\n\\log E(y|\\pmb x_i) =\\log \\mu(\\pmb x_i) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{6.2}\\]\n포아송 회귀모형에서 회귀 계수의 의미를 알아보기 위하여 다음과 같이 하나의 설명변수만 있으며 그 값이 \\(x=0\\) 과 \\(x=1\\) 인 경우에 회귀식을 보자.\n\\[\n\\log E(y| x = 1 ) = \\log \\mu( x = 1) =  \\beta_0 + \\beta_1, \\quad\n\\log E(y| x = 2) = \\log \\mu( x = 2) =  \\beta_0 + 2\\beta_1\n\\] 따라서 다음과 같은 식이 성립하므로 설명변수 \\(x\\) 가 1 단위 증가하면 반응변수의 평균은 \\(\\exp(\\beta_1)\\) 배 증가한다는 것을 알 수 있다.\n\\[\n\\frac{E(y| x = 2 )}{E(y| x = 1 )}= \\frac{\\mu( x = 2)} {\\mu( x = 1)} = \\frac{\\exp(\\beta_0 + 2\\beta_1)}{\\exp(\\beta_0 + \\beta_1) } = \\exp(\\beta_1)\n\\]\n사실 포아송 분포의 로그가능도함수에서 로그함수가 자연 연결함수임을 쉽게 알 수 있다. 즉, \\(\\pmb y=(y_1,y_2,\\dots,y_n)^t\\)를 서로 독립이고 평균이 \\(\\mu_i = \\mu(\\pmb x_i)\\)인 포아송 확률변수라고 한다면 로그가능도함수는 다음과 같다.\n\\[\n\\begin{aligned}\nl &= \\log \\prod_{i=1}^n  f(y_i|\\mu_i)   \\\\\n   &= \\sum_{i=1}^n [y_i \\log \\mu_i - \\mu_i - \\log y_i!]\n\\end{aligned}\n\\tag{6.3}\\]\n위에서 볼수 있듯이 충분통계량 \\(y_i\\)에 대응하는 모수에 대한 항은 \\(\\log \\mu_i\\) 로서 이는 로그함수가 자연연결함수임을 나타낸다.\n회귀계수 \\(\\pmb \\beta\\)의 추정은 로지스틱 회귀와 같이 최대가능도추정법(maximum likelihood estimation)으로 구한다. 포아송 회귀에서도 최대가능도추정량은 직접 계산으로 구할 수 없기 때문에 수치적인 방법을 이용하여 구한다.\n또한 회귀계수에 대한 검정 \\(H_0: \\beta_i=0\\)은 대표본이론에 의거한 정규근사를 이용한다. 즉 유의수준 \\(\\alpha\\)에서 t-통계량 \\(t=\\hat \\beta_i/se(\\hat \\beta_i)\\)의 절대값 \\(|t|\\)가 \\(z_\\alpha\\)보다 크면 귀무가설을 기각한다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#편차",
    "href": "notes/poisson.html#편차",
    "title": "6  포아송 회귀모형",
    "section": "6.4 편차",
    "text": "6.4 편차\n포아송 회귀분석에서 편차(deviance) \\(D\\)를 구해보기 위하여 포화모형을 생각해보자.\n각 관측값의 평균 \\(\\mu_i\\)를 자신의 관측값 \\(y_i\\)로 추정하는 것이 포화모형이다. 따라서 포화모형의 로그가능도함수는 다음과 같이 주어지고\n\\[\nl_{saturated} = \\sum_{i=1}^n [y_i \\log y_i - y_i - \\log y_i!]  \n\\] 식 6.3 으로 주어진 포아송 회귀분석의 로그가능도함수를 빼주면 \\(D\\)를 얻을 수 있다.\n\\[\n\\begin{aligned}\nD & = 2 [ l_{saturated}(\\hat {\\pmb \\mu} | y)-l_{regession}(\\hat {\\pmb \\mu} | y) ] \\\\\n  & = 2 \\sum_{i=1}^n [y_i \\log y_i - y_i - \\log y_i!]  \n  - \\sum_{i=1}^n [y_i \\log {\\hat \\mu}_i - {\\hat \\mu}_i - \\log y_i!]   \\\\\n  &= 2 \\sum_{i=1}^n [ y_i \\log (y_i / {\\hat \\mu}_i) - (y_i - {\\hat \\mu}_i) ]\n\\end{aligned}\n\\]\n또한 모형의 적합성을 측정하는 양으로서 \\(\\chi^2\\)-통계량을 사용할 수 있다.\n\\[\n\\chi^2 = \\sum_{i=1}^n \\frac{(y_i - \\hat \\mu_i)^2}{\\hat \\mu_i}\n\\]\n로지스틱 회귀에서와 비슷하게 포아송 회귀분석에서도 과포화(overdispersion)가 나타날 수 있다. 즉, 포아송 모형의 가정은 평균과 분산이 같은 것인데 (\\(\\mu_i=E(y_i)=Var(y_i)\\)) 이러한 가정은 실제 자료 분석에서 많은 경우에 만족하지 않을 수 있으며 과포화가 나타난다\n\\[\nE(y_i)= \\mu_i, \\quad \\text{ but} \\quad Var(y_i) &gt; \\mu_i\n\\]\n이렇게 과포화가 나타나는 경우에는 산포모수(dispersion parameter) \\(\\phi\\)를 추정하여 회귀계수의 표준오차 계산에 반영해주어야 한다. 산포모수는 \\(\\chi^2\\)통계량을 통하여 추정할 수 있다.\n\\[ \\hat \\phi = \\frac { \\chi^2}{n-p} \\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#발생율-모형",
    "href": "notes/poisson.html#발생율-모형",
    "title": "6  포아송 회귀모형",
    "section": "6.5 발생율 모형",
    "text": "6.5 발생율 모형\n어떤 사건이 일어날 횟수는 집단이나 시간의 크기(size)에 의존할 수 있다. 예를 들어 각 도시의 1년 범죄 발생 횟수는 그 도시의 인구수나 크기에 비례하게 된다.\n이러한 모형은 이항분포를 이용하여 분석할 수 도 있지만 사건의 발생확률이 매우 작고 집단의 크기가 크면 포아송 근사를 통한 분석도 가능하다. 또한 어떤 경우에는 집단의 크기에 대한 정보가 부족할 수 있다.\n이러한 비율에 대한 회귀모형을 발생율 모형(rate models) 로 부르며 식으로 나타내면 아래와 같고\n\\[\n\\log \\frac {\\text{ 발생횟수} } { \\text{집단의 크기} } = \\pmb x^t \\pmb \\beta \\]\n이는 다시 발생횟수에 대한 포아송 회귀모형의 형태로 나타내면 다음과 같이 쓸 수 있다.\n\\[\n\\log \\text{ 발생횟수} =  (1)(\\log \\text{집단의 크기}) +  \\pmb x^t \\pmb \\beta\n\\]\n따라서 발생횟수에 대한 포아송 회귀분석을 적합할 때 집단의 크기를 안다면 그 \\(\\log\\) 변환값을 회귀식에 포함하여 적합할 수 있다. 위의 식에서 알 수 있듯이 크기의 \\(\\log\\) 변환변수는 회귀계수를 강제로 1로 놓는 제약을 둘 수 있다. 이러한 변수를 오프셋 변수(offset variable)이라고 한다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#음이항-분포",
    "href": "notes/poisson.html#음이항-분포",
    "title": "6  포아송 회귀모형",
    "section": "6.6 음이항 분포",
    "text": "6.6 음이항 분포\n베르누이 독립시행에서 \\(k\\)번째의 성공까지의 시행회수 \\(z\\)는 음이항 분포(negative bionomial)을 따른다. 음이항분포는 포아송 분포에서 모수가 감마를 따를 때 근사분포로 사용될 수 있다.\n\\[\nP(z) = {{z-1}\\choose {k-1}} p^k (1-p)^{z-k},\\quad z=k,k+1,\\dots\n\\tag{6.4}\\]\n위의 분포에서 확률 변수와 모수를 다시 아래와 같이 정의하면\n\\[\ny=z-k, \\quad p= \\frac{1}{1+\\alpha}\n\\]\n\\(y\\)의 확률분포는 다음과 같고\n\\[\nP(y) = {{y+k-1}\\choose {k-1}} \\frac{\\alpha^y}{(1+\\alpha)^{y+k}},\\quad y=0,1,2,\\dots\n\\]\n따라서 \\(y\\)의 평균과 분산은 다음과 같이 주어진다.\n\\[\nE(y) = \\mu =k\\alpha, \\quad Var(y) = k\\alpha + k\\alpha^2= \\mu + \\mu^2/k\n\\]\n또한 로그가능도함수는 다음과 같이 주어지고\n\\[\nl= \\sum_{i=1}^n \\left ( y_i \\log \\frac{\\alpha}{1+\\alpha} -k \\log (1+\\alpha) + \\sum_{j=0}^{y_i-1} \\log (j+k) -\\log y_i! \\right )\n\\]\n연결함수는 다음과 같다.\n\\[\n\\log \\frac{\\alpha}{1+\\alpha} = \\log \\frac{\\mu}{\\mu+k} = \\eta=\\pmb x^t \\pmb \\beta\n\\] 보통의 경우 \\(k\\)는 고정된 상수로 생각할 수도 있고 또는 모수로 보고 추정할 수 도 있다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#영과잉모형",
    "href": "notes/poisson.html#영과잉모형",
    "title": "6  포아송 회귀모형",
    "section": "6.7 영과잉모형",
    "text": "6.7 영과잉모형\n어떤 사건의 발생횟수에 대한 자료를 수집할 떄 0이 비정상적으로 많이 나타나는 경우가 있다.\n만약 발생횟수의 분포를 포아송분포(식 6.1)로 가정하면 0이 관측될 확률은 크지 않다.\n\\[\nP(y=0) =  e^{-\\mu}\n\\]\n자료에서 0의 발생 빈도가 비정상적으로 많은 자료를 영과잉자료(zero inflated data)라고 하며 이러한 자료에 포아송 분포를 그대로 적용하면 회귀 계수의 추정량에 편이(bias)가 발생할 수 있으며 과포화(overdispersion)가 발생하는 등 여러 가지 문제가 생긴다.\n발생횟수에 0이 많은 이유는 매우 다양하다. 0이 많이 발생하는 대표적인 이유를 살펴보자.\n\n외부 요인에 의하여 사건의 발생이 제약을 받는 경우\n발생은 했는데 관측이 안된 경우\n원래 0이 많은 경우\n\n이렇게 0 과잉 자료를 분석할 수 있는 대표적인 모형은 영과잉 포아송 모형(zero inflated poission model; ZIP)이다\n확률변수 \\(y_i\\)를 사건의 발생 회수라고 하면 ZIP 모형에서 0이 관측될 확률을 다음과 같이 나타낼 수 있다.\n\\[\nP(y=0) = P(\\text{ False zeros }) + [1-P(\\text{ False zeros })] P(\\text{ count process gives a zero })\n\\]\n즉 0이 관측될 확률은 잘못된 0이 관찰 될 확률과 원래 확률 과정에서 0이 관찰 될 확률의 조합(mixture)으로 나타난다. 이제 \\(i\\)번째 관측에서 잘못된 0이 관찰 될 확률을 \\(\\pi_i\\)라 하면\n\\[\nP(y_i=0) = \\pi_i + (1-\\pi_i) P(\\text{ count process gives a zero })\n\\]\n더 나아가 확률 과정이 평균이 \\(\\mu_i\\)인 포아송 분포를 따른다고 가정하고\n\\[\n\\begin{aligned}\nP(y_i=0) &  = \\pi_i + (1-\\pi_i) P(y_i=0 | \\mu_i) =  \\pi _i+ (1-\\pi_i) e^{-\\mu_i} \\\\\nP(y_i=k) &  =  P(y_i=k | \\mu_i)  =  (1-\\pi_i)\\frac{ e^{-\\mu_i} \\mu_i^{y_k} }{y_k!}, \\quad k=1,2,\\cdots\n\\end{aligned}\n\\]\n위의 분포에서 \\(y\\)의 평균과 분산을 구해보면 다음과 같이 주어진다.\n\\[\n\\begin{aligned}\nE(y_i) &  =   (1-\\pi_i)\\mu_i  \\\\\nVar(y_i) &  =   (1-\\pi_i)\\mu_i + (1-\\pi_i)\\pi_i \\mu_i^2\n\\end{aligned}\n\\]\n위의 식에서 볼 수 있듯이 영과잉 포아송 모형은 과포화들 보인다\n\\[ Var(y_i) &gt; E(y_i) \\]\n영과잉 포아송 모형에 대한 회귀분석은 다음 두 모형을 동시에 고려하는 모형이다.\n\n잘못된 0이 관측될 확률 \\(\\pi_i\\)에 대한 로지스틱 회귀모형\n발생회수에 대한 포아송 회귀모형\n\n\\[\n\\begin{aligned}\n\\log \\frac{\\pi_i} {1-\\pi_i}  &  = {\\pmb x}_b^t {\\pmb \\beta}_b  \\\\\n\\log \\mu_i &  =  {\\pmb x}_p^t {\\pmb \\beta}_p  \n\\end{aligned}\n\\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#예제",
    "href": "notes/poisson.html#예제",
    "title": "6  포아송 회귀모형",
    "section": "6.8 예제",
    "text": "6.8 예제\n\n6.8.1 Galapagos 군도의 거북이\nGalapagos 군도에 있는 30개의 섬에서 사는 거북이의 개체 수 Species 를 반응변수 \\(y\\)로하고 5개의 지리적 변수를 예측변수로 하는 Poisson 회귀식을 적합하려고 한다. 이 예제는 교재 Faraway (2016) 57페이지에 있는 예제이다.\n데이터 gala 를 구성하는 변수들은 다음과 같다.\n\nSpecies: the number of plant species found on the island\nEndemics : the number of endemic species (아래 분석에서 제외)\nArea : the area of the island (km\\(^2\\))\nElevation : the highest elevation of the island (m)\nNearest : the distance from the nearest island (km)\nScruz : the distance from Santa Cruz island (km)\nAdjacent : the area of the adjacent island (square km)\n\n\ngala_2 &lt;- gala[,-2]\nhead(gala_2)  %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\n\nSpecies\nArea\nElevation\nNearest\nScruz\nAdjacent\n\n\n\n\nBaltra\n58\n25.09\n346\n0.6\n0.6\n1.84\n\n\nBartolome\n31\n1.24\n109\n0.6\n26.3\n572.33\n\n\nCaldwell\n3\n0.21\n114\n2.8\n58.7\n0.78\n\n\nChampion\n25\n0.10\n46\n1.9\n47.4\n0.18\n\n\nCoamano\n2\n0.05\n77\n1.9\n1.9\n903.82\n\n\nDaphne.Major\n18\n0.34\n119\n8.0\n8.0\n1.84\n\n\n\n\n\n\n\n데이터를 일반적인 선형모형과 반응변수에 제곱근 변환을 적용한 결과는 다음과 같다.\n\nmodl &lt;- lm(Species ~ . , gala_2)\nplot(modl, 1)\n\n\n\nsummary(modl)\n\n\nCall:\nlm(formula = Species ~ ., data = gala_2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-111.679  -34.898   -7.862   33.460  182.584 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.068221  19.154198   0.369 0.715351    \nArea        -0.023938   0.022422  -1.068 0.296318    \nElevation    0.319465   0.053663   5.953 3.82e-06 ***\nNearest      0.009144   1.054136   0.009 0.993151    \nScruz       -0.240524   0.215402  -1.117 0.275208    \nAdjacent    -0.074805   0.017700  -4.226 0.000297 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 60.98 on 24 degrees of freedom\nMultiple R-squared:  0.7658,    Adjusted R-squared:  0.7171 \nF-statistic:  15.7 on 5 and 24 DF,  p-value: 6.838e-07\n\n\n\nmodt &lt;- lm(sqrt(Species) ~ . , gala)\nplot(modt, 1)\n\n\n\nsummary(modt)\n\n\nCall:\nlm(formula = sqrt(Species) ~ ., data = gala)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.77512 -0.67895 -0.07101  0.62771  2.50402 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.3705693  0.4253328   5.573 1.14e-05 ***\nEndemics     0.2002788  0.0217192   9.221 3.45e-09 ***\nArea        -0.0002763  0.0005147  -0.537    0.597    \nElevation   -0.0002509  0.0021483  -0.117    0.908    \nNearest      0.0198908  0.0226069   0.880    0.388    \nScruz       -0.0021423  0.0047791  -0.448    0.658    \nAdjacent     0.0001255  0.0005361   0.234    0.817    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.307 on 23 degrees of freedom\nMultiple R-squared:  0.9537,    Adjusted R-squared:  0.9417 \nF-statistic: 79.03 on 6 and 23 DF,  p-value: 3.457e-14\n\n\n포아송 회귀모형을 적합한 결과는 다음과 같다.\n\nmodp &lt;- glm(Species ~ .,family=poisson, gala_2)\nsummary(modp)\n\n\nCall:\nglm(formula = Species ~ ., family = poisson, data = gala_2)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.155e+00  5.175e-02  60.963  &lt; 2e-16 ***\nArea        -5.799e-04  2.627e-05 -22.074  &lt; 2e-16 ***\nElevation    3.541e-03  8.741e-05  40.507  &lt; 2e-16 ***\nNearest      8.826e-03  1.821e-03   4.846 1.26e-06 ***\nScruz       -5.709e-03  6.256e-04  -9.126  &lt; 2e-16 ***\nAdjacent    -6.630e-04  2.933e-05 -22.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3510.73  on 29  degrees of freedom\nResidual deviance:  716.85  on 24  degrees of freedom\nAIC: 889.68\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n6.8.2 세포의 비정상성\n세포(cells)에 감마 방사능을 쏘였을 떄 비정상성(ca)를 나타내는 횟수에 대하여 발생율 모형을 적합시켰다. 예측변수는 방사능의 양(doseamt)와 비율(doserate)이다. 여기서 세포의 수(cells)를 오프셋 변수(offset variable)로 사용한다. 이 예제는 교재 Faraway (2016) 61페이지에 있는 예제이다.\n\ncells : Number of cells in hundreds\nca : Number of chromosomal abnormalities\ndoseamt : amount of dose in Grays\ndoserate : rate of dose in Grays/hour\n\n\nhead(dicentric) %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\ncells\nca\ndoseamt\ndoserate\n\n\n\n\n478\n25\n1\n0.10\n\n\n1907\n102\n1\n0.25\n\n\n2258\n149\n1\n0.50\n\n\n2329\n160\n1\n1.00\n\n\n1238\n75\n1\n1.50\n\n\n1491\n100\n1\n2.00\n\n\n\n\n\n\n\n다음 표는 방사능의 양(doseamt)와 비율(doserate)의 조합에 따라 비정상 세포의 비율을 나타낸다.\n\nround(xtabs(ca/cells ~ doseamt+doserate, dicentric),2)\n\n       doserate\ndoseamt  0.1 0.25  0.5    1  1.5    2  2.5    3    4\n    1   0.05 0.05 0.07 0.07 0.06 0.07 0.07 0.07 0.07\n    2.5 0.16 0.28 0.29 0.32 0.38 0.41 0.41 0.37 0.44\n    5   0.48 0.82 0.90 0.88 1.23 1.32 1.34 1.24 1.43\n\n\n\nwith(dicentric,interaction.plot(doseamt, doserate, ca/cells, legend= FALSE))\n\n\n\n\n먼저 일반적인 선형모형을 적용하고 잔차분석을 수행하자.\n\nlmod &lt;- lm(ca/cells ~ log(doserate)*factor(doseamt), dicentric)\nsummary(lmod)\n\n\nCall:\nlm(formula = ca/cells ~ log(doserate) * factor(doseamt), data = dicentric)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.184275 -0.004212  0.001314  0.021208  0.089076 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      0.063489   0.019528   3.251  0.00382 ** \nlog(doserate)                    0.004573   0.016692   0.274  0.78680    \nfactor(doseamt)2.5               0.276315   0.027616  10.005 1.92e-09 ***\nfactor(doseamt)5                 1.004119   0.027616  36.359  &lt; 2e-16 ***\nlog(doserate):factor(doseamt)2.5 0.063933   0.023606   2.708  0.01317 *  \nlog(doserate):factor(doseamt)5   0.239129   0.023606  10.130 1.54e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05858 on 21 degrees of freedom\nMultiple R-squared:  0.9874,    Adjusted R-squared:  0.9844 \nF-statistic:   330 on 5 and 21 DF,  p-value: &lt; 2.2e-16\n\nplot(residuals(lmod) ~ fitted(lmod),xlab=\"Fitted\",ylab=\"Residuals\")\nabline(h=0)\n\n\n\n\n위의 잔차분석에서는 등분산성이 의심되는 결과가 나타난다.\n이제 doseamt 를 범주형 자료로 만들고 세포의 갯수(cells) 를 다음과 같이 log 변환하여 독립변수에 포함시키자. 이제 반응변수는 비정상 세포의 비율이 아니라 비정상 세포의 갯수이다.\n\ndicentric_1 &lt;- dicentric\ndicentric_1$dosef &lt;- factor(dicentric_1$doseamt)\npmod &lt;- glm(ca ~ log(cells)+log(doserate)*dosef,  family=poisson, dicentric_1)\nsummary(pmod)\n\n\nCall:\nglm(formula = ca ~ log(cells) + log(doserate) * dosef, family = poisson, \n    data = dicentric_1)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.76534    0.38116  -7.255 4.02e-13 ***\nlog(cells)              1.00252    0.05137  19.517  &lt; 2e-16 ***\nlog(doserate)           0.07200    0.03547   2.030 0.042403 *  \ndosef2.5                1.62984    0.10273  15.866  &lt; 2e-16 ***\ndosef5                  2.76673    0.12287  22.517  &lt; 2e-16 ***\nlog(doserate):dosef2.5  0.16111    0.04837   3.331 0.000866 ***\nlog(doserate):dosef5    0.19316    0.04299   4.493 7.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 916.127  on 26  degrees of freedom\nResidual deviance:  21.748  on 20  degrees of freedom\nAIC: 211.15\n\nNumber of Fisher Scoring iterations: 4\n\n\n이제 다음과 같은 관계에 따라서 세포의 갯수(cells)를 오프셋 변수로 다시 적합시켜보자.\n\\[\n\\log (\\text{ca}/ \\text{cell}) = {\\pmb x}^t {\\pmb \\beta}\n\\Leftarrow\n\\log (\\text{ca} ) = \\log(\\text{cell}) + {\\pmb x}^t {\\pmb \\beta}\n\\]\n\nrmod &lt;- glm(ca ~ offset(log(cells))+log(doserate)*dosef,  family= poisson, dicentric_1) \nsummary(rmod)\n\n\nCall:\nglm(formula = ca ~ offset(log(cells)) + log(doserate) * dosef, \n    family = poisson, data = dicentric_1)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.74671    0.03426 -80.165  &lt; 2e-16 ***\nlog(doserate)           0.07178    0.03518   2.041 0.041299 *  \ndosef2.5                1.62542    0.04946  32.863  &lt; 2e-16 ***\ndosef5                  2.76109    0.04349  63.491  &lt; 2e-16 ***\nlog(doserate):dosef2.5  0.16122    0.04830   3.338 0.000844 ***\nlog(doserate):dosef5    0.19350    0.04243   4.561  5.1e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4753.00  on 26  degrees of freedom\nResidual deviance:   21.75  on 21  degrees of freedom\nAIC: 209.16\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n6.8.3 국립공원 방문자\n국립공원에서 일하는 야생동물 연구원은 공원방문자들이 얼마나 많은 수의 고기(fish)를 잡는지 알고 싶어한다.공원방문자는 공원을 떠날 때 다음과 같은 설문들에 대하여 답하였다. 총 250명의 방문자(group)가 설문에 응답하였다. 이 예제는 교재 Faraway (2016) 94페이지에 있는 예제이다.\n\n며칠동안 공원에 머물렀는가?\n같이 공원에 온 사람들은 총 몇 명인가? (persons)\n같이 공원에 온 사람들 중에 어린이는 몇 명인가? (child)\n공원 방문중에 낚시를 하였는가?\n낚시를 하였다면 고기를 몇 마리 잡았는가? (count)\n공원을 방문할 떄 캠핑카를 가지고 왔는가? (camper)\n\n공원에 방문한 사람들 중에 낚시를 하지 않은 사람들이 많기 때문에 많은 수의 그룹이 잡은 고기의 수가 0이다.\n위의 자료를 영과잉모형으로 분석하기 위하여 다음과 같이 자료를 부르고 히스토그램을 그려보자.\n\nzinb&lt;-read.csv(here::here(\"data/fish.csv\"))\nhead(zinb)  %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nnofish\nlivebait\ncamper\npersons\nchild\nxb\nzg\ncount\n\n\n\n\n1\n0\n0\n1\n0\n-0.8963146\n3.0504048\n0\n\n\n0\n1\n1\n1\n0\n-0.5583450\n1.7461489\n0\n\n\n0\n1\n0\n1\n0\n-0.4017310\n0.2799389\n0\n\n\n0\n1\n1\n2\n1\n-0.9562981\n-0.6015257\n0\n\n\n0\n1\n0\n1\n0\n0.4368910\n0.5277091\n1\n\n\n0\n1\n1\n4\n2\n1.3944855\n-0.7075348\n0\n\n\n\n\n\n\n\n\nzinb_1 &lt;- within(zinb, {\n    nofish &lt;- factor(nofish)\n    livebait &lt;- factor(livebait)\n    camper &lt;- factor(camper)\n})\n\nsummary(zinb_1)\n\n nofish  livebait camper     persons          child             xb           \n 0:176   0: 34    0:103   Min.   :1.000   Min.   :0.000   Min.   :-3.275050  \n 1: 74   1:216    1:147   1st Qu.:2.000   1st Qu.:0.000   1st Qu.: 0.008267  \n                          Median :2.000   Median :0.000   Median : 0.954550  \n                          Mean   :2.528   Mean   :0.684   Mean   : 0.973796  \n                          3rd Qu.:4.000   3rd Qu.:1.000   3rd Qu.: 1.963855  \n                          Max.   :4.000   Max.   :3.000   Max.   : 5.352674  \n       zg              count        \n Min.   :-5.6259   Min.   :  0.000  \n 1st Qu.:-1.2527   1st Qu.:  0.000  \n Median : 0.6051   Median :  0.000  \n Mean   : 0.2523   Mean   :  3.296  \n 3rd Qu.: 1.9932   3rd Qu.:  2.000  \n Max.   : 4.2632   Max.   :149.000  \n\n\n\nggplot(zinb_1, aes(count)) + geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(zinb, aes(count)) + geom_histogram() + scale_x_log10() +ggtitle(\"x-axis is log scale\")\n\nWarning: Transformation introduced infinite values in continuous x-axis\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 142 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n다음은 영과잉 포아송모형을 적합한 결과이다. 0에 대한 로지스틱 회귀에서 사용하는 독립변수는 persons이다.\n\nzip1 &lt;- pscl::zeroinfl(count ~ child + camper | persons, data = zinb_1)\nsummary(zip1)\n\n\nCall:\npscl::zeroinfl(formula = count ~ child + camper | persons, data = zinb_1)\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.2369 -0.7540 -0.6080 -0.1921 24.0847 \n\nCount model coefficients (poisson with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.59789    0.08554  18.680   &lt;2e-16 ***\nchild       -1.04284    0.09999 -10.430   &lt;2e-16 ***\ncamper1      0.83402    0.09363   8.908   &lt;2e-16 ***\n\nZero-inflation model coefficients (binomial with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.2974     0.3739   3.470 0.000520 ***\npersons      -0.5643     0.1630  -3.463 0.000534 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 10 \nLog-likelihood: -1032 on 5 Df\n\n\n다음은 일반적인 포아송모형을 적합한 결과이다.\n\npois1 &lt;- glm(count ~ child + camper, family = poisson, data = zinb_1)\nsummary(pois1)\n\n\nCall:\nglm(formula = count ~ child + camper, family = poisson, data = zinb_1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.91026    0.08119   11.21   &lt;2e-16 ***\nchild       -1.23476    0.08029  -15.38   &lt;2e-16 ***\ncamper1      1.05267    0.08871   11.87   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2958.4  on 249  degrees of freedom\nResidual deviance: 2380.1  on 247  degrees of freedom\nAIC: 2723.2\n\nNumber of Fisher Scoring iterations: 6\n\n\n영과잉 모형과 일반적인 포아송 모형의 적합도를 비교하는 가설검정은 Vuong test 를 이용하여 다음과 같이 수행할 수 있다. 아래에서 p-값이 매우 작은 것은 영과잉 모형이 더 적절함을 나타낸다.\n\npscl::vuong(pois1, zip1)\n\nVuong Non-Nested Hypothesis Test-Statistic: \n(test-statistic is asymptotically distributed N(0,1) under the\n null that the models are indistinguishible)\n-------------------------------------------------------------\n              Vuong z-statistic             H_A    p-value\nRaw                   -3.574259 model2 &gt; model1 0.00017561\nAIC-corrected         -3.552397 model2 &gt; model1 0.00019087\nBIC-corrected         -3.513904 model2 &gt; model1 0.00022079\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#필요한-패키지와-함수",
    "href": "notes/random_effect.html#필요한-패키지와-함수",
    "title": "7  반복측정자료",
    "section": "7.1 필요한 패키지와 함수",
    "text": "7.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(brms)\n# ggplot2 에서 한글의 사용\nlibrary(showtext)\nfont_add_google(\"Nanum Pen Script\", \"nanum\")\nshowtext_auto()",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#repeatmeasure-paired",
    "href": "notes/random_effect.html#repeatmeasure-paired",
    "title": "7  반복측정자료",
    "section": "7.2 독립표본과 대응표본",
    "text": "7.2 독립표본과 대응표본\n서로 다른 두 처리의 효과(treatment effect)를 비교하기 위하여 주로 사용되는 방법은 두 개의 독립표본(independent sample)을 비교하는 t-검정법이다. 서로 독립인 두개의 집단(구성원이 겹치지 않는 집단)에 서로 다른 처리를 적용한 뒤에 관측된 자료의 표본 평균을 비교하여 두 개의 처리 효과의 차이를 통계적으로 검정하는 방법이다. t-검정을 위한 분포 가정은 다음과 같다.\n\\[\nx_1,x_2, \\dots x_{n} \\sim_{iid} N(\\mu_1, \\sigma^2)\n\\quad\ny_1,y_2, \\dots y_{n} \\sim_{iid} N(\\mu_2, \\sigma^2)\n\\]\n위의 가정을 다음과 같은 평균모형(mean model)로 표현할 수 있다.\n\\[\nx_i = \\mu_1 + e_{i1}, \\quad y_i = \\mu_2 + e_{i2}  \n\\tag{7.1}\\]\n여기서 \\(e_{i1}\\)와 \\(e_{i2}\\)들은 모두 독립이며 \\(N(0,\\sigma^2)\\)을 따르는 오차들이다.\n여기서 확률변수 \\(x\\)와 \\(y\\)는 서로 독립이고 각 관측값 \\(x_1,x_2, \\dots x_{n_1}\\)과 \\(y_1,y_2, \\dots y_{n_2}\\)들도 각각 모두 독립이다. 분포가정에서 다른 것은 확률변수 \\(x\\)와 \\(y\\)의 평균이 다르다.\n이러한 가정 하에서 다음의 두개의 가설검정을 할 수 있는 방법이 t-검정법이며\n\\[\nH_0 : \\mu_1 = \\mu_2 \\quad \\text{vesus} \\quad H_1 : \\mu_1 \\ne \\mu_2  \n\\tag{7.2}\\]\n검정통계량은 다음과 같이 주어진다.\n\\[\nt = \\frac{ \\bar x -\\bar y} {s_p \\sqrt{\\tfrac{1}{n} + \\tfrac{1}{n}}}  \n\\tag{7.3}\\]\n여기서 \\(\\bar x\\)와 \\(\\bar y\\)는 각 집단의 표본 평균이고 \\(s_p^2\\)은 합동분산추정량(pooled variance estimator)이다.\n\\[\ns^2_p = \\frac{\\sum_{i=1}^n (x_i -\\bar x)^2 + \\sum_{i=1}^n (y_i -\\bar y)^2 }{2n-2}\n\\]\n이제 두 개의 처리를 비교하는 경우, 독립 표본이 아닌 경우를 고려해 보자.\n독립 표본이 아닌 대표적인 경우가 대응표본(또는 쌍표본)에 대한 t-검정이다(paired t-test). 대응표본 검정에서는 하나의 개체에 두 개의 처리를 모두 적용하여 각 처리에 대한 반응값을 쌍 \\((x_i,y_i)\\)으로 얻는다.\n예를 들어 최초로 허가 받은 약품과 복제약의 생물학적동등성(bioequivalence)을 입증하는 실험에서는 한 사람에게 최초허가약을 투여하여 약의 효과를 보고 일정 시간이 지난 뒤 복제약을 같은 사람에게 투여하여 그 효과를 측정한다. 다른 예로서 두 개의 눈병 치료제를 각각 누에 투여하여 효과를 비교하는 경우도 이러한 대응표본에 속한다. 넓은 의미에서 일란성 쌍둥이에게 각각 다른 처리를 하여 비교하는 것도 대응비교라고 할 수 있다.\n\n\n생물학적동등성 실험에서 사용되는 교차실험(crossover design) - 개체 당 2개의 관측치 (각 처리에 대하여 한 개의 관측값)\n\n\n\n가장 단순한 대응비교로서 각 개체애 대하여 두 개의 처리에 대한 대응표본 \\((x_i,y_i)\\)를 관측한다고 가정하자.\n이에 대한 분포 모형은 다음과 같다.\n\\[\nd_i = x_i -y_i  \\sim_{iid} N(\\delta,\\sigma^2) \\text { where } \\delta = \\mu_1-\\mu_2 = E(x)-E(y)\n\\]\n대응비교에서 사용되는 t-통계량은 다음과 같다.\n\\[\nt = \\frac{ \\bar d} {s_d / \\sqrt{n}} =\\frac{ \\bar x -\\bar y} {s_d / \\sqrt{n}}\n\\tag{7.4}\\]\n여기서 \\(s^2_d\\)는 \\(d_1,d_2,\\dots ,d_n\\)의 표본분산이다.\n\\[\ns^2_d = \\frac{\\sum_{i=1}^n (d_i -\\bar d)^2}{n-1}\n\\]\n위에서 알아본 독립표본에 의한 비교와 대응표본에 의한 비교가 다른 점은 무었일까 생각해 보자.\n표본의 비교가 다른 개체에서 추출된 독립인 관측치를 이용하는지 또는 같은 개체에서 추출된 대응하는(독립이 아닌) 관측치를 이용하는지에 따라서 서로 다른 t-통계량을 사용한다. 식 7.3 과 식 7.4 에 나타난 t-통계량을 비교하면 분자에 나타난 통계량은 효과의 차이를 나타내는 두 개의 평균의 차이로서 기본적으로 동일하다\\((\\bar d =\\bar x -\\bar y)\\). 하지만 분모에서는 분자에 나타난 통계량의 표본오차(standard error)를 나타내는 양으로서 서로 다르다.\n독립표본에서는 표본의 평균이 서로 독립이므로 다음과 같이 평균의 차이에 대한 분산이 각각의 분산의 합과 같으므로 이에 대한 추정량으로서 합동분산추정량을 이용하였다.\n\\[\nVar(\\bar x - \\bar y) = Var(\\bar x) + Var(\\bar y)   \n\\tag{7.5}\\]\n대응표본에서는 위의 식 7.5 을 적용할 수 없다. 왜냐하면 두개의 표본 평균이 서로 독립이 아닐 가능성이 매우 높기 때문이다. 같은 개체에서 나온 관측치는 어떠한 형태로든 서로 관계가 있을 가능성이 높기 때문에 독립을 함부로 가정할 수 없다. 예를 들어 생물학적동등성 실험에서는 약 효과의 차이보다 약이 몸에 흡수되는 개인적인 체질이 관측값에 더 큰 영향을 줄 수 있다.",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#임의효과",
    "href": "notes/random_effect.html#임의효과",
    "title": "7  반복측정자료",
    "section": "7.3 임의효과",
    "text": "7.3 임의효과\n확률변수 \\(x\\)와 \\(y\\)가 독립이 아닌 경우 두 모형균의 차이를 비교하기 위하여 비교에 사용된 통계양은 두 확률변수의 차이다.\n\\[\nd_i = x_i - y_i\n\\]\n여기서 두 개의 확률변수의 차이를 이용할 때 암시적인 가정은 두 개의 확률변수의 차이를 내면 두 변수에 공통적으로 포함된 개인의 특성이 서로 상쇄되어 처리의 차이만이 확률변수 \\(d_i\\)에 존재한다는 것이다. 지금 설명한 대응비교 모형의 합리적인 가정을 요약하면 다음과 같다.\n\n개인의 특성을 반영하는 공통 요인이 두 변수에 모두 영향을 미친다.\n따라서 두 관측값 \\((x_i,y_i)\\)가 독립이 아니다\n두 관측값의 차이를 내면 공통요인이 서로 상쇄되어 처리효과만 남는다.\n\n\\[\nE(d_i) = \\mu_1 - \\mu_2\n\\]\n위의 가정을 구현할 수 있는 대응비교 모형을 다음과 같은 가법모형(additive models)로 표현할 수 있다.\n\\[  \nx_i = \\mu_1 + a_i + e_{i1}, \\quad y_i = \\mu_2 + a_i + e_{i2}\n\\tag{7.6}\\]\n여기서 \\(a_i\\)는 두 확률변수 \\((x_i,y_i)\\)에 공통으로 포함된 개인적인 특성을 나타내는 요인이며 위의 식 7.6 는 식 7.1 에 공통요인 \\(a_i\\)가 추가된 형태이다.\n두 확률변수 \\((x_i,y_i)\\)가 종속이기 위해서는 다음과 같은 가정을 이용할 수 있다.\n\\[\na_i \\sim N(0, \\sigma^2_a), \\quad  e_{i1} \\sim_{iid}  N(0, \\sigma^2_e)  \\quad e_{i2} \\sim_{iid}  N(0, \\sigma^2_e)\n\\] 여기서 \\(a_i\\)가 평균이 0이고 분산이 \\(\\sigma_a^2\\) 인 확률변수이다. 이러한 요인을 임의효과(random effect) 라고 하며 모수(parameter)인 평균 \\(\\mu_i\\)은 고정효과(fixed effect)라고 부른다. \\(e_{i1}\\)와 \\(e_{i2}\\)들은 모두 독립이며 평균이 \\(0\\) 이고 분산이 \\(\\sigma^2_e\\)인 정규분포를 따르는 오차들이다. 또한 \\(a_i\\)와 (\\(e_{i1}\\),\\(e_{i2}\\))도 독립이다.\n위와 같은 가정에서 두 변수의 차이를 내면 공통요인인 \\(a_i\\)가 제거되어 두 처리의 차이만이 남게되며 \\(x_i\\)와 \\(y_i\\)는 분포의 가정상 독립이 아니다.\n\\[\n\\begin{aligned}\nd_i &= x_i -y_i \\\\\n   &= \\mu_1+ a_i + e_{i1} -(\\mu_2+ a_i + e_{i2}) \\\\\n   &= \\mu_1 -\\mu_2 +(e_{i1}-e_{i2}) \\\\\n   &= \\mu_1 -\\mu_2 +e^*_i\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nCov(x_i,y_i) &= Cov(\\mu_1+ a_i + e_{i1},\\mu_2+ a_i + e_{i2}) \\\\\n    & =  Cov(a_i, a_i) \\\\\n    & =  Var(a_i) \\\\\n    & =  \\sigma^2_a\n\\end{aligned}\n\\]\n다음 절에서는 여기서 논의한 독립표본과 대응표본의 개념 및 추정법을 일반적인 선형모형으로 확장하여 체계적인 비교를 해볼것이다.",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#repeatmeasure-oneway",
    "href": "notes/random_effect.html#repeatmeasure-oneway",
    "title": "7  반복측정자료",
    "section": "7.4 일원배치 모형",
    "text": "7.4 일원배치 모형\n\n7.4.1 고정효과 모형\n먼저 일원배치 요인계획(one-way factor design)이용한 실험을 생각해 보자. 고려하는 요인의 수준의 개수를 \\(I\\)라고 하면 \\(I\\)개의 수준 중에 하나를 임의로 선택하여 실험대상에 적용하는 임의화 방법으로 각 수준마다 \\(J\\)의 관측값을 얻어다고 하자. 다음과 같은 ANOVA모형을 고려하여 분석을 할 수 있다.\n\\[\ny_{ij} = \\mu + \\alpha_i + e_{ij}, \\quad i=1,2,\\dots,I \\text{ and } j=1,2,\\dots, J  \n\\tag{7.7}\\]\n여기서 \\(e_{ij}\\)는 서로 독립이며 \\(N(0,\\sigma_e^2)\\)를 따르는 오차항이다.\nANOVA 모형 식 7.7 에서 \\(\\mu\\)와 \\(\\alpha_i\\)는 고정효과(fixed effect)라고 부르며 추정해야 할 모수(parameter)이다. 세심하게 설계된 실험에서는 수준에 대한 효과 \\(\\alpha_i\\)의 값이 변하지 않게 통제할 수 있는 실험 환경이 가능하다고 생각할 수 있으므로 \\(\\alpha_i\\)의 값을 변하지 않는 고정효과로 보는 것이 합리적이다.\n일원배치 요인계획을 이용한 실험에서는 주요 관심사가 수준간의 차이가 있는지에 대한 것이며 이는 제곱합을 이용한 ANOVA table에서 F-test를 이용하여 검정할 수 있다.\n\\[\nH_0: \\alpha_1 = \\alpha_2 =\\dots = \\alpha_I\n\\]\n\n\n7.4.2 임의효과 모형\n이제 다음과 같은 자료의 추출을 생각해 보자. 서울시 A구에 초등학교가 20개있다고 하자. 20개의 학교중 6개의 학교를을 임의로 추출하고 추출된 학교에 속한 모든 6학년 학생들에게 과학시험을 보게하여 점수를 얻었다. 이러한 자료에서 학생들의 성적은 모두 같지 않을 것이 당연하며 가장 점수가 낮은 학생부터 높은 학생까지 점수의 변동(variation)이 존재한다. 변동의 요인은 무었일까? 학생의 개인의 차이(예:학생의 지능, 노력 정도, 학습 환경)도 변동의 요인이지만 또한 학교의 차이도 변동의 요인이 될 수 있다.\n여기서 학교에 대한 요인은 앞 절에서 본 실험 자료에서 나타나는 고정 효과에 의한 요인과는 성격이 틀리다. 20개의 학교라는 모집단에서 6개의 학교가 추출되었으며 이 때 학교의 차이는 설계된 실험에서는 수준에 대한 효과와는 다르게 표본 추출 때문에 생기는 변동이라고 할 수 있다. 또한 같은 학교에 다니는 학생들은 같은 지역과 교사 등 공통적인 요인에 의하여 영향을 받는다고 가정할 수 있다. 따라서 같은 학교에 다는 학생들의 성적이 독립이 아닐 수도 있다.\n이러한 효과를 임의효과(random effect)라고 부르며 학생들의 과학점수에 대한 모형을 다음과 같은 임의효과모형(random effects model) 또는 혼합효과모형(mixed effects model) 으로 설명할 수 있다.\n\\[\ny_{ij} = \\mu + a_i + e_{ij}, \\quad i=1,2,\\dots,I \\text{ and } j=1,2,\\dots, J  \n\\tag{7.8}\\]\n여기서 \\(a_i\\)는 학교의 효과를 나타내는 임의효과이며 서로 독립이고 \\(N(0,\\sigma_a^2)\\)를 따른다. 또한 개인에 대한 효과 또는 오차항 \\(e_{ij}\\)는 서로 독립이며 \\(N(0,\\sigma_e^2)\\)를 따른다. 임의효과 \\(a_i\\)와 오차항 \\(e_{ij}\\)는 서로 독립이다. 고정효과 \\(\\mu\\)는 전체 평균을 나타내는 모수이다.\n학교를 추출할 때 그 효과를 분산이 \\(\\sigma^2_a\\)를 가지는 정규모집단에서 추출한다고 가정하는 것이다. 학교를 하나의 군집(cluster)로 생각하고 학교의 효과를 군집효과로 보고 총변동의 일부로서 고려하고 나머지 변동은 오차의 변동으로 개인의 효과 등으로 설명한다.\n\\[\nVar(y_{ij}) =Var(\\mu + a_i + e_{ij}) = Var(a_i) + Var(e_{ij}) = \\sigma^2_a + \\sigma^2_e\n\\]\n식 7.8 로 표현된 임의효과를 포함한 혼합모형(일원배치 임의효과 모형; one-way random effect models)의 가장 큰 특징 중에 하나는 같은 군집에 속하는 관측치들은 서로 독립이 아니며 양의 상관관계가 있다.\n위의 예제에서 두 학생 \\(j\\)와 \\(k\\)가 같은 학교 \\(i\\)에 속한다면\n\\[\nCov(y_{ij},y_{ik}) = Cov(  \\mu + a_i + e_{ij}, \\mu + a_i + e_{ik}) =Cov (a_i, a_i)=\\sigma^2_a\n\\]\n따라서\n\\[\ncorr(y_{ij},y_{ik})= \\frac{ Cov(y_{ij},y_{ik})}{\\sqrt{Var(y_{ij})Var(y_{ik})} } = \\frac{\\sigma^2_a }{\\sigma^2_a + \\sigma^2_e }\n\\]\n위의 상관계수를 보면 학교간의 변동의 크기를 나타내는 \\(\\sigma^2_a\\) 가 각 개인간의 변동을 나타내는 \\(\\sigma^2_e\\)보다 상대적으로 클수록 상관계수가 1에 가까와진다.\n보통 \\(\\sigma^2_a\\)을 집단간 변동(between-group variance)라 하고 \\(\\sigma^2_e\\)를 집단내 변동(within-group variance)라고 한다. 따라서 \\(\\sigma^2_a\\)와 \\(\\sigma^2_e\\)의 상대적인 크기의 차이에 따라 군집내 관측값의 상관관계가 달라진다.\n식 7.8 의 임의효과 모형은 임의효과가 2개 이상인 모형으로 확장될 수 있다. 예제에서 학교를 추출하고 학교내에서 학급을 추출하여 추출된 학급내의 학생들이 시험을 보면 다음과 같은 모형을 적용할 수 있다.\n\\[\ny_{ijk} = \\mu + a_i + b_{ij} + e_{ijk}\n\\] 위의 모형에서 \\(a_i\\)는 \\(N(0,\\sigma^2_a)\\)를 따르는 학교에 대한 임의효과, \\(b_{ij}\\)는 \\(N(0,\\sigma^2_b)\\)를 따르는 학급에 대한 임의효과, \\(e_{ijk}\\)는 \\(N(0,\\sigma^2_e)\\)를 따르는 학생에 대한 임의효과 또는 오차항으로 생각할 수 있다.\n임의효과 모형에 고정효과가 같이 포함되어 있는 모형을 혼합모형(mixed model)이라고 부르며 반응변수의 변동에 영향을 미치는 요인들 또는 예측변수 중에서 임의효과와 고정효과를 구별하여 정하고 동시에 모형에 포함시킬수 있다.\n예를 들어서 학교를 선택하여 과학시험을 볼 경우에 학기가 시작할 떄 과학교수법 두가지 중 하나를 임의화해서 각 학교에 배정하여 배정된 교수법으로 학생을 가르친 후에 시험을 보았다면 교수법에 대한 효과는 고정효과로 볼 수 있다. 따라서 다음과 같은 모형을 고려할 수 있다.\n\\[\ny_{ij} = \\mu + \\tau_{k(i)} + a_i + e_{ij}  \n\\tag{7.9}\\]\n여기서 \\(\\tau_{k(i)}\\)는 \\(i\\)번째 학교의 교수법에 대한 고정효과이다(교수법이 배정된 결과에 의하여 \\(k(i)=1\\) 또는 \\(k(i)=2\\)이 된다). 이 교수법에 대한 고정효과에 대해서는 두 교수법이 차이가 있는 지에 대한 검정이 주요한 관심사일 것이다 (\\(H_0: \\tau_1=\\tau_2\\))",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#반복측정자료",
    "href": "notes/random_effect.html#반복측정자료",
    "title": "7  반복측정자료",
    "section": "7.5 반복측정자료",
    "text": "7.5 반복측정자료\n반복측정자료(longitudinal data, repeated measurements)는 관측단위안에서 여러 개의 관측값을 측정한 자료의 형식을 말한다.\n예를 들어 환자가 병원을 여러 번 방문하고 방문시마다 혈압을 측정하였다면 한 명의 환자에서 반복 측정한 자료는 서로 독립이 아니다. 또한 가구조사(household survey)에서 가구원의 취업 여부, 건겅 상태등을 여러 해동안 매년 측정하는 경우 이러한 자료를 패널자료(panel data) 또는 longitudinal 자료라고 한다.\n이렇게 하나의 관측단위 안에서 측정한 자료들은 서로 독립이 아닌 특징이 있고 자료를 분석하는 경우 이러한 자료들의 종속구조를 고려하는 모형을 사용하는 것이 적절하다. 이렇게 반복측정자료에서 반복자료들의 공분산구조를 설정하는 통계적 방법들은 다양하지만 대표적으로 쉽게 사용할 수 있는 방법이 임의효과를 포함한 혼합모형을 사용하는 방법이다.\nlme4 패키지에 자료인 spleepstudy는 화물트럭 운전사들에 대한 수면부족 현상에 대하여 연구한 자료이다. 18명의 운전자들이 매일 3시간의 수면(부족한 수면)을 하면서 매일 일정한 동작의 반응시간을 10일동안 반복적으로 측정한 자료가 있다.\n한명의 운전사에게 10일 동안의 반응에 대한 측정자료 10개가 존재하므로 이는 반복측정 자료이며 이러한 10개의 자료는 독립이 아니다.\n일단 자료의 구조를 살펴보자. 반응변수 Reaction은 반응시간(ms)를 나타내며 설명변수로서 Days는 날짜(\\(t=0,1,2,\\dots,9\\)), Subject 는 운전자의 고유번호를 나타낸다.\n\nlibrary(lme4)\nlibrary(lmerTest)\nstr(sleepstudy)\n\n'data.frame':   180 obs. of  3 variables:\n $ Reaction: num  250 259 251 321 357 ...\n $ Days    : num  0 1 2 3 4 5 6 7 8 9 ...\n $ Subject : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nhead(sleepstudy,n=20)\n\n   Reaction Days Subject\n1  249.5600    0     308\n2  258.7047    1     308\n3  250.8006    2     308\n4  321.4398    3     308\n5  356.8519    4     308\n6  414.6901    5     308\n7  382.2038    6     308\n8  290.1486    7     308\n9  430.5853    8     308\n10 466.3535    9     308\n11 222.7339    0     309\n12 205.2658    1     309\n13 202.9778    2     309\n14 204.7070    3     309\n15 207.7161    4     309\n16 215.9618    5     309\n17 213.6303    6     309\n18 217.7272    7     309\n19 224.2957    8     309\n20 237.3142    9     309\n\n\n각 운전자에 대한 10일 간의 반응속도가 시간에 따라 어떻게 변하는 가를 알아보자. 전반적으로 시간이 지나면서 운전자들의 반응시간이 증가하고 있음을 알 수 있다. 또한 개인 별로 반응 시간의 변화와 패턴이 다르다는 것을 알 수 있다.\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) +\n     geom_point(size=0.7) +\n     facet_wrap(\"Subject\", labeller = label_both)+ \n     theme_bw()\n\n\n\n\n\n7.5.1 선형 회귀모형\n각 운전자 \\(i\\) 에 대하여 10일간 측정한 반응속도 \\(y_{ij}\\)를 시간에 대하여 선형모형으로 적합하면 개체별 선형회귀 모형(individual model) 을 다음과 같이 표시할 수 있다.\n\\[\ny_{ij} = \\beta_{0i} + \\beta_{1i} t_j + e_{ij},\\quad i=1,2,\\dots,18,\\quad j=1,2,\\dots,10\n\\tag{7.10}\\]\n여기서 오차항 \\(e_{ij}\\)은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n행렬식으로는 다음과 같이 나타낼 수 있다.\n\\[  \n\\pmb y_i =\\pmb X_i \\pmb \\beta_{i} +\\pmb e_i ,\\quad i=1,2,\\dots,18\n\\]\n여기서 \\[\n\\pmb y_i=\\begin{bmatrix}\ny_{i1} \\\\\ny_{i2} \\\\\n\\vdots \\\\\ny_{i,10}\n\\end{bmatrix},~ \\pmb X_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix}, \\pmb \\beta_i=\n\\begin{bmatrix}\n\\beta_{0i} \\\\\n\\beta_{1i} \\\\\n\\end{bmatrix}, \\pmb e_i=\n\\begin{bmatrix}\ne_{i1} \\\\\ne_{i2} \\\\\n\\vdots \\\\\ne_{i,10}\n\\end{bmatrix}\n\\]\n위의 식에서 \\(\\beta_{0i}\\)와 \\(\\beta_{1i}\\)는 \\(i\\)번째 운전사의 반응속도를 설명하는 회귀직선의 절편과 기울기이다.\n절편 \\(\\beta_{0i}\\)는 실험 시작때 반응속도를 의미하고 기울기 \\(\\beta_{1i}\\)는 실험이 진행되는 동안 반응속도가 어떻게 변하는 지 변화의 방향과 크기를 보여준다. 함수 lmList를 아래와 같이 이용하면 식 식 7.10 을 각 운전사마다 적합시켜 각각의 절편과 기울기를 구할 수 있다.\n\nlmf1 &lt;- lmList(Reaction ~ Days | Subject, sleepstudy)\nlmf1\n\nCall: lmList(formula = Reaction ~ Days | Subject, data = sleepstudy) \nCoefficients:\n    (Intercept)      Days\n308    244.1927 21.764702\n309    205.0549  2.261785\n310    203.4842  6.114899\n330    289.6851  3.008073\n331    285.7390  5.266019\n332    264.2516  9.566768\n333    275.0191  9.142045\n334    240.1629 12.253141\n335    263.0347 -2.881034\n337    290.1041 19.025974\n349    215.1118 13.493933\n350    225.8346 19.504017\n351    261.1470  6.433498\n352    276.3721 13.566549\n369    254.9681 11.348109\n370    210.4491 18.056151\n371    253.6360  9.188445\n372    267.0448 11.298073\n\nDegrees of freedom: 180 total; 144 residual\nResidual standard error: 25.59182\n\n\n위에서 고려한 개체별 선형회귀 직선들을 그림으로 그려보면 다음과 같이 나타난다.\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.5) + \n  stat_smooth(method = \"lm\",se=F,linewidth=0.5)+ \n  facet_wrap(\"Subject\", labeller = label_both)+ \n  theme_bw() \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n18개의 절편과 기울기는 큰 상관관계는 없는것으로 보이지만 약한 음의 상관계수가 나타났다. 절편과 기울기에 대한 분포를 보기 위하여 상자그림을 그려보면 평균을 중심으로 대칭인 분포를 보이고 있다.\n\ncor(coef(lmf1))\n\n            (Intercept)       Days\n(Intercept)   1.0000000 -0.1375534\nDays         -0.1375534  1.0000000\n\nplot(coef(lmf1),main=\"intercepts and slopes on drivers: sleep study \")\n\n\n\n\nboxplot(coef(lmf1)[1])\nboxplot(coef(lmf1)[2])\n\n\n\n그림 7.1: 개별 선형회귀모형에서 절볓과 기울기의 분포\n\n\n\n\n\n\n\n(a) 절편\n\n\n\n\n\n\n\n\n\n\n\n(b) 기울기\n\n\n\n\n\n\n\n\n\n\n\n\nboxplot(coef(lmf1)[1])\n\n\n\n\n이제 각 운전사에 대하여 회귀식을 따로 적합하지 않고 전체 운전사들의 자료를 모두 합쳐서 하나의 회귀식을 고려할 수 있다. 개체의 특성을 반영하는 모형이 아닌 전체 모집단에 대한 모집단 평균 모형(population mean model) 을 고려하는 것이다.\n\\[\ny_{ij} = \\beta_0 + \\beta_1 t_j + e_{ij} ,\\quad i=1,2\\dots,18,  j=1,2, \\dots, 10\n\\tag{7.11}\\]\n여기서 오차항은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n위와 같은 전체 운전사 집단의 관측값을 운전자의 특성을 고려하지 않고 세운 모형으로서 시간에 따른 반응시간에 대한 모집단의 전체적인 평균적 함수 관계를 파악하는 모형이라고 할 수 있다.\n\nlmpop &lt;- lm(Reaction ~ Days, sleepstudy)\nsummary(lmpop)\n\n\nCall:\nlm(formula = Reaction ~ Days, data = sleepstudy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-110.848  -27.483    1.546   26.142  139.953 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.610  38.033  &lt; 2e-16 ***\nDays          10.467      1.238   8.454 9.89e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47.71 on 178 degrees of freedom\nMultiple R-squared:  0.2865,    Adjusted R-squared:  0.2825 \nF-statistic: 71.46 on 1 and 178 DF,  p-value: 9.894e-15\n\nwith(sleepstudy, plot(Days, Reaction,main=\"Population and individual regression lines\"))\nabline(a=coef(lmpop)[1], b=coef(lmpop)[2],lwd=3)\nfor ( i in 1:18 ) {\n  xx &lt;- as.numeric(coef(lmf1)[i,])\nabline(a=xx[1],b=xx[2], lty=2)\n}\n\n\n\n\n식 7.10 의 개체별 선형회귀 모형에서 얻은 모든 절편들과 기울기들의 평균을 구하면 다음과 같다.\n\napply(coef(lmf1),2,mean)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n다음으로 식 7.11 의 선형회귀 모형에서 얻은 절편과 기울기의 평균을 구하면 다음과 같다.\n\ncoef(lmpop)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n각 운전사에 대하여 식 7.10 의 개체별로 적합한 회귀식에서 구한 계수들\\((\\hat \\beta_{0i}, \\hat \\beta_{1i})\\) 와 식 7.11 의 모집단 평균 회귀모형에서 구한서 계수 \\((\\hat \\beta_{0}, \\hat \\beta_{1})\\)의 관계를 보면 개체별로 적합한 회귀 계수들의 평균이 모집단 평균 회귀모형의 계수와 매우 가까운 사실을 알 수 있다.\n\n\n7.5.2 임의계수 모형\n앞 절의 모형과 분석에서 알 수 있듯이 한 개체에 대하여 여러 개의 관측값을 측정한 자료에 회귀방정식을 각각 적합시켜보고 또한 개체의 특성을 고려하지않은 전체 모형을 적합해보면 다음과 같은 두 가지 결과를 볼 수 있다.\n\n각 개체별 회귀식은 개인의 특성을 반영한다. 즉, 개체에 따라 시간에 따른 반응시간의 변화가 다르게 나타난다.\n하지만 개인별로 볼 때도 전체적으로는 시간에 따라서 반응시간이 증가하는 경향이 있음을 알 수 있다.\n전체 자료에 적합한 모형을 보면 개인별로 적합한 모형의 공통적인 성격, 즉 시간에 따른 반응시간의 증가를 알 수 있다.\n이러한 결과를 보고 각 개인의 변화는 전체적인 변화를 따르면서 각 개인의 특성이 반영되었다고 가정할 수 있다.\n\n위에서 논의하였듯이 전체적인 경향과 개인의 특성을 동시에 고려할 수 있는 모형이 생각할 수 있고 이러한 모형이 다음과 같은 모형이다.\n\\[\ny_{ij} = (\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i}) t_j + e_{ij}\n\\tag{7.12}\\]\n식 7.12 는 절편과 기울기가 두 개의 구성 요소로 더해져서 표현된다. 기울기는 \\(\\beta_1+b_{1i}\\)로서 나타내어지며 \\(\\beta_1\\)은 모집단이 가지는 공통적인 경향을 반영하는 모수이고 \\(b_{1i}\\)는 \\(i\\) 번째 개체의 특성을 반영한 확률변수이다. 절편도 유사한 형식으로 구성된다.\n각 개인에 대한 특성을 나타내는 변수 \\((b_{0i}, b_{1i})\\) 을 확률변수로 설정하고 이를 모수(\\(\\beta_0, \\beta_1)\\) (parameter or fixed effect)와 구별하여 임의효과(random effect)라고 한다. 임의효과는 모집단을 구성하는 개인이 표본에 추출되었다고 생각하며 확률분포를 따른다고 가정한다. 반복측정자료에서 인의효과를 공통으로 가지고 있는 관측치는 독립이 아니게 돼며 따라서 같은 개체에서 나온 관측값은 독립이 아니다.\n18명에 대한 회귀직선의 절편과 기울기를 보면 개인의 차이에 따른 변동을 볼 수 있으며 이러한 각 개인간의 변동을 임의효과를 이용하여 다음과 같은 모형을 생각해보자.\n\\[\n\\pmb \\beta_i=\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\end{bmatrix}\n+\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix}\n=\n\\pmb \\beta + {\\pmb b}_i\n\\]\n\\[\n{\\pmb b}_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b1} & \\rho \\sigma_{b1} \\sigma_{b2}\\\\\n\\rho \\sigma_{b1} \\sigma_{b2} & \\sigma^2_{b2} \\\\\n\\end{bmatrix}\n\\right )\n\\]\n위의 모형은 각 개인의 회귀직선에서 각 절편과 기울기가 전체평균 \\(\\beta_0\\)와 \\(\\beta_1\\)를 따르며 각 개인의 차이는 전체평균에 임의효과인 \\(b_{0i}\\)와 \\(b_{1i}\\)가 더해져서 나타난다는 것을 의미한다.\n이변량 임의효과 \\(b_{0i}\\)와 \\(b_{1i}\\)는 이변량 정규분포를 따르며 각각의 분산과 상관계수가 \\(\\sigma^2_{b1}\\), \\(\\sigma^2_{b2}\\), \\(\\rho\\)이다.\n다른 개체에 대한 임의효과는 서로 독립이며 임의 효과와 오차항은 독립이다. 여기서 오차항은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n\\[  Cov(\\pmb b_{i}, \\pmb b_{j}) =\\pmb 0 \\text{ when } i \\ne j,\\quad\nCov(\\pmb b_{i}, e_{jk}) =\\pmb 0 \\text{ for all } i,j,k \\]\n\n\n7.5.3 혼합효과 모형\n임의계수모형을 각 개인 \\(i\\)에 대하여 행렬식으로 표시하면 다음과 같은 혼합효과모형(mixed effects model)으로 나타낼 수 있다. 혼합효과모형은 반응변수에 영향을 미치는 효과를 고정효과와 임의효과로 나누어 설명하는 모형이다.\n\\[  \n\\pmb y_i = \\pmb X_i \\pmb \\beta + \\pmb Z_i \\pmb b_i + \\pmb e_i\n\\]\n여기서\n\\[  \n\\pmb y_i=\\begin{bmatrix}\ny_{i1} \\\\\ny_{i2} \\\\\n\\vdots \\\\\ny_{i,10}\n\\end{bmatrix},~\\pmb X_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix}, \\pmb  \\beta=\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\end{bmatrix}, ~\\pmb Z_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix},~ \\pmb b_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix},~\n\\pmb  e_i=\n\\begin{bmatrix}\ne_{i1} \\\\\ne_{i2} \\\\\n\\vdots \\\\\ne_{i,10}\n\\end{bmatrix}\n\\]\n위의 각 개인에 대한 모형을 모두 합쳐서 하나의 혼합효과모형으로 나타내면 다음과 같이 표현할 수 있다.\n\\[\n\\pmb  y = \\pmb  X \\pmb \\beta + \\pmb Z \\pmb b + \\pmb e\n\\tag{7.13}\\] \\end{equation}\n여기서 반응변수 벡터 \\(\\pmb y\\)와 고정효과 \\(\\pmb \\beta\\)에 대한 계획행렬 \\(X\\)는 각 개인의 반응변수 벡터 \\(\\pmb y_i\\)와 \\(\\pmb X_i\\)를 행으로 쌓아놓은 것으로 표현된다. 오차항에 대한 벡터 \\(\\pmb e\\)도 동일한 형식의 벡터이다.\n\\[  \n\\pmb y_i=\\begin{bmatrix}\n\\pmb y_{1} \\\\\n\\pmb y_{2} \\\\\n\\vdots \\\\\n\\pmb y_{18}\n\\end{bmatrix},~\\pmb X =\n\\begin{bmatrix}\n\\pmb X_1 \\\\\n\\pmb X_2 \\\\\n\\vdots \\\\\n\\pmb  X_{18}\n\\end{bmatrix}\n~ \\pmb e =\n\\begin{bmatrix}\n\\pmb e_1 \\\\\n\\pmb e_2 \\\\\n\\vdots  \\\\\n\\pmb e_{18}\n\\end{bmatrix}\n\\]\n임의효과 벡터 \\({\\pmb b}\\) 는 각 개인에 대한 임의효과벡터 \\(\\pmb b_i\\)를 행으로 쌓아놓은것과 같고 임의효과에 대한 계획행렬 \\(\\pmb Z\\)는 각 개인의 계획행렬 \\(\\pmb Z_i\\)를 대각원소로 같은 행렬이다.\n\\[\n\\pmb b=\\begin{bmatrix}\n\\pmb b_{1} \\\\\n\\pmb b_{2} \\\\\n\\vdots \\\\\n\\pmb b_{18}\n\\end{bmatrix},~\\pmb Z =\n\\begin{bmatrix}\n\\pmb Z_1 & 0 & \\dots & 0 \\\\\n0   & \\pmb Z_2 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots  \\\\\n0 & 0 & \\dots & \\pmb Z_{18}\n\\end{bmatrix}\n\\]\n임의효과는 개인의 특성을 설명하는 효과로서 모집단을 구성하는 개인이 표본에 추출되었다고 생각하며 확률분포를 따른다고 가정한다. 반복측정자료에서 임의효과를 공통으로 가지고 있는 관측치는 독립이 아니게 돼며 따라서 같은 개체에서 나온 관측값은 독립이 아니다.\n\n\n7.5.4 선형혼합모형의 적합\n혼합모형 식 7.13 은 lmer() 함수를 이용하여 적합시켜보자. 모형식에서 (1 + Days|Subject) 는 각 개체 Subject 에 대하여 절편 1 과 기울기 Days에 임의효과를 포함한다고 지정한다.\n\nfm1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy)\nsummary(fm1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  &lt; 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n\n\n위의 혼합모형 적합결과를 살펴보자. 첫째로 고정효과에 대한 추정식은 다음과 같다\n\nfixef(fm1)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n\\[\n\\begin{bmatrix}\n\\hat {\\beta}_{0} \\\\\n\\hat {\\beta}_{1} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n251.4051048 \\\\\n10.467286\n\\end{bmatrix}\n\\]\n또한 오차항에 대한 분산 및 임의효과의 분산성분과 상관계수는 다음과 같이 나타난다.\n\nVarCorr(fm1)\n\n Groups   Name        Std.Dev. Corr \n Subject  (Intercept) 24.7407       \n          Days         5.9221  0.066\n Residual             25.5918       \n\n\n\\[\n\\begin{aligned}\n\\hat \\sigma_{b1} & =  24.740658 \\\\\n\\hat \\sigma_{b2} & =  5.9221377 \\\\\n\\hat \\rho & = 0.0655512 \\\\\n\\hat \\sigma_e & = 25.5917957\n\\end{aligned}\n\\]\n\n\n7.5.5 임의효과에 대한 예측\n이제 임의효과 \\(\\pmb b_i =(b_{0i}, b_{1i})^t\\)에 대한 예측(prediction)을 생각해보자. 우리는 오직 관측벡터 \\(\\pmb y_i\\)만을 관측하고 임의효과 \\(\\pmb b_i\\)는 관측을 할 수 없는 확률변수이다. 하지만 주어진 관측벡터와 추정된 분산으로 임의효과의 값을 예측할 수있으며 그 결과는 다음과 같다.\n\nre &lt;- ranef(fm1)$Subject\nre\n\n    (Intercept)        Days\n308   2.2585509   9.1989758\n309 -40.3987381  -8.6196806\n310 -38.9604090  -5.4488565\n330  23.6906196  -4.8143503\n331  22.2603126  -3.0699116\n332   9.0395679  -0.2721770\n333  16.8405086  -0.2236361\n334  -7.2326151   1.0745816\n335  -0.3336684 -10.7521652\n337  34.8904868   8.6282652\n349 -25.2102286   1.1734322\n350 -13.0700342   6.6142178\n351   4.5778642  -3.0152621\n352  20.8636782   3.5360011\n369   3.2754656   0.8722149\n370 -25.6129993   4.8224850\n371   0.8070461  -0.9881562\n372  12.3145921   1.2840221\n\n\n예를 들어 첫 번째 운전자에 대한 절편과 기울기의 임의효과에 대한 예측값은 다음과 같다.\n\\[ {\\hat b}_{0i} = 2.2585509, \\quad  {\\hat b}_{1i} =   9.1989758 \\] 위에서 구한 절편과 기울기에 대한 임의효과들의 산포도를 보면 다음과 같다.\n\nplot(re, main =\"prediction of random effects \")\n\n\n\n\n예측된 각 개인의 절편과 기울기에 대한 임의효과의 예측값 \\({\\hat b}_{0i}\\)과 \\({\\hat b}_{1i}\\)에 고정효과의 추정량 \\(\\hat \\beta_0\\)와 \\(\\hat \\beta_1\\)에 각각 더해주면 각 개인의 절편과 기울기에 대한 예측값을 구할 수 있다.\n\\[\n{\\hat \\beta}_{0i} = \\hat \\beta_0 + {\\hat b}_{0i} , \\quad\n{\\hat \\beta}_{1i} = \\hat \\beta_1 + {\\hat b}_{1i}\n\\]\n\nbeta &lt;- matrix(as.numeric(fixef(fm1)),18,2,byrow=T)\nbeta + re \n\n    (Intercept)       Days\n308    253.6637 19.6662617\n309    211.0064  1.8476053\n310    212.4447  5.0184295\n330    275.0957  5.6529356\n331    273.6654  7.3973743\n332    260.4447 10.1951090\n333    268.2456 10.2436499\n334    244.1725 11.5418676\n335    251.0714 -0.2848792\n337    286.2956 19.0955511\n349    226.1949 11.6407181\n350    238.3351 17.0815038\n351    255.9830  7.4520239\n352    272.2688 14.0032871\n369    254.6806 11.3395008\n370    225.7921 15.2897709\n371    252.2122  9.4791297\n372    263.7197 11.7513080\n\n\n예를 들어 선형혼합모형에서 첫 번째 운전자에 대한 절편과 기울기에 대한 추정값은 다음과 같다.\n\\[\n{\\hat \\beta}_{0i} =  253.6637,  \\quad {\\hat \\beta}_{1i} = 19.6662617\n\\]\n\n\n7.5.6 수축 현상\n각 운전자에 대해 개체별 회귀직선 식 7.10 과 임의계수 모형 식 7.10 적합시켜서 얻은 18개의 절편과 기울기를 비교해보자.\n먼저 개체별 회귀직선에서 적합한 절편과 기울기는 다음과 같다.\n\nab_lines_ind &lt;- coef(lmf1) %&gt;% \n  tibble::rownames_to_column(\"Subject\") %&gt;% \n  rename(intercept = `(Intercept)`) %&gt;%\n  tibble::add_column(Model = \"개체별 모형\")\nab_lines_ind\n\n   Subject intercept      Days       Model\n1      308  244.1927 21.764702 개체별 모형\n2      309  205.0549  2.261785 개체별 모형\n3      310  203.4842  6.114899 개체별 모형\n4      330  289.6851  3.008073 개체별 모형\n5      331  285.7390  5.266019 개체별 모형\n6      332  264.2516  9.566768 개체별 모형\n7      333  275.0191  9.142045 개체별 모형\n8      334  240.1629 12.253141 개체별 모형\n9      335  263.0347 -2.881034 개체별 모형\n10     337  290.1041 19.025974 개체별 모형\n11     349  215.1118 13.493933 개체별 모형\n12     350  225.8346 19.504017 개체별 모형\n13     351  261.1470  6.433498 개체별 모형\n14     352  276.3721 13.566549 개체별 모형\n15     369  254.9681 11.348109 개체별 모형\n16     370  210.4491 18.056151 개체별 모형\n17     371  253.6360  9.188445 개체별 모형\n18     372  267.0448 11.298073 개체별 모형\n\n\n이제 식 7.12 의 임의계수 모형에서 적합한 기울기와 절편은 다음과 같다.\n\nab_lines_random &lt;- coef(fm1)[[\"Subject\"]] %&gt;% \n  tibble::rownames_to_column(\"Subject\") %&gt;% \n  rename(intercept = `(Intercept)`) %&gt;%\n  tibble::add_column(Model = \"임의계수 모형\")\nab_lines_random \n\n   Subject intercept       Days         Model\n1      308  253.6637 19.6662617 임의계수 모형\n2      309  211.0064  1.8476053 임의계수 모형\n3      310  212.4447  5.0184295 임의계수 모형\n4      330  275.0957  5.6529356 임의계수 모형\n5      331  273.6654  7.3973743 임의계수 모형\n6      332  260.4447 10.1951090 임의계수 모형\n7      333  268.2456 10.2436499 임의계수 모형\n8      334  244.1725 11.5418676 임의계수 모형\n9      335  251.0714 -0.2848792 임의계수 모형\n10     337  286.2956 19.0955511 임의계수 모형\n11     349  226.1949 11.6407181 임의계수 모형\n12     350  238.3351 17.0815038 임의계수 모형\n13     351  255.9830  7.4520239 임의계수 모형\n14     352  272.2688 14.0032871 임의계수 모형\n15     369  254.6806 11.3395008 임의계수 모형\n16     370  225.7921 15.2897709 임의계수 모형\n17     371  252.2122  9.4791297 임의계수 모형\n18     372  263.7197 11.7513080 임의계수 모형\n\n\n이제 개체별 회귀직선 식 7.10 과 임의계수 모형 식 7.10 적합시켜서 얻은 18명의 개체에 대한 선형회귀 모형을 그림으로 그려보자.\n\nab_lines_pop &lt;- data_frame(\n  Subject = unique(sleepstudy$Subject),\n  intercept = coef(lm(Reaction ~ Days, sleepstudy))[1],\n  Days = coef(lm(Reaction ~ Days, sleepstudy))[2],\n  Model = \"모집단 평균모형\"\n)\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\nall_lines &lt;- bind_rows(ab_lines_pop, ab_lines_ind, ab_lines_random)\n\nhead(all_lines,5) \n\n# A tibble: 5 × 4\n  Subject intercept  Days Model          \n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n1 308          251.  10.5 모집단 평균모형\n2 309          251.  10.5 모집단 평균모형\n3 310          251.  10.5 모집단 평균모형\n4 330          251.  10.5 모집단 평균모형\n5 331          251.  10.5 모집단 평균모형\n\n\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.7) + \n  geom_abline(aes(intercept = intercept, slope = Days, color=Model), data = all_lines) +\n  facet_wrap(\"Subject\") + \n  theme_bw() + \n  theme(legend.position = \"bottom\") \n\n\n\n\n이렇게 혼합모형을 통해서 얻은 각 개인의 절편과 기울기에 대한 예측값과 각각의 개체별 선형회귀 직선을 따로 적합하여 얻은 절편과 기울기의 관계를 그림으로 그려보면 다음과 같다.\n혼합모형을 통해서 얻은 각 개인의 절편과 기울기는 절편과 기울기의 전체평균값 방향으로 수축되는 경향(shrinkage)을 볼수있다.\n\nggplot(bind_rows(ab_lines_ind, ab_lines_random)) + \n  aes(x = intercept, y = Days, color = Model) + \n  geom_point() + \n  geom_point(data = ab_lines_pop) + \n  geom_path(aes(group = Subject), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  theme_bw() + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"회귀계수의 수축\")\n\n\n\n\n\n\n7.5.7 모형의 비교\n위에서 고려한 임의계수모형 식 7.12 에서는 절편과 기울기에 대한 2개의 임의효과 \\(b_{0i}\\) 와 \\(b_{1i}\\) 를 고려하고 더 나아가 두 개의 임의효과가 독립이 아니며 상관계수가 \\(\\rho\\)라고 가정하였다.\n앞에서 추정결과에 의하면 두 개의 임의효과의 상관계수의 추정값은 \\(\\hat \\rho = 0.066\\) 으로 거의 0에 가깝다. 이러한 결과에 근거하여 두 임의효과가 독립인 축소모형을 고려해 보자. 즉 임의계수모형 식 7.12 에서 임의효과의 상관계수가 \\(\\rho=0\\)인 임의효과의 분포를 다음과 같이 가정한다.\n\\[\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b1} & 0\\\\\n0 & \\sigma^2_{b2} \\\\\n\\end{bmatrix}\n\\right )\n\\]\n이러한 모형을 아래와 같이 적합시키면 추정결과는 다음과 같다. 아래 모형식에서 (1 + Days||Subject) 는 각 개체 Subject 에 대하여 절편 1 과 기울기 Days에 임의효과를 포함한다고 지정하며 한개의 바 | 대신 두 개의 바 || 를 사용하면 임의효과가 독립이라는 것을 지정한다.\n\nfm2 &lt;- lmer(Reaction ~ 1 + Days + (1+Days || Subject) , sleepstudy)\nsummary(fm2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days || Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9626 -0.4625  0.0204  0.4653  5.1860 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n Subject   (Intercept) 627.57   25.051  \n Subject.1 Days         35.86    5.988  \n Residual              653.58   25.565  \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.885  18.156  36.513  &lt; 2e-16 ***\nDays          10.467      1.560  18.156   6.712 2.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.184\n\n\n상관계수가 0인 모형에 대한 추정 결과는 상관계수가 있는 모형과 크게 다르지 않다.\n두 모형, 즉 절편과 기울기에 대한 두 임의효과가 종속인지 또는 독립인지에 대한 두 모형을 AIC(Akaike Information Criteris)와 BIC(Bayesian Information Criteria)로 비교한 결과이다. 두 모형 간의 차이는 거의 없는 것으로 판단된다.\n\nc(AIC(fm1) , BIC(fm1))\n\n[1] 1755.628 1774.786\n\nc(AIC(fm2), BIC(fm2))\n\n[1] 1753.669 1769.634\n\n\n더나아가 anova 함수를 이용하여 두 모형의 차이를 검정한 결과는 두 모형 간의 차이가 없다는 것이다. 참고할 점은 혼합모형에서의 모형을 비교하는 분산분석에 의한 검정은 효율이 떨어질 수 있기 때문에 주의해야 한다.\n\nanova(fm1,fm2)\n\nrefitting model(s) with ML (instead of REML)\n\n\nData: sleepstudy\nModels:\nfm2: Reaction ~ 1 + Days + (1 + Days || Subject)\nfm1: Reaction ~ 1 + Days + (1 + Days | Subject)\n    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)\nfm2    5 1762.0 1778.0 -876.00   1752.0                     \nfm1    6 1763.9 1783.1 -875.97   1751.9 0.0639  1     0.8004",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#필요한-패키지와-함수",
    "href": "notes/logistic_practice.html#필요한-패키지와-함수",
    "title": "8  로지스틱 회귀모형 실습 1",
    "section": "8.1 필요한 패키지와 함수",
    "text": "8.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nsource(\"../R/functions.R\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#분석-자료",
    "href": "notes/logistic_practice.html#분석-자료",
    "title": "8  로지스틱 회귀모형 실습 1",
    "section": "8.2 분석 자료",
    "text": "8.2 분석 자료\n로지스틱 회귀모형에 대한 분석은 교과서 Faraway (2016) 에서 사용된 wcgs 데이터프레임을 사용한다.\n데이터프레임 wcgs 은 Western Collaborative Group Study 에 참가한 3154명의 39-59 세 남성에 대한 신체 자료와 관상동맥질환(coronary heat disease)의 발병 여부에 대한 자료이다.\n\nhelp(wcgs)\n\n\nhead(wcgs)\n\n  age height weight sdp dbp chol behave cigs dibep chd  typechd timechd   arcus\n1  49     73    150 110  76  225     A2   25     A  no     none    1664  absent\n2  42     70    160 154  84  177     A2   20     A  no     none    3071 present\n3  42     69    160 110  78  181     B3    0     B  no     none    3071  absent\n4  41     68    152 124  78  132     B4   20     B  no     none    3064  absent\n5  59     70    150 144  86  255     B3   20     B yes infdeath    1885 present\n6  44     72    204 150  90  182     B4    0     B  no     none    3102  absent\n\n\n반응 변수는 chd 로서 만약 coronary heat disease 가 발생한 여부를 yes 와 no 로 표시한다.\n\nstr(wcgs)\n\n'data.frame':   3154 obs. of  13 variables:\n $ age    : int  49 42 42 41 59 44 44 40 43 42 ...\n $ height : int  73 70 69 68 70 72 72 71 72 70 ...\n $ weight : int  150 160 160 152 150 204 164 150 190 175 ...\n $ sdp    : int  110 154 110 124 144 150 130 138 146 132 ...\n $ dbp    : int  76 84 78 78 86 90 84 60 76 90 ...\n $ chol   : int  225 177 181 132 255 182 155 140 149 325 ...\n $ behave : Factor w/ 4 levels \"A1\",\"A2\",\"B3\",..: 2 2 3 4 3 4 4 2 3 2 ...\n $ cigs   : int  25 20 0 20 20 0 0 0 25 0 ...\n $ dibep  : Factor w/ 2 levels \"A\",\"B\": 1 1 2 2 2 2 2 1 2 1 ...\n $ chd    : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 2 1 1 1 1 1 ...\n $ typechd: Factor w/ 4 levels \"angina\",\"infdeath\",..: 3 3 3 3 2 3 3 3 3 3 ...\n $ timechd: int  1664 3071 3071 3064 1885 3102 3074 3071 3064 1032 ...\n $ arcus  : Factor w/ 2 levels \"absent\",\"present\": 1 2 1 1 2 1 1 1 1 2 ...\n\n\n이번 분석에서는 wcgs 자료에서 dibep 와 마지막 3개 변수를 제외하고 사용하겠다.\n\nwcgs_1 &lt;- wcgs %&gt;%\n  dplyr::select(!(typechd:arcus) ) %&gt;% dplyr::select(!dibep )\nhead(wcgs_1)\n\n  age height weight sdp dbp chol behave cigs chd\n1  49     73    150 110  76  225     A2   25  no\n2  42     70    160 154  84  177     A2   20  no\n3  42     69    160 110  78  181     B3    0  no\n4  41     68    152 124  78  132     B4   20  no\n5  59     70    150 144  86  255     B3   20 yes\n6  44     72    204 150  90  182     B4    0  no",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#로지스틱-회귀모형",
    "href": "notes/logistic_practice.html#로지스틱-회귀모형",
    "title": "8  로지스틱 회귀모형 실습 1",
    "section": "8.3 로지스틱 회귀모형",
    "text": "8.3 로지스틱 회귀모형\n이제 다음과 같이 개의 설명 변수가 포함된 로지스틱 회귀모형을 적합해 보자.\n\nfit_all &lt;- glm(chd ~ age +  height +  weight + sdp + dbp +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_all)\n\n\nCall:\nglm(formula = chd ~ age + height + weight + sdp + dbp + chol + \n    behave + cigs, family = binomial, data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -12.989034   2.336470  -5.559 2.71e-08 ***\nage           0.065068   0.012125   5.367 8.03e-08 ***\nheight        0.015824   0.033141   0.477  0.63302    \nweight        0.007874   0.003881   2.029  0.04248 *  \nsdp           0.017536   0.006395   2.742  0.00611 ** \ndbp           0.000121   0.010833   0.011  0.99109    \nchol          0.011076   0.001522   7.278 3.38e-13 ***\nbehaveA2      0.088266   0.222589   0.397  0.69171    \nbehaveB3     -0.602705   0.244216  -2.468  0.01359 *  \nbehaveB4     -0.499214   0.320978  -1.555  0.11988    \ncigs          0.020998   0.004280   4.906 9.32e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1580.4  on 3131  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1602.4\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n8.3.1 회귀계수의 의미\n위의 결과에서 회귀계수의 의미에 대하여 살펴보자. 먼저 하루에 평균 피우는 담배의 개수 cigs 의 의미는 다음과 같다.\n\nfit_all$coefficients['cigs']\n\n      cigs \n0.02099804 \n\n\n설명변수 cigs 의 계수가 0.020998 이므로 담배의 개수가 1개 증가하면 심장병 관련 질환의발생 확률이 다음과 같이 오즈비 단위로 증가 한다.\n아래 식에서 유의할 점은 다른 설명변수들은 모두 같다는 가정하에서 성립한다는 것이다.\n\\[ \\frac{\\text{odd(cigs = a+1)}}{\\text{odd(cigs = a)}} =\n\\frac{\\tfrac{P(\\text{chd =  y} | \\text{cigs = a+1})}{1- P(\\text{chd = y} | \\text{cigs = a+1} )}}\n{\\tfrac{P(\\text{chd = y} | \\text{cigs = a})}{1- P(\\text{chd = y} | \\text{cigs = a})}}= \\exp(0.020998) = 1.02122\n\\tag{8.1}\\]\n이제 좀 더 이해하기 쉬운 상대위험으로 회귀계수의 영향에 대하여 알아보자.\n먼저 연속형 변수들의 평균을 구하고 데이터프레임으로 만들자. 또한 범주형 변수인 behave 도 하나의 레벨을 추가하자.\n\nmean_vars &lt;- get_means(wcgs_1) %&gt;% t() %&gt;% as.data.frame()\nmean_vars$behave &lt;- 'A2'\nmean_vars\n\n       age   height   weight      sdp      dbp     chol     cigs behave\n1 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 11.60051     A2\n\n\n이제 데이터프레임 mean_vars 에서 주어진 설명변수의 값에서 성공의 확률을 예측해 보자\n\\[ \\hat P(y=1| \\pmb x) = \\frac{1}{1+\\exp(-[\\hat \\beta_0 + \\hat \\beta_1 x_1 + \\dots + \\hat \\beta_p x_p])} \\tag{8.2}\\]\n\npredict(fit_all, newdata=mean_vars, type = \"response\")\n\n         1 \n0.08085642 \n\n\n참고로 함수 prediction 은 선형예측식의 값만을 구할 수 있다.\n\\[ \\hat \\eta = \\hat \\beta_0 + \\hat \\beta_1 x_1 + \\dots + \\hat \\beta_p x_p \\]\n\npredict(fit_all, newdata=mean_vars, type = \"link\")\n\n        1 \n-2.430767 \n\n\n위에서 type = \"link\" 는 default 선택문이다.\n\npredict(fit_all, newdata=mean_vars)\n\n        1 \n-2.430767 \n\n\n확률로 바꿀려면 다음과 같이 식 8.2 을 이용하면 된다.\n\n1/(1+exp(-predict(fit_all, newdata=mean_vars, type = \"link\")))\n\n         1 \n0.08085642 \n\n\n위와 같이 계산은 logit 함수의 역함수인 ilogit 함수를 이용하여 구할 수 있다\n\nfaraway::ilogit(predict(fit_all, newdata=mean_vars, type = \"link\"))\n\n         1 \n0.08085642 \n\n\n이제 데이터프레임 mean_vars 의 두 번째 행에 cigs 가 1 증가한 관측값을 추가하자.\n\nsel_var &lt;- 'cigs'\nmean_vars_df &lt;- rbind(mean_vars,mean_vars)\nmean_vars_df[2,c(sel_var)] &lt;- mean_vars_df[2,c(sel_var)] + 1\nmean_vars_df\n\n       age   height   weight      sdp      dbp     chol     cigs behave\n1 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 11.60051     A2\n2 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 12.60051     A2\n\n\n다시 예측값을 구해보면 다음과 같다.\n\npre_p &lt;- predict(fit_all, newdata=mean_vars_df, type = \"response\")\npre_p\n\n         1          2 \n0.08085642 0.08243076 \n\n\n위의 결과로 오즈비를 구해보면 식 8.1 에 나타난 값과 같다.\n\n(pre_p[2]/(1-pre_p[2]))/(pre_p[1]/(1-pre_p[1]))\n\n      2 \n1.02122 \n\n\n이제 우리는 확률의 예측값을 계산할 수 있으므로 상대위험을 구해보면 다음과 같다.\n\npre_p[2]/pre_p[1]\n\n       2 \n1.019471 \n\n\n이제 age 도 비슷한 분석을 해보자. 나이는 30세와 60세의 상대위험을 계산해 보자.\n\nsel_var &lt;- 'age'\nmean_vars_df &lt;- rbind(mean_vars,mean_vars)\nmean_vars_df[1,c(sel_var)] &lt;- 30\nmean_vars_df[2,c(sel_var)] &lt;- 60\npre_p &lt;- predict(fit_all, newdata=mean_vars_df, type = \"response\")\npre_p[2]/pre_p[1]\n\n       2 \n5.974438 \n\n\n이제 범주형 변수에 대한 회귀계수의 의미를 살펴보자. 먼저 범주형변수 behave 가 가질 수 있는 범주를 보자.\n\nlevels(wcgs_1$behave)\n\n[1] \"A1\" \"A2\" \"B3\" \"B4\"\n\n\n또한 범주형변수 behave 에 관련된 회귀계수의 추정값을 보자.\n\ncoef1 &lt;- fit_all$coefficients \ncoef1\n\n  (Intercept)           age        height        weight           sdp \n-1.298903e+01  6.506806e-02  1.582390e-02  7.873538e-03  1.753588e-02 \n          dbp          chol      behaveA2      behaveB3      behaveB4 \n 1.209992e-04  1.107574e-02  8.826567e-02 -6.027047e-01 -4.992142e-01 \n         cigs \n 2.099804e-02 \n\n\n위의 결과에서 behave 의 A0 에 대한 게수의 값은 0이다. 즉 다음과 같은 식이 성립한다.\n\\[\n\\begin{aligned}\n\\text{logit} [ P(y=1 | \\text{behave = A0}) ] = \\cdots & + 0 + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = A2}) ] = \\cdots & + (0.0882657) + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = B3}) ]= \\cdots & + (-0.6027047) + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = B4}) ]= \\cdots & + (-0.4992142) + \\cdots\n\\end{aligned}\n\\]\n따라서 다른 설명 변수들의 값이 고정되어 있다면, 예를 들어 behave 의 두 범주 A0 와 A2 에 대한 오즈비는 다음과 같다.\n\\[\n\\frac{\\text{odd(behave = A2)}}{\\text{odd(behave = A0)}} =\n\\frac{\\tfrac{P(\\text{chd =  y} | \\text{ehave = A2})}{1- P(\\text{chd = y} | \\text{behave = A2)} )}}\n{\\tfrac{P(\\text{chd = y} | \\text{ehave = A0})}{1- P(\\text{chd = y} | \\text{ehave = A0})}}= \\exp(0.0882657 - 0) = 1.0922783\n\\tag{8.3}\\]\n\n\n8.3.2 모형의 비교: 내포된 모형\n이제 몇 개의 변수를 제외한 모형을 더적합해 보자. 모형에서 height 와 dbp 를 제외하고 적합해 보자.\n\nfit_1 &lt;- glm(chd ~ age +  weight + sdp  +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_1)\n\n\nCall:\nglm(formula = chd ~ age + weight + sdp + chol + behave + cigs, \n    family = binomial, data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -11.989331   0.995324 -12.046  &lt; 2e-16 ***\nage           0.064732   0.012103   5.348 8.87e-08 ***\nweight        0.008874   0.003173   2.797  0.00516 ** \nsdp           0.017326   0.004095   4.231 2.33e-05 ***\nchol          0.011005   0.001513   7.274 3.49e-13 ***\nbehaveA2      0.090232   0.222140   0.406  0.68460    \nbehaveB3     -0.602010   0.243734  -2.470  0.01351 *  \nbehaveB4     -0.498449   0.320571  -1.555  0.11997    \ncigs          0.021198   0.004226   5.017 5.26e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1580.7  on 3133  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1598.7\n\nNumber of Fisher Scoring iterations: 6\n\n\n이제 두 개의 모형 fit_all 과 fit_1 을 비교해 보자. 두 모형의 편차(deviance)는 다음과 같다.\n\ndeviance(fit_all)\n\n[1] 1580.446\n\ndeviance(fit_1)\n\n[1] 1580.676\n\n\n두 개의 모형 fit_all 과 fit_1 의 편차가 거의 차이가 없으므로 모형에서 height 와 dbp 를 제외하더라도 모형의 설명력이 거의 차이가 없다고 볼 수 있다.\n이제 3개의 설명변수 height , dbp, weight 를 제외한 모형을 적합해 보자.\n\nfit_2 &lt;- glm(chd ~ age  + sdp  +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_2)\n\n\nCall:\nglm(formula = chd ~ age + sdp + chol + behave + cigs, family = binomial, \n    data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -10.582582   0.843068 -12.552  &lt; 2e-16 ***\nage           0.061049   0.012003   5.086 3.66e-07 ***\nsdp           0.019909   0.003946   5.046 4.51e-07 ***\nchol          0.010950   0.001502   7.290 3.10e-13 ***\nbehaveA2      0.073842   0.221516   0.333  0.73887    \nbehaveB3     -0.630270   0.243056  -2.593  0.00951 ** \nbehaveB4     -0.539369   0.319753  -1.687  0.09164 .  \ncigs          0.020246   0.004222   4.796 1.62e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1588.4  on 3134  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1604.4\n\nNumber of Fisher Scoring iterations: 6\n\n\n\ndeviance(fit_all)\n\n[1] 1580.446\n\ndeviance(fit_1)\n\n[1] 1580.676\n\ndeviance(fit_2)\n\n[1] 1588.378\n\n\n이제 두 모형 fit_1 과 fit_2 의 편처의 차이를 보면 다음과 같다.\n\ndeviance(fit_2) - deviance(fit_1)\n\n[1] 7.702675\n\n\n이제 질문은 모형에서 weight 를 제외하면 모형의 설명력에 유의한 영향이 있는지에 대한 것이다. 이는 다음과 같은 가설로 표현할 수 있다.\n\\[ H_0 : \\beta_{\\text{weight}} = 0 \\quad \\text{vs.} \\quad \\beta_{\\text{weight}} \\ne 0 \\]\n이제 함수 anova 를 통해서 가설검정을 해보자.\n\nanova(fit_2, fit_1, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: chd ~ age + sdp + chol + behave + cigs\nModel 2: chd ~ age + weight + sdp + chol + behave + cigs\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   \n1      3134     1588.4                        \n2      3133     1580.7  1   7.7027 0.005514 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n위의 결과에서 weight 를 제외하면 모형의 설명력에 유의한 영향이 있다고 할 수 있다. 즉 weight 는 모형에서 유의한 변수이다.\n참고로 두 개의 설명 변수 height, dbp 를 제외한 경우는 큰 차이가 유의한 차이가 있는지 알아보자.\n\nanova(fit_1, fit_all, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: chd ~ age + weight + sdp + chol + behave + cigs\nModel 2: chd ~ age + height + weight + sdp + dbp + chol + behave + cigs\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      3133     1580.7                     \n2      3131     1580.5  2  0.22978   0.8915\n\n\n위의 결과를 보면 \\(H_0 : \\beta_{\\text{height}} =\\beta_{\\text{dbp}} = 0\\)를 기각할 수 없다는 것을 알 수 있다.\n주어진 모형에서 1개의 변수를 제거할 수 있는지는 다음과 같은 함수 drop1 으로 알아볼 수 있다. 아래 결과를 보면 각 독립변수를 제거한 경우에 얻어진 편차를 보여주고 그 편차의 차이가 유의한 지를 알려준다.\n아래 결과를 보면 설명 변수 height 와 dbp 는 모형에서 제외해도 유의한 차이가 없음을 알려준다.\n\ndrop1(fit_all, test = \"Chisq\")\n\nSingle term deletions\n\nModel:\nchd ~ age + height + weight + sdp + dbp + chol + behave + cigs\n       Df Deviance    AIC    LRT  Pr(&gt;Chi)    \n&lt;none&gt;      1580.5 1602.5                     \nage     1   1609.1 1629.1 28.662 8.617e-08 ***\nheight  1   1580.7 1600.7  0.228  0.632710    \nweight  1   1584.5 1604.5  4.072  0.043612 *  \nsdp     1   1587.8 1607.8  7.299  0.006898 ** \ndbp     1   1580.5 1600.5  0.000  0.991089    \nchol    1   1635.2 1655.2 54.739 1.376e-13 ***\nbehave  3   1602.0 1618.0 21.518 8.218e-05 ***\ncigs    1   1603.6 1623.6 23.159 1.492e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n적합한 모형에서 각 회귀계수의 신뢰구간은 다음과 같이 구할 수 있다.\n\nconfint(fit_all)\n\nWaiting for profiling to be done...\n\n\n                    2.5 %      97.5 %\n(Intercept) -1.761371e+01 -8.45120837\nage          4.131448e-02  0.08887927\nheight      -4.890449e-02  0.08105677\nweight       2.268784e-04  0.01544556\nsdp          4.869834e-03  0.02996578\ndbp         -2.114627e-02  0.02134188\nchol         8.112039e-03  0.01407651\nbehaveA2    -3.351460e-01  0.53997138\nbehaveB3    -1.073224e+00 -0.11295633\nbehaveB4    -1.143870e+00  0.12153181\ncigs         1.255611e-02  0.02935499\n\n\n\n\n8.3.3 모형의 비교: 일반적인 모형\n일반적으로 두 개 이상의 모형을 비교하는 경우 가장 자주 사용되는 측도는 정보기준 측도인 AIC(Akaike Information Criteris) 와 BIC(Bayesian Information Criteria) 가 이 있다. AIC와 BIC 모두 값이 작은 것이 좋으 모형이다.\n이제 앞에서 살펴본 3개의 모형의 AIC 와 BIC 를 구해보자.\n\nAIC(fit_all, fit_1, fit_2)\n\n        df      AIC\nfit_all 11 1602.446\nfit_1    9 1598.676\nfit_2    8 1604.378\n\n\n\nBIC(fit_all, fit_1, fit_2)\n\n        df      BIC\nfit_all 11 1669.024\nfit_1    9 1653.149\nfit_2    8 1652.799\n\n\nAIC 기준으로는 모형 fit_1 이 제일 좋으며 BIC 기준으로는 fit_2 가 가장 좋다. BIC 가 AIC 보다 설명변수의 수가 적은 성김 모형을 선호하는 일반적인 결과이다.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#회귀모형의-진단",
    "href": "notes/logistic_practice.html#회귀모형의-진단",
    "title": "8  로지스틱 회귀모형 실습 1",
    "section": "8.4 회귀모형의 진단",
    "text": "8.4 회귀모형의 진단\n\n8.4.1 잔차\n선형회귀 모형처럼 관측값(로지스틱 회귀에서는 0 또는 1)에서 예측값을 뺀 잔차 \\(r_i\\) (residual, raw residual)을 구할 수 있다.\n\\[ r_i = y_i - \\hat P(y_i=1| \\pmb x_i)  \\tag{8.4}\\]\n다음과 같이 residuals 함수에 type=\"response\"를 이용하면 식 8.4 의 잔차 를 구할 수 있다.\n\nhead(residuals(fit_all, type=\"response\")) # 너무 많아서 일부만 출력\n\n          1           2           3           4           5           6 \n-0.08157607 -0.06242009 -0.01031108 -0.01118637  0.84345627 -0.03832130 \n\n\n이제 잔차를 표준화한 피어슨 잔차(pearson residual)은 다음과 같이 구할 수 있다.\n\\[ r^*_i = \\frac{y_i - \\hat p_i}{\\sqrt{\\hat p_i (1-\\hat p_i)}}  \\tag{8.5}\\]\n\nhead(residuals(fit_all, type=\"pearson\")) \n\n         1          2          3          4          5          6 \n-0.2980299 -0.2580228 -0.1020711 -0.1063622  2.3212047 -0.1996205 \n\n\n참고로 피어슨 잔차를 제곱한 합은 적합도 분석에 사용하는 카이제곱 통계량이다.\n\\[ \\chi^2 = \\sum_{i=1}^n \\left [ r^*_i \\right ]^2 \\]\n그리고 잔차를 분석하는 그림도 다음과 같이 출력할 수 있다.\n\nplot(fit_all)\n\n\n\n\n\n\n\n\n\n\n\n\n\n다른 잔차로서 편차 잔차(deviance residual) 이 있으며 이는 편차의 합으로 표시될 수 있도록 잔차를 로그가능도 함수의 값으로 정의한 것이다.\n\\[ d_i = sign(y-\\hat p_i) \\sqrt{-2\\{  y_i \\log \\hat p_i + (1-y_i) \\log (1- \\hat p_i)\\}}  \\tag{8.6}\\]\n여기서 정의된 편차 잔차는 다음의 식을 만족하도록 구한 잔차이다.\n\\[ \\text{deviance} = D(\\hat {\\pmb y} ; \\hat {\\pmb \\mu } ) = \\sum_{i=1}^n d^2_i \\]\n로지스틱 회귀모형에서의 정의된 모든 잔차는 선형모형과의 잔차와는 많이 다르다. 로지스틱 회귀모형에서 반응값은 0 또는 1 의 값만 가지기 때문에 잔차의 범위가 제약되어 있고 두 개의 패턴으로 몰려서 나오기 때문에 이상점을 찾거나 등분산성을 판단하는 진단으로 이용하기는 힘들다.\n\n\n8.4.2 다중공선성\n로지스틱 회귀모형에서도 다중공선성(colliearity)는 쉽게 진단할 수 있다.\n함수vif 를 이용하면 분산팽창계수(variance inflation factor; vif)의 값을 구하고 상대적으로 큰 값을 보이는 설명변수들이 다중공선성의 위험이 높다.\n다음의 결과에서 두 개의 혈압 sdp 와 dbp 의 vif 값이 높다는 것을 알 수 있다.\n\nvif(fit_all)\n\n           GVIF Df GVIF^(1/(2*Df))\nage    1.052733  1        1.026028\nheight 1.474285  1        1.214201\nweight 1.599757  1        1.264815\nsdp    2.656508  1        1.629880\ndbp    2.792595  1        1.671106\nchol   1.019601  1        1.009753\nbehave 1.029248  3        1.004816\ncigs   1.051759  1        1.025553\n\n\n다음과 같이 설명변수들의 상관계수를 보면 두 개의 혈압 sdp 와 dbp 이 상관계수가 0.77로 다른 조합보다 높게 나타난다.\n\ncor(model.matrix(fit_all)[,-1])\n\n                  age       height       weight         sdp          dbp\nage       1.000000000 -0.091924057 -0.033078516  0.17005253  0.143979992\nheight   -0.091924057  1.000000000  0.533288106  0.01556533  0.006985365\nweight   -0.033078516  0.533288106  1.000000000  0.25127827  0.293968705\nsdp       0.170052531  0.015565329  0.251278272  1.00000000  0.770044438\ndbp       0.143979992  0.006985365  0.293968705  0.77004444  1.000000000\nchol      0.089188510 -0.088937779  0.008537442  0.12306130  0.129597108\nbehaveA2  0.052019677  0.035509861  0.032336093  0.07146950  0.038463827\nbehaveB3 -0.065710685 -0.018273763 -0.022060732 -0.05832314 -0.040950551\nbehaveB4 -0.040543591 -0.025710608 -0.033791371 -0.03375835 -0.031730174\ncigs     -0.006111181  0.017304324 -0.082673038  0.02928485 -0.062670918\n                 chol    behaveA2    behaveB3    behaveB4         cigs\nage       0.089188510  0.05201968 -0.06571069 -0.04054359 -0.006111181\nheight   -0.088937779  0.03550986 -0.01827376 -0.02571061  0.017304324\nweight    0.008537442  0.03233609 -0.02206073 -0.03379137 -0.082673038\nsdp       0.123061297  0.07146950 -0.05832314 -0.03375835  0.029284852\ndbp       0.129597108  0.03846383 -0.04095055 -0.03173017 -0.062670918\nchol      1.000000000  0.03365476 -0.03791301 -0.03204021  0.096031834\nbehaveA2  0.033654760  1.00000000 -0.67403983 -0.30058884  0.069761255\nbehaveB3 -0.037913013 -0.67403983  1.00000000 -0.27929653 -0.060013668\nbehaveB4 -0.032040209 -0.30058884 -0.27929653  1.00000000 -0.053546698\ncigs      0.096031834  0.06976125 -0.06001367 -0.05354670  1.000000000",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#예측",
    "href": "notes/logistic_practice.html#예측",
    "title": "8  로지스틱 회귀모형 실습 1",
    "section": "8.5 예측",
    "text": "8.5 예측\n이제 적합된 성공 확률을 이용하여 반응변수의 값과 예측값을이 얼마나 일치하는지 알아보자.\n\\[\n\\hat y_i =\n\\begin{cases}\n\\text{yes} & \\text{ if } \\hat p_i \\ge \\text{threshold} \\\\\n\\text{no} & \\text{ if } \\hat p_i &lt; \\text{threshold}\n\\end{cases}\n\\]\n먼저 자주 사용되는 분류기준 \\(\\text{threshold}=0.5\\) 이용하여 반응값을 예측해보자.\n\nTH &lt;- 0.5\npred_y &lt;- ifelse(predict(fit_2, type=\"response\") &lt; TH , 0, 1)\npred_df &lt;- data.frame(response=fit_1$y , predicted=pred_y)\nhead(pred_df)\n\n  response predicted\n1        0         0\n2        0         0\n3        0         0\n4        0         0\n5        1         0\n6        0         0\n\n\n\nclass_table &lt;- xtabs(~response+predicted, data=pred_df)\nclass_table\n\n        predicted\nresponse    0    1\n       0 2884    1\n       1  254    3\n\n\n이제 분류기준을 정하면 위의 분류표와 민감도와 특이도를 계산하는 함수를 만들어 보자\n\nclassify_func &lt;- function(fit_glm, th){\n  pred_y &lt;- ifelse(predict(fit_glm, type=\"response\") &lt; th , 0, 1)\n  pred_df &lt;- data.frame(response=fit_glm$y , predicted=pred_y)\n  class_table &lt;- xtabs(~response+predicted, data=pred_df)\n  sensitivity &lt;- class_table[2,2]/(class_table[2,1] + class_table[2,2])\n  specificity &lt;- class_table[1,1]/(class_table[1,1] + class_table[1,2])\n  \n  list(class_table, sensitivity, specificity)\n}\n\n분류기준을 0.5 로 하면 다음과 같은 결과가 얻어진다.\n\nclassify_func(fit_1, 0.5)\n\n[[1]]\n        predicted\nresponse    0    1\n       0 2882    3\n       1  255    2\n\n[[2]]\n[1] 0.007782101\n\n[[3]]\n[1] 0.9989601\n\n\n분류기준을 0.3으로 낮추면 민감도가 조금 증가하는 것을 알 수 있다.\n\nclassify_func(fit_1, 0.3)\n\n[[1]]\n        predicted\nresponse    0    1\n       0 2824   61\n       1  234   23\n\n[[2]]\n[1] 0.08949416\n\n[[3]]\n[1] 0.9788562\n\n\n양성예측도와 음성예측도를 구하는 함수를 다음과 같이 만들 수 있다.\n\nclassify_func(fit_1, 0.3)[[2]][1]\n\n[1] 0.08949416\n\n\n\n# prev : 유병률\ncalpred &lt;- function(prev, sen, spe){\n    pred.pos &lt;- sen*prev/(sen*prev + (1-spe)*(1-prev))\n  pred.neg &lt;- spe*(1-prev)/(spe*(1-prev) + (1-sen)*(prev))\n  res &lt;- data.frame(sen, spe, prev, pred.pos, pred.neg)\n  colnames(res) &lt;- c(\"Sensitivity\", \"SPecificity\",\"Prevalnce\", \"Pred. Post.\", \"Pred. Nega.\")\n  res\n}\n\n분류기준을 0.3, 관상동맥질환의 한국 유병율을 \\(3.0\\%\\) 로 놓고 양성예측도와 음성예측도를 구해보자.\n\ncalpred(0.03, classify_func(fit_1, 0.3)[[2]][1], classify_func(fit_1, 0.3)[[3]][1])\n\n  Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1  0.08949416   0.9788562      0.03   0.1157534   0.9720362\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#필요한-패키지와-함수",
    "href": "notes/logistic_practice_2.html#필요한-패키지와-함수",
    "title": "9  로지스틱 회귀모형 실습 2",
    "section": "9.1 필요한 패키지와 함수",
    "text": "9.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nsource(\"../R/functions.R\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#예제-백혈병의-재발",
    "href": "notes/logistic_practice_2.html#예제-백혈병의-재발",
    "title": "9  로지스틱 회귀모형 실습 2",
    "section": "9.2 예제: 백혈병의 재발",
    "text": "9.2 예제: 백혈병의 재발\n다음은 Jaewon Lee (2005) 의 4장에 나오는 예제이다.\n102명의 백혈병(Lukeumia) 환자들을 랜덤하게 두 개의 그룹으로 나누어서 한 그룹에는 처리 A를 하고, 다른 그룹에는 처리 B를 적용하여 재발 여부를 조사하였다. 이때 재발 여부에 영향을 미치는 또 다른 요인으로 호전기간(remission time)을 예측변수로 고려하였다.\n변수 remission 는 호전기간(단위는 월)이며 재발여부를 나타내는 y 는 1이면 재발을 나타내며 이 예제에서는 재발할 확률이 관심 사건이다. 이제 처리 그룹 trt 과 호전 기간이 재발 여부에 미치는 영향을 알아보자.\n참고로 백혈병(Lukeumia) 환에 대한 자료는 확률변수 \\(y_i\\) 가 베르누이 분포 \\(Berr(p_i)\\)를 따른다.\n먼저 자료를 데이터프레임으로 읽어 오자.\n\nluk &lt;- read.csv(\"../data/leukemia.csv\", header=T, sep=\"\")\nhead(luk,5)\n\n  trt remission y\n1   A         3 0\n2   A         3 1\n3   A        15 0\n4   A         6 1\n5   A        15 0\n\n\n먼저 재발여부를 나타내는 y 는 1 이 성공 사건이므로 level=c(0,1) 로 지정한다.\n\nluk$y &lt;- factor(luk$y, levels=c(0, 1))\n\n먼저 처리와 재발에 대한 분할표를 만들어 보자. 또한 호전 기간의 요약통계도 살펴보자.\n\ntable(luk$trt, luk$y)\n\n   \n     0  1\n  A 29 22\n  B 20 31\n\n\n\nsummary(luk$remission)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.000   6.000   9.000   9.735  12.000  18.000 \n\n\n이제 다음과 같이 함수 glm 을 이용하여 로지스틱 회귀모형을 적합해보자.\n\nluk_res &lt;- glm(y~ trt + remission, family = \"binomial\", data=luk)\nsummary(luk_res)\n\n\nCall:\nglm(formula = y ~ trt + remission, family = \"binomial\", data = luk)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.45595    0.55839   2.607 0.009123 ** \ntrtB         1.17754    0.46669   2.523 0.011631 *  \nremission   -0.19985    0.05589  -3.576 0.000349 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 141.25  on 101  degrees of freedom\nResidual deviance: 122.68  on  99  degrees of freedom\nAIC: 128.68\n\nNumber of Fisher Scoring iterations: 3\n\n\n위의 결과를 해석하면 다음과 같이 설명할 수 있다. 일단 두 환자가 같은 호전 시간 remission 을 보여주었다면 처리 A 와 B 에 대한 재발 확률의 오즈비는 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|B)}{1-P(y=1|B)} \\right ] \\\\\n& \\quad = [1.4559 + 0 + (-0.1998)(x)] - [1.4559 + 1.1775\n  + (-0.1998)(x)] \\\\\n& \\quad  = - 1.1775\n\\end{aligned}\n\\]\n따라서\n\\[\n\\log   \\left [  \\frac {\\tfrac{P(y=1|A)}{1-P(y=1|A)}}{\\tfrac{P(y=1|B)}{1-P(y=1|B)}} \\right ]  = - 1.1775\n\\]\n다시 쓰면\n\\[\n\\frac {\\tfrac{P(y=1|A)}{1-P(y=1|A)}}{\\tfrac{P(y=1|B)}{1-P(y=1|B)}}   = \\exp(-1.1775) = 0.308\n\\]\n따라서 처리 A 를 받은 환자들의 오드가 처리 B 를 받은 환자들의 오드의 약 0.3 배(30%)가 된다는 것을 의미한다. 처리 A의 한자들이 재발할 가능성이 처리 B 를 받은 환자들 보다 작다는 것을 의미하며 처리 trt 의 회귀계수에 대한 p-값이 \\(0.0116\\) 이므로 처리 간의 차이가 유의한 것을 알 수 있다.\n호전기간 remisson 에 대한 효과도 알아보자. 일단 두 환자가 같은 처리를 받았다고 가정하고(예를 들어 처리 A) 호전 시간이 1개월 차이가 는 경우의 배발 확률을 비교해보자.\n한 명의 한자는 호전기간이 \\(r+1\\) 개월이고 다른 환자는 \\(r\\) 개월 이라면 재발 확률의 오즈비는 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|x=r+1)}{1-P(y=1|x=r+1)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|x=r)}{1-P(y=1|x=r)} \\right ] \\\\\n& \\quad = [1.4559 + 0 + (-0.1998)(r+1)] - [1.4559 + 0\n  + (-0.1998)(r)] \\\\\n& \\quad  = -0.1998\n\\end{aligned}\n\\]\n따라서\n\\[\n\\frac {\\tfrac{P(y=1|x=r+1)}{1-P(y=1|x=r+1)}}{\\tfrac{P(y=1|x=r)}{1-P(y=1|x=r)}}   = \\exp(-0.1998) = 0.819\n\\]\n즉, 호전기간이 1개월 증가하면 오즈가 이전의 약 81.9% 가 된다. 따라서 호전 기간이 늘어날수록 재발할 확률이 낮아지는 것을 알 수 있다. 가설 검정에 의하여 호전 기간은 매우 유의한 예측변수이다(p-값 = 0.000349).\n이제 함수 predict() 를 이용하여 각 환자에 대한 재발 확률의 예측값을 구해보자. 선택문 type = \"response\"을 이용해야 확률의 예측값이 구해진다.\n\nluk_pred_p &lt;- predict(luk_res, type = \"response\")\nluk_pred_p[1:14]\n\n        1         2         3         4         5         6         7         8 \n0.7019096 0.7019096 0.1762813 0.5638664 0.1762813 0.2804544 0.5638664 0.5638664 \n        9        10        11        12        13        14 \n0.2804544 0.5638664 0.5638664 0.7019096 0.4151610 0.5638664 \n\n\n각 처리에 따라서 호전기간이 변하면 재발확률이 어떻게 변하는지 에측확률에 대한 그림을 다음과 같이 그려보자.\n먼저 두 처리 그룹에 대하여 호전기간에 대한 값을 1개월부터 24개월까지 새로운 자료를 만들자.\n\nt_num = 24\ntrt_new = c(rep(\"A\", t_num), rep(\"B\", t_num))\nremission_new = rep(1:t_num, 2)\nluk_new = data.frame(trt = trt_new, remission=remission_new)\nhead(luk_new,10)\n\n   trt remission\n1    A         1\n2    A         2\n3    A         3\n4    A         4\n5    A         5\n6    A         6\n7    A         7\n8    A         8\n9    A         9\n10   A        10\n\n\n새롭개 만든 데이터프레임 luk_new 에 예측함수 predict() 를 이용하여 예측한 재발확률의 벡터를 만들고 데이터프레임 luk_new 에 포함시킨다.\n\npred_new = predict(luk_res, newdata = luk_new, type = \"response\")\nluk_new$hatp = pred_new \nhead(luk_new)\n\n  trt remission      hatp\n1   A         1 0.7783541\n2   A         2 0.7419740\n3   A         3 0.7019096\n4   A         4 0.6584875\n5   A         5 0.6122346\n6   A         6 0.5638664\n\n\n이제 패키지 ggplot2 를 이용하여 처리에 따라서 호전기간에 따른 예측된 재발확률의 변화를 그림으로 그려보자.\n\nggplot(luk_new, aes(x=remission, y=hatp, color=trt)) + \n  geom_line() + \n  labs(x=\"remission(month)\", y=\"Probability\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#예제-종양-치료",
    "href": "notes/logistic_practice_2.html#예제-종양-치료",
    "title": "9  로지스틱 회귀모형 실습 2",
    "section": "9.3 예제: 종양 치료",
    "text": "9.3 예제: 종양 치료\n다음은 Jaewon Lee (2005) 의 4장에 나오는 예제이다.\n두 종류의 종양(T,M)이 있는 환자들을 대상으로 3가지 치료 방법(A, B, C)를 적용하여 종양이 치료되었는지 여부를 조사한 자료이다. 변수 cured 와 uncured 는 각각 치료된 환자와 그렇지 못한 환자의 수를 나타낸다.\n연구자의 관심은 치료율이 종양과 치료법에 따라서 다른지 알아보는데 있다.\n\ntumor &lt;- read.csv(text = \"\ntype trt  cured uncured\nT A  65   18\nM B  100  13\nT C  56   38\nM A  80   15\nT B  29   9\nM C  78   22\n\", sep=\"\", header=TRUE )\n\ntumor\n\n  type trt cured uncured\n1    T   A    65      18\n2    M   B   100      13\n3    T   C    56      38\n4    M   A    80      15\n5    T   B    29       9\n6    M   C    78      22\n\n\n먼저 자료에서 종양의 종류(type) 과 치료법(trt)를 범주형 변수로 정하고 수준(level)과 순서를 정하자.\n\ntumor$type &lt;- factor(tumor$type, levels = c(\"M\", \"T\"))\ntumor$trt &lt;-  factor(tumor$trt, levels=c(\"A\", \"B\", \"C\"))\nstr(tumor)\n\n'data.frame':   6 obs. of  4 variables:\n $ type   : Factor w/ 2 levels \"M\",\"T\": 2 1 2 1 2 1\n $ trt    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 2 3 1 2 3\n $ cured  : int  65 100 56 80 29 78\n $ uncured: int  18 13 38 15 9 22\n\n\n이제 다음과 같인 종양의 종류와 치료법을 예측변수로 하는 로지스틱 회귀식을 적합해 보자.\n모형식에서 반응값으로 함수 cbind() 에 성공의 횟수(cured)와 실패의 횟수(uncured)를 지정한다.\n\ntumor_res &lt;- glm( cbind(cured, uncured) ~ type + trt, family = \"binomial\", data=tumor)\n\nsummary(tumor_res)\n\n\nCall:\nglm(formula = cbind(cured, uncured) ~ type + trt, family = \"binomial\", \n    data = tumor)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.8575     0.2328   7.978 1.48e-15 ***\ntypeT        -0.7216     0.2202  -3.276  0.00105 ** \ntrtB          0.1288     0.3073   0.419  0.67515    \ntrtC         -0.6795     0.2505  -2.712  0.00668 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 26.8238  on 5  degrees of freedom\nResidual deviance:  1.0604  on 2  degrees of freedom\nAIC: 35.669\n\nNumber of Fisher Scoring iterations: 4\n\n\n앞에서 종양의 종류와 치료 방법에 대한 수준(level)을 만들 때 종양 M 과 치료법 A 를 첫 수준으로 놓있기 떄문에 효과에 대한 추정치는 0이 된다. 즉, 나머지 종양과 치료법의 효과는 종양 M 과 치료법 A 에 대한 상대적인 효과이다.\n추정의 결과를 해석하면 다음과 같다. 비교하고자 하는 효과를 제외한 다른 효과들은 모두 같은 효과를 가정하므로 0으로 놓고 계산해도 무방하다.\n\n종양의 종류가 M 인 경우의 치료에 대한 오드가 T 인 경우의 2.06 배 이다 [\\(\\exp(0.7216)\\)]. 따라서 종양의 종류가 M 인 경우가 T 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|M)}{1-P(y=1|M)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|T)}{1-P(y=1|T)} \\right ] \\\\\n& \\quad = [1.8575 + 0 + 0 ] - [1.8575 -0.7216 + 0] \\\\\n& \\quad  =0.7216\n\\end{aligned}\n\\]\n\n치료 방법이 A 인 경우의 치료에 대한 오드가 B 인 경우의 87.91 % 이다 [\\(\\exp(-0.1288)\\)]. 따라서 치료 방법이 B 인 경우가 A 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|B)}{1-P(y=1|B)} \\right ] \\\\\n& \\quad = [1.8575 + 0 + 0 ] - [1.8575 + 0 + 0.1288 ] \\\\\n& \\quad  = - 0.1228\n\\end{aligned}\n\\]\n\n치료 방법이 A 인 경우의 치료에 대한 오드가 C 인 경우의 1.97 배 이다 [\\(\\exp( 0.6795)\\)]. 따라서 치료 방법이 A 인 경우가 C 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|C)}{1-P(y=1|C)} \\right ] \\\\\n& \\quad = [1.8575 0 + 0 ] - [1.8575  + 0 - 0.6795] \\\\\n& \\quad  = 0.6795\n\\end{aligned}\n\\]\n\n치료 방법이 B 인 경우의 치료에 대한 오드가 C 인 경우의 2.23 배 이다 [\\(\\exp(0.8023)\\)]. 따라서 치료 방법이 B 인 경우가 C 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|C)}{1-P(y=1|C)} \\right ] \\\\\n& \\quad = [1.8575 +  0 + 0.1288 ] - [1.8575  + 0 - 0.6795] \\\\\n& \\quad  = 0.1228 +  0.6795 = 0.8023\n\\end{aligned}\n\\]\n이제 종양별, 치료 방법별로 치료의 확률에 대한 예측값을 구해보자.\n종양의 종류에 관계없이 치료법 B 가 가장 치료 효과가 높다는 것을 알 수 있다.\n\ntumor_new &lt;- tumor[,1:2]\npred_new = predict(tumor_res, newdata = tumor_new, type = \"response\")\ntumor_new$hatp = pred_new \ntumor_new %&gt;% arrange(type, trt)\n\n  type trt      hatp\n1    M   A 0.8650044\n2    M   B 0.8793494\n3    M   C 0.7645810\n4    T   A 0.7569227\n5    T   B 0.7798294\n6    T   C 0.6121479\n\n\n여기서 주의할 점은 각 종양과 치료법의 조합에서 구할 수 있는 치료된 환자들의 표본 비율과 로지스틱 회귀에서 나타나는 추정 확률은 약간 차이가 난다. 그 이유는 로지스틱회귀에서는 최대가능도함수 추정법을 사용하여 각 조합의 효과를 추정하기 때문에 단순한 표본 비율과 차이가 날 수 있다.\n\n\n\n\nJaewon Lee, Hanna Yu, Mira Park. 2005. 생명과학연구를 위한 통계적 방법. 1st ed. 자유아카데미.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agresti, Alan. 2007. An Introduction to Categorical Data\nAnalysis. John Wiley & Sons, Ltd.\n\n\n———. 2012. Categorical Data Analysis. Vol. 792. John Wiley\n& Sons.\n\n\nButler-Laporte, Guillaume, Alexander Lawandi, Ian Schiller, Mandy Yao,\nNandini Dendukuri, Emily G McDonald, and Todd C Lee. 2021.\n“Comparison of Saliva and Nasopharyngeal Swab Nucleic Acid\nAmplification Testing for Detection of SARS-CoV-2: A Systematic Review\nand Meta-Analysis.” JAMA Intern Med 181 (3): 353–58.\n\n\nFaraway, Julian J. 2016. Extending the Linear Model with r:\nGeneralized Linear, Mixed Effects and Nonparametric Regression\nModels. CRC press.\n\n\nJaewon Lee, Hanna Yu, Mira Park. 2005. 생명과학연구를 위한 통계적\n방법. 1st ed. 자유아카데미.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth.\nHoboken NJ: Wiley. http://z.umn.edu/alr4ed.",
    "crumbs": [
      "References"
    ]
  }
]