[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "데이터 분석 방법론",
    "section": "",
    "text": "Preface\n이 사이트는 데이터 분석 방법론 강의 온라인 강의 노트입니다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "notes/intro.html#학습-내용",
    "href": "notes/intro.html#학습-내용",
    "title": "1  서론",
    "section": "1.1 학습 내용",
    "text": "1.1 학습 내용\n이 교과서는 다양한 형태를 가진 자료를 분석하는 통계적 방법들의 이론과 응용을 살펴보기 위한 것입니다.\n이 교과서에서는 다음과 같은 주제를 다룰 것입니다.\n\n교차표에서의 통계적 분석방법\n범주형 자료와 발생횟수를 따르는 자료에 대한 모형 구축과 추론\n일반화 선형모형에서의 추론\n반복측정자료와 군집자료에 대한 분석 방법",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#r-언어",
    "href": "notes/intro.html#r-언어",
    "title": "1  서론",
    "section": "1.2 R 언어",
    "text": "1.2 R 언어\n이 교과서에서는 통계 방법들의 실습을 위하여 R 프로그램을 사용합니다. R 프로그램이 익숙하지 않는 학생들은 R 프로그램에 대한 기초적인 내용을 먼저 숙지하느 것을 추천합니다. 참고로 저자의 R 기초 강의 사이트에서 R 프로그램에 대한 기초적인 내용을 배울 수 있습니다.\n이 강의에서 사용하는 R 패키지는 다음과 같다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#참고도서",
    "href": "notes/intro.html#참고도서",
    "title": "1  서론",
    "section": "1.3 참고도서",
    "text": "1.3 참고도서\n\nFaraway (2016)\nAgresti (2007)\nAgresti (2012)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/intro.html#유용한-사이트",
    "href": "notes/intro.html#유용한-사이트",
    "title": "1  서론",
    "section": "1.4 유용한 사이트",
    "text": "1.4 유용한 사이트\n\nData sets for “An Introduction to Categorical Data Analysis”\nR codes for “An Introduction to Categorical Data Analysis”\n\n\n\n\n\nAgresti, Alan. 2007. An Introduction to Categorical Data Analysis. John Wiley & Sons, Ltd.\n\n\n———. 2012. Categorical data analysis. Vol 792. John Wiley & Sons.\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>서론</span>"
    ]
  },
  {
    "objectID": "notes/association.html#필요한-패키지",
    "href": "notes/association.html#필요한-패키지",
    "title": "2  연관성의 측도",
    "section": "2.1 필요한 패키지",
    "text": "2.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#이항변수",
    "href": "notes/association.html#이항변수",
    "title": "2  연관성의 측도",
    "section": "2.2 이항변수",
    "text": "2.2 이항변수\n통계학에서 관측값은 값이 가지는 특성에 따라서 연속형 변수(continuous variable)과 범주형 변수(categorical variable)로 나눈다.\n결과가 2개인 범주형 변수인 이항변수(binary variable)는 매우 중요한 역할을 한다. 그 이유는 두 개의 선택 중에서 하나를 선택해 야할 의사결정이 실제로 대부분을 차지하고 있기 때문이다.\n예를 들어서 코로나 19에 감염된 환자가 병원에서 치료를 받고 있다고 가정해보자. 환자는 병원에서 여러 가지 검사를 수행하면서 다양한 자료를 수집한다. 예를 들어 환자는 수시로 체온을 재고 항체검사, 혈액검사 등을 받을 것이다. 다양한 검사 등에서 나온 자료는 연속형 또는 범주형 자료로 구성될 것이다.\n하지만 의사가 가장 중요하게 결정할 사항은 환자가 계속 치료를 필요로 하는지 아닌지 결정해야 한다. 즉, 여러 가지 검사를 고려하여 최종적으로 의사는 환자가 더 치료가 필요한지 아닌 지를 결정해야 한다. 의사의 결정을 이항변수 \\(Y\\)로 다음과 같이 표현할 수 있다..\n\\[\nY =\n\\begin{cases}\n1 & \\text{ if patient still needs treatment} \\\\\n0 & \\text{ if patient dose not need treatment any more (GO HOME!)}\n\\end{cases}\n\\]\n실제 임상에서는 이러한 두 개의 가능한 선택 중에 하나를 선택하는 결정이 빈번하게 일어나며 이러한 결정은 대부분 중요한 임상적 결정이다. 예를 들어 다음과 같은 의사결정들은 이항변수로 표현할 수 있다.\n\n환자는 약을 복용해야 하는가?\n환자는 입원을 해야 하는가?\n환자는 중환자실로 가야 하는가?\n환자는 퇴원해도 되는가?\n\n또는 환자의 상태(outcome)가 이항변수로 표현될 수 있다.\n\n환자는 치료가 되었는가?\n환자가 사망하였는가?\n\n이제 코로나 19 치료제의 효과를 알아보기 위한 임상실험을 수행하는 경우를 생각해보자. 통상적으로 임상실험에서는 두 개의 집단을 비교하며 가장 많이 사용하는 두 개의 집단은 실제 치료(drug)를 받은 사람들과 위약(placebo)을 받은 사람들이다. 즉 치료를 받은 사람과 받지 않는 사람들의 효과를 비교하는 것이 임상실험의 목적이다. 이러한 경우 앞에서 논의한 의사 결정과 마찬가지로 한 환자가 받은 치료의 종류를 이항변수 \\(X\\)로 나타낼 수 있다.\n\\[\nX=\n\\begin{cases}\n1 & \\text{ if patient receives drug} \\\\\n0 & \\text{ if treatment receives placebo}\n\\end{cases}\n\\]",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#분할표와-연관성의-측도",
    "href": "notes/association.html#분할표와-연관성의-측도",
    "title": "2  연관성의 측도",
    "section": "2.3 분할표와 연관성의 측도",
    "text": "2.3 분할표와 연관성의 측도\n\n2.3.1 분할표\n이제 앞에서 말한 두 개의 변수 \\(X\\) 와 \\(Y\\) 의 관계에 대해서 생각해 보자. 실험에서 사람들은 코로나 19에 대한 치료약의 효과에 관심이 있다. 코로나 19 환자가 치료약을 처치 받으면 치료약을 이용하지 않는 환자보다 빨리 치료되거나 사망할 가능성이 낮은 지가 주요 관심사이다. 즉, 치료약이 환자의 회복 속도나 사망과 연관(association)이 있는지 알고 싶은 것이며, 특히 실험이 매우 정교하게 설계된 경우는 치료약이 환자의 회복이나 사망에 영향을 미치는 원인이 되는지(cause-effect relation) 파악하고 싶은 것이다.\n\n먼저 코로나 19에 대한 치료약의 효과에 대한 임상실험에 \\(n\\) 명의 환자들이 실험에 참가 했다고 가정하자.\n치료약이 효과가 있는지에 대한 결과(\\(Y\\))는 치료를 시작하여 정해진 기간 내에 사망하였는지에 대한 사건으로 결정하였다.\n\n\\[\nY =\n\\begin{cases}\n1 & \\text{ if patient is dead within D days } \\\\\n0 & \\text{ otherwise}\n\\end{cases}\n\\]\n코로나 19에 대한 치료약의 효과에 대한 임상실험의 결과를 다음과 같은 분할표(contingency table)로 요약할 수 있다.\n\n\n\n표 2.1: \\(2 \\times 2\\) 분할표\n\n\n\n\n\n치료/결과\n사망 (\\(Y=1\\))\n생존 (\\(Y=0\\))\n합계\n\n\n\n\n위약 (\\(X=0\\))\n\\(n_{11}\\)\n\\(n_{12}\\)\n\\(n_{1+}\\)\n\n\n치료약 (\\(X=1\\))\n\\(n_{21}\\)\n\\(n_{22}\\)\n\\(n_{2+}\\)\n\n\n합계\n\\(n_{+1}\\)\n\\(n_{+2}\\)\n\\(n\\)\n\n\n\n\n\n\n많은 임상실험이나 의학연구의 결과들을 위와 같은 \\(2 \\times 2\\) 분할표로 요약할 수 있다. 이제 우리의 관심은 분할표를 통해서 임상실험의 결과를 어떻게 통계적으로 추론할 수 있는지이다.\n\n\n\n\n\n\n노트\n\n\n\n분할표에서 연관성의 측도를 계산하는 경우 성공의 기준(이항변수로 표현하면 \\(Y=1\\))에 따라서 계산을 수행해야 한다. 어떤 경우는 사망이나 악화와 같은 위험한 사건이 성공 사건이 될 수 있으며 어떤 경우는 생존이나 회복과 같은 좋은 사건이 성공이 될 수 있다.\n또한 기준이 되는 그룹(이항변수 \\(X\\))에 따라서 연관성의 측도 계산할 때 분자와 분모에 해당하는 그룹을 적절하게 선택해야 한다.\n분할표에서 연관성의 측도를 계산하는 경우 분석의 의도와 목적에 맞게 성공 사건과 기준그룹을 정의하고 그에 따라서 연관성의 측도를 계산해야 한다.\n\n\n\n\n2.3.2 상대위험\n\\(2 \\times 2\\) 분할표 표 2.1 에서 두 개의 처리군, 즉 치료약을 받은 집단과 위약을 받은 집단의 효과를 비교할 때 가장 많이 사용되는 측도(measure)는 상대위험(relative risk, risk ratio, prevalnce ratio;RR)이다.\n주어진 집단의 위험율을 그 집단에 속한 환자의 수에서 사망한 사람의 비율이다. 분할표 표 2.1 에서 위약 집단의 위험율은 \\(n_{11}/n_{1+}\\) 이며 이는 치료를 받지 않는 경우에 나타나는 기준점인 위험율(baseline risk)을 의미한다. 치료약 집단의 위험율은 \\(n_{21}/n_{2+}\\) 이다. 통상적으로 위험율은 비율(proportion, percent)로 나타내며 발생률(rate,예를 들어 인구 1000명당 X명)로 나타내기도 한다.\n상대위험은 두 위험율의 비율로서 다음과 같이 정의한다.\n\\[\\begin{equation}\nRR = \\frac{n_{11}/n_{1+}}{n_{21}/n_{2+}} = \\frac{ \\tfrac{n_{11}}{n_{11} + n_{12}}} { \\tfrac{n_{21}}{n_{21} + n_{22}}}\n\\end{equation}\\]\n상대위험이 1보다 크면 분자에 위치한 집단이 위험(위의 예제에서는 위험이 사망을 의미한다)에 처할 가능성이 분모에 위치한 집단보다 \\(RR\\) 배 높다는 것을 의미한다. 상대위험이 1이면 두 집단에 대한 위험이 동일하다는 것을 의미한다.\n예를 들어 특정한 코로나 치료제의 효과를 실험하는 임상실험에서 다음과 결과를 얻었다.\n\n\n\n표 2.2: 코로나 치료제 실험 결과\n\n\n\n\n\n치료/결과\n사망 (\\(Y=1\\))\n생존 (\\(Y=0\\))\n합계\n\n\n\n\n위약 (\\(X=0\\))\n\\(10\\)\n\\(1212\\)\n\\(1222\\)\n\n\n치료약 (\\(X=1\\))\n\\(5\\)\n\\(2355\\)\n\\(2360\\)\n\n\n합계\n\\(15\\)\n\\(3567\\)\n\\(3582\\)\n\n\n\n\n\n\n상대위험은 다음과 같이 계산된다.\n\\[ RR = \\frac{10/1222}{5/2360} = 3.8625 \\approx 4 \\]\n상대위험이 약 4 배란 의미는 치료약을 받은 집단보다 위약집단이 사망할 가능성이 약 4배 높다는 것이다.\n\n\n\n\n\n\n노트\n\n\n\n우리는 두 집단의 비율을 비교할 때 두 비율의 차이를 이용하는 방법을 자주 사용한다. 두 집단의 비율이 각각 \\(p_1\\), \\(p_2\\) 라면 두 비율의 차이는 \\(p_1 - p_2\\) 이며 이는 우리가 평상 적으로 사용하는 비율의 비교 측도이다.\n예를 들어 대통령 후보들의 지지율과 차이는 많은 언론에서 사용하고 있으며 기초 통계학에서 두 모집단의 비교를 위한 가설 검정에서도 비율의 차이를 이용하였다.\n위의 코로나 치료제의 효과를 비교하는 실험에서 치료집단과 위약집단의 사망률 차이를 측도로 사용하면 어떨까?\n\n\n\n\n2.3.3 기여위험과 백신효과\n기여위험(attributable proportion, attributable risk percent, AR)은 두 그룹의 위험에 대한 비교를 위한 다른 측도이다. 기여위험은 특정한 성격을 가진 집단(exposed group)이 위험에 처한 전체 집단에서 차지하는 비율을 백분율로 나타낸다.\n\\[\\begin{equation}\nAR = \\frac{ (n_{11}/n_{1+}) - (n_{21}/n_{2+})} {n_{11}/n_{1+} } \\times 100\n\\end{equation}\\]\n예를 들어 비흡연자(unexposed group)와 흡연자(exposed group)의 폐암에 대한 위험을 비교하는 경우를 생각해 보자.비흡연자의 폐암으로 인한 사망률이 연간 1000명 당 0.07명이고 흡연자는 1000명당 0.57명이라고 하면\n일단 상대위험은 약 8배이다.\n\\[  RR = 0.57/0.07 = 8.1428 \\]\n두 집단의 비교를 기여위험으로 나타내면 다음과 같다.\n\\[ AR = \\frac{0.57-0.07}{0.57} \\times (100) = 87.7\\% \\approx 88 \\%\\]\n만약 흡연이 폐암을 일으키는 원인이고 두 집단의 다른 요인이 유사하다고 가정하면, 기여위험이 약 88% 라는 것은 모든 폐암 환자(위험에 처한 전체 집단)의 88% 가 흡연에 의한 것이라고 해석할 수 있다.\n최근에 코로나 19에 대한 백신과 치료제의 임상실험에서 효과를 발표하는 경우 위에서 언급한 상대위험을 사용하지 않고 백신효과(Vaccine efficacy, vaccine effectiveness; VE) 라는 백분율을 사용한다. 백신효과는 기본적으로 기여위험과 동일한 측도이다.\n예를 들어 위의 예제에서 치료제의 효과를 백신효과(VE)로 계산하면 다음과 같다.\n\\[ VE = \\left [ \\frac{10/1222 - 5/2360}{10/1222} \\right ]\\times 100 =74.1101\\% \\]\n백신효과가 74% 란 의미는 치료제를 사용하면 사용하지 않는 경우보다 사망을 74% 줄일 수 있다고 해석할 수 있다.\n간단한 예로서 코로나19로 인한 치명율(사망자/확진자)을 비교한다고 가정하자. 백신을 맞은 그룹의 치명율이 1%이고 백신을 맞지 않는 그룹의 치명율이 2% 백신효과는 50%이다.\n\n\n2.3.4 오즈비\n오드(odd)는 가능성을 나타내는 측도로서 전통적으로 도박에서 유래된 측도이다.\n우리가 주사위를 던져서 1과 2가나오면 성공, 다른 숫자가 나오면 실패라고 하는 경우 성공의 확률은 \\(2/6 =0.3333\\) 으로 계산한다. 확률을 계산하는 경우는 분모에 전체 사건의 수를 사용한다.\n위의 주사위 예제로 오드를 계산하면 \\(2/4 =0.5\\) 가 된다. 즉, 오드는 분모에 성공을 제외한 실패의 사건을 수를 사용한다. 만약 오드가 1이면 무슨 의미인가? 오드가 1이면 성공하는 사건의 수가 실패하는 사건의 수가 동일하다는 의미이다. 게임에서 이길 확률이 \\(1/2\\) 이면 공정한 게임이며 이 경우 오드는 1 이다.\n전통적으로 오드는 확률의 개념이 나오기 전에 가능성의 측도로 오랫동안 사용되어 왔으며 도박에서 상대방이 1번 이길 때 내가 이기는 평균적인 횟수를 의미한다.\n\\[ odd = \\frac{\\text{number of events for success}}{\\text{number of events for failure}} \\]\n예를 들어 위의 코로나 치료제 실험에서 성공을 사망할 사건이라고 하면 위약군의 오드는 \\(n_{11}/n_{12} =10/1212\\) 이고 치료군의 오드는 \\(n_{21}/n_{22} = 5/2355\\) 이다.\n두 집단을 비교하는 측도 중 하나는 오즈비(odds ratio; OR)가 있다. 오즈비는 두 그룹의 오드들의 비율로 정의된다. 오즈비가 1이면 두 그룹에서 성공 사건의 가능성이 같다는 것이다.\n\\[ OR = \\frac{n_{11}/n_{12}}{n_{21}/n_{22}} = \\frac{n_{11} n_{22}}{n_{12} n_{21}} \\]\n코로나 치료제 실험에서의 오즈비는 \\((10/1212)/(5/2355) =3.8861\\) 이다.\n오즈비는 상대위험이나 기여위험에 비하여 의미 있는 해석이 어렵다. 오즈비가 1이면 두 집단이 성공의 가능성이 같다(또는 두 요인의 연관성이 없다)는 것으로 해석이 쉽다. 하지만 예를 들어 오즈비가 1 보다 큰 경우(또는 작은 경우) 두 집단의 차이를 의미 있게 해석하는 것이 어렵다.\n오즈비는 향후 학습할 통계적 가설검정에서 중요한 모수(parameter)로 사용되며 특히 실험의 방법이 사례-대조 연구와 같은 특별한 방법을 사용하는 경우 오즈비가 중요한 역할을 하게 된다.\n\n예를 들어 다음과 같은 분할표에서 비율의 차이, 상대위험, 오즈비를 구하여 비교해 보자.\n\n\n\n표 2.3: \\(2 \\times 2\\) 분할표 예제\n\n\n\n\n\n처리 /결과\n성공 (\\(Y=1\\))\n실패 (\\(Y=0\\))\n합계\n\n\n\n\n0 (\\(X=0\\))\n\\(6\\)\n\\(4\\)\n\\(10\\)\n\n\n1 (\\(X=1\\))\n\\(4\\)\n\\(6\\)\n\\(10\\)\n\n\n합계\n\\(10\\)\n\\(10\\)\n\\(20\\)\n\n\n\n\n\n\n비율의 차이(DP)은 다음과 같이 계산된다.\n\\[ DP(0/1) =  6/10 - 4/10 = 0.2 \\]\n상대위험은 다음과 같이 계산된다.\n\\[ RR(0/1) = \\frac{6/10}{4/10} = \\frac{6}{4} = 1.5 \\]\n오즈비는 다음과 같이 계산된다.\n\\[ OR(0/1) = \\frac{6/4}{4/6} = \\frac{(6)(6)}{(4)(4)} = 2.25 \\]",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#신뢰구간",
    "href": "notes/association.html#신뢰구간",
    "title": "2  연관성의 측도",
    "section": "2.4 신뢰구간",
    "text": "2.4 신뢰구간\n상대위험과 오즈비는 분할표에서 연관성을 나타내는 하나의 측도, 즉 점추정량(point estimation) 이다. 하나의 숫자로 표현되는 점추정은 표본으로 부터 발생한 불확실성을 반영하지 못한다. 따라서 점추정량을 보완하기 위하여 신뢰구간(confidence interval)을 제시할 수 있다.\n상대위험과 오즈비는 표본비율 또는 셀 도수의 함수로 나타난다. 하지만 함수의 형태가 비율로서 비선형이기 때문에 상대위험과 오즈비의 근사적인 표준오차(standard error)는 쉽게 구할 수 없다.\n다항분포를 가정하고 로그 오즈비의 점근적 분산을 다음과 같이 유도할 수 있다.\n\\[ v_1 =V ( \\log OR)   \\approx \\frac{1}{n_{11}} + \\frac{1}{n_{12}} + \\frac{1}{n_{21}} + \\frac{1}{n_{22}} \\]\n따라서 로그 오즈비의 \\(100(1-\\alpha)\\) % 근사 신뢰구간을 다음과 같이 구할 수 있다.\n\\[\\begin{equation*}\n   \\log OR \\pm z_{\\alpha/2} \\sqrt{v_1}\n\\end{equation*}\\]\n위의 신뢰구간을 오즈비로 역변환하면 오즈비 \\(OR\\) 의 \\(100(1-\\alpha)\\) % 근사 신뢰구간을 다음과 같다.\n\\[\n   ( OR \\times \\exp [ - z_{\\alpha/2} \\sqrt{v_1}], ~~OR \\times \\exp [  z_{\\alpha/2} \\sqrt{v_1}] )\n\\tag{2.1}\\]\n상대위험(RR)의 신뢰구간도 오즈비의 신뢰구간을 유도하는 방법과 유사하게 델타 방법을 사용하며 다음과 같이 구할 수 있다.\n\\[\n   ( RR \\times \\exp [ - z_{\\alpha/2} \\sqrt{v_2}], ~~OR \\times \\exp [  z_{\\alpha/2} \\sqrt{v_2}] )\n\\tag{2.2}\\]\n위의 식 식 2.2 에서 \\(v_2\\) 는 다음과 같이 계산한다.\n\\[ v_2 =V ( \\log RR)   \\approx \\frac{1-n_{11}/n_{1+}}{n_{11}} + \\frac{1-n_{21}/n_{2+}}{n_{21}} \\]\n\n2.4.1 예제: 아스피린 임상실험\n소량의 아스피린 복용이 심장병으로 인한 위험을 줄이는데 효과가 있는지 알아보고자 임상실험을 실시하였다. 22,701명의 남성을 임의화(randomization) 을 통해서 두 그룹으로 나눈 후, 한 그룹은 매일 일정량의 아스피린을 복용시키고 다른 그룹은 위약(palcebo)를 복용하게 한 후 약 5년간 심근경색이 일어나는지 알아보았다. 임상실험의 결과는 아래 표와 같다.\n\n\n\n표 2.4: 아스피린 임상실험 결과\n\n\n\n\n\n\n심근경색 발생\n심근경색 없음\n합\n\n\n\n\n아스피린\n\\(139\\)\n\\(10,898\\)\n\\(11,037\\)\n\n\n위약\n\\(239\\)\n\\(10,795\\)\n\\(11,034\\)\n\n\n\n\n\n\n위약 집단과 아스피린 집단의 상대위험은 다음과 같다.\n\\[ RR = \\frac{139/11037}{239/11034} = 0.581 \\]\n상대위험을 보면 1보다 작으므로 아스피린을 복용한 집단이 위약 집단에 비해서 심근 경색이 일어날 위험이 적어진 다는 것을 알 수 있다.\n상대위험의 95% 근사 신뢰구간은 다음과 같이 계산한다.\n먼저 다음 \\(v_2\\) 를 계산하면\n\\[ v_2 = \\frac{1-n_{11}/n_{1+}}{n_{11}} + \\frac{1-n_{21}/n_{2+}}{n_{21}}  =\n\\frac{1-139/11037}{139} + \\frac{1-239/11034}{239} = 0.011 \\]\n상대위험의 신뢰구간은 다음과 같다.\n\\[(0.581 \\times \\exp[-1.96\\sqrt{0.011}], 0.581 \\times \\exp[1.96\\sqrt{0.011}])\n= ( 0.473, 0.715)\\]\n위의 신뢰구간은 1을 포함하지 않으므로 상대위험이 1 과 유의한 차이가 있다고 할 수 있다. 결론적으로 아스피린의 복용은 심근경색의 발생을 감소시킨다고 할 수 있다.\n이제 epiR 패키지를 사용하여 위에서 분석한 내용을 다시 구해보자.\n먼저 위의 임상실험 자료를 R 의 matrix 형태로 저장한다.\n\nex1dat &lt;- matrix( c(139, 10898, 239, 10795), 2, 2, byrow=TRUE)\nex1dat\n\n     [,1]  [,2]\n[1,]  139 10898\n[2,]  239 10795\n\n\n이제 함수 epi.2by2를 이용하여 상대위험과 싱대구간을 구해보자. 임의화를 사용한 임상실험 자료인 경우 method = \"cross.sectional\" 으로 지정한다. 관심이 있는 사건(심근경색, outcome)의 도수가 첫 번째 열(column)에 있으니 outcome = \"as.columns\"이라고 지정한다.\n아래 결과에 Prevalence ratio라고 나오는 것이 상대위험이다.\n\nepi.2by2(dat = ex1dat, method = \"cross.sectional\", conf.level = 0.95, units = 100, \n   interpret = FALSE, outcome = \"as.columns\")\n\n             Outcome +    Outcome -      Total               Prev risk *\nExposed +          139        10898      11037       1.26 (1.06 to 1.49)\nExposed -          239        10795      11034       2.17 (1.90 to 2.46)\nTotal              378        21693      22071       1.71 (1.55 to 1.89)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nPrev risk ratio                                0.58 (0.47, 0.72)\nPrev odds ratio                                0.58 (0.47, 0.71)\nAttrib prev in the exposed *                   -0.91 (-1.25, -0.56)\nAttrib fraction in the exposed (%)            -71.99 (-111.63, -39.78)\nAttrib prev in the population *                -0.45 (-0.77, -0.13)\nAttrib fraction in the population (%)         -26.47 (-36.51, -17.18)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 26.944 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval\n * Outcomes per 100 population units",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association.html#casecontrol",
    "href": "notes/association.html#casecontrol",
    "title": "2  연관성의 측도",
    "section": "2.5 사례-대조 연구",
    "text": "2.5 사례-대조 연구\n심장발작을 일으킨 환자와 그렇지 않은 사람들을 각각 214명씩 조사하여 과거에 약물남용을 한 경력이 있는지 조사한 사례-대조 연구의 자료이다.\n\n\n\n표 2.5: 약물 남용 사례-대조 연구 결과\n\n\n\n\n\n\n심장 발작 발생\n심장발작 없음\n\n\n\n\n약물남용 유\n\\(73\\)\n\\(18\\)\n\n\n약물남용 무\n\\(141\\)\n\\(196\\)\n\n\n합\n214\n214\n\n\n\n\n\n\n이 연구의 목표는 약물남용과 심장발작의 연관성이 있는지를 알아보는 것이다. 이제 다음과 같은 사건들을 정의해 보자.\n\n\\(H+\\): 심장발작이 발생했다.\n\\(H-\\): 심장발작이 발생하지 않았다.\n\\(D+\\): 약물남용을 했다.\n\\(D-\\): 약물남용을 하지 않았다.\n\n위에서 정의된 사건들을 고려할 때 사례-대조 연구의 자료에서 다음과 같은 조건부 확률에 대한 추정값을 구할 수 있다.\n\\[\\begin{align*}\nP(\\textrm{약물남용을 했다} | \\textrm{심장발작이 발생했다}) & =P(D+|H+) = \\frac{73}{214} \\\\\nP(\\textrm{약물남용을 하지 않았다} | \\textrm{심장발작이 발생했다}) & =P(D-|H+) = 1- P(D+|H+) = \\frac{141}{214} \\\\\n  & \\\\\nP(\\textrm{약물남용을 했다} | \\textrm{심장발작이 발생하지 않았다}) & =P(D+|H-) = \\frac{18}{214} \\\\\n  P(\\textrm{약물남용을 하지 않았다} | \\textrm{심장발작이 발생하지 않았다}) & =P(D-|H-) = 1- P(D+|H-) = \\frac{196}{214}\n\\end{align*}\\]\n\n2.5.1 사례대조 연구의 목표와 가설\n연구에서 비교하고 싶은 비율은 위에서 추정한 확률이 아니고 조건과 결과가 바뀐 다음과 같은 조건부 확률이다. \\[\\begin{align*}\nP( \\textrm{심장발작이 발생했다} | \\textrm{약물남용을 했다} ) & = P(H+|D+) \\\\\nP( \\textrm{심장발작이 발생했다} | \\textrm{약물남용을 하지 않았다} ) & = P(H+|D-) \\\\\n\\end{align*}\\]\n즉 연구의 목표는 다음과 같은 가설을 검정하는 것이다.\n\\[\nH_0: P(H+|D+) = P(H+|D-)  ~~~\\text{ vs } ~~~H_1: P(H+|D+) \\ne P(H+|D-)\n\\tag{2.3}\\]\n전체 모집단을 약물남용을 한 사람들과 하지 않은 사람들로 두 집단으로 나누었을 때 두 집단에 대한 심장발작의 확률이 같은지 다른지 비교하고 싶은 것이다.\n위의 식에서 보듯이 추정하고 싶은 확률인 \\(P(H+|D+)\\)와 \\(P(H+|D-)\\)를 추정하려면 전체 모집단에 대한 심장발작 발병률 \\(P(H+)\\)와 약물남용의 비율 \\(P(D+)\\)를 알아야 한다. 즉\n\\[\\begin{align*}\nP(H+|D+) & = \\frac{ P(H+ \\cap D+)} { P(D+)} \\\\\n          & = \\frac{ P(D+|H+) P(H+)} { P(D+)} \\\\\n          & \\approx  (73/214) \\frac{ P(H+)} { P(D+)} \\\\\n\\end{align*}\\]\n위의 식은 다음의 조건부 확률 공식을 각 단계마다 적용한 결과이다.\n\\[ P(A \\cap B) = P(A|B)P(B) = P(B|A) P(A) \\]\n사례-대조 연구의 자료만으로는 모집단에 대한 심장발작 발병률 \\(P(H+)\\)와 약물남용의 비율 \\(P(D+)\\)을 구할 수 없다. 또한 다른 외부의 자료가 있다 하더라도 약물남용의 비율을 정확하게 추정하는 것은 매우 어렵다.\n\n\n2.5.2 오즈비의 비교\n이러한 문제는 두 집단의 비율의 차이나 상대위험을 비교하지 않고 오즈비를 구하여 비교하면 심장발작 발병률와 약물남용의 비율을 추정하지 않고 사례-대조 연구의 자료만으로 추론이 가능하다.\n다음의 가설은 두 비율의 비교를 오즈비로 표현한 것이다.\n\\[\nH_0: \\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)} =1  ~~~\\text{ vs } ~~~H_1:\n\\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)} \\ne 1\n\\tag{2.4}\\]\n위의 가설 식 2.4 는 단순한 비율을 비교하는 가설 식 2.3 과 동일한 가설이다.\n가설 식 2.4 에서 나타는 오즈비는 심장발작 발병률와 약물남용의 비율을 이용하지 않고 사례-대조 연구에서 추정할 수 있는 조건부 확률만으로 추정할 수 있다.\n\\[\\begin{align*}\n\\frac{P(H+|D+)/P(H-|D+)}{P(H+|D-) / P(H-|D-)}  \n   & =  \\frac{[P(H+|D+)P(D+)]/[P(H-|D+)P(D+)]}{[P(H+|D-)P(D-)] / [P(H-|D-)P(D-)]} \\\\\n   & =  \\frac{P(H+ \\cap D+)/P(H- \\cap D+)}{P(H+ \\cap D-) / P(H- \\cap D-)}\\\\\n   & =  \\frac{[P(D+|H+)P(H+)]/ [P(D+|H-) P(H-)]} {[P( D-|H+)P(H+)] / [P(D-|H-)P(H-)]}\\\\\n   & =  \\frac{P(D+|H+)/ P(D+|H-)} {P( D-|H+) / P(D-|H-)} \\\\\n   &=   \\frac{(73/214)/ (142/214)} {(18/214)/ (196/214)} \\\\\n   & = \\frac{(73)(196)}{(141)(18)} \\\\\n   & = 5.64\n\\end{align*}\\]\n결론적으로 사례-대조 연구에서는 연구의 목표에 대한 가설 검정을 비율의 차이나 상대위험으로 표현하여 수행할 수 없다. 하지만 오즈비를 검정하는 것으로 가설을 세우면 자료에서 쉽게 유도할 수 있는 오즈비로 가설 검정을 쉽게 수행할 수 있다.\n\n\n2.5.3 예제: 약물남용 사례-대조 연구\n심작발작을 일으킨 환자와 그렇지 않은 사람들을 각각 214명씩 조사하여 과거에 약물남용을 한 경력이 있느지 조사한 사례-대조 연구(case-control study) 의 결과가 표 표 2.5 에 있다.\n사례-대조 연구는 사례(case)가 발견되면, 즉 위의 연구와 같이 심장발작이 일어난 환자가 발생하면 그 환자와 유사한 나이와 성별 등을 가진 일반사람을 찾아 매칭하여 환자와 일반인의 과거 경력을 조사하는 후향적인 연구(restrspective study)이다. 반대로 앞의 예제에서 본 임의화를 이용한 임상실험은 전향적 연구(prospective study)이다.\n이러한 사례-대조 연구에서는 상대위험을 이용하여 연관성을 알아낼 수 없다. 하지만 사례-대조 연구에서 상대위험 대신 오즈비를 이용하여 연관성을 추론할 수 있다.\n위의 심장발작에 대한 사례-대조 연구의 결과에서 오즈비와 그 신뢰구간을 구해보자.\n먼저 오즈비는 다음과 같다.\n\\[ OR = \\frac{(73)(196)}{(18)(141)} = 5.64 \\]\n위의 결과는 심장발작이 일어난 집단에서 약물남용을 한 환자들의 오즈가 심장발작이 일어나지 않은 집단에서 약물남용을 한 사람들의 오즈에 비해 5.6배 크다는 것을 알 수 있으며 이는 1보다 상당히 크다.\n오즈비의 95% 근사 신뢰구간은 다음과 같이 계산한다.\n먼저 다음 \\(v_1\\) 를 계산하면\n\\[ v_1 =V ( \\log OR)   \\approx \\frac{1}{n_{11}} + \\frac{1}{n_{12}} + \\frac{1}{n_{21}} + \\frac{1}{n_{22}} = \\frac{1}{73} + \\frac{1}{18} + \\frac{1}{141} + \\frac{1}{196} =0.08\\]\n오즈비의 신뢰구간은 다음과 같다.\n\\[(5.64 \\times \\exp[-1.96\\sqrt{0.08}], 5.64 \\times \\exp[1.96\\sqrt{0.08}])\n= (3.222, 9.863)\\]\n위의 신뢰구간을 보면 1을 포함하지 않으므로 약물남용이 심장발작의 위험을 높인다고 말할 수 있다.\n이제 epiR 패키지를 사용하여 위에서 분석한 내용을 다시 구해보자.\n먼저 위의 사례-대조 연구 자료를 R 의 matrix 형태로 저장한다.\n\nex2dat &lt;- matrix( c(73,18,141,196), 2, 2, byrow=TRUE)\nex2dat\n\n     [,1] [,2]\n[1,]   73   18\n[2,]  141  196\n\n\n이제 함수 epi.2by2를 이용하여 오즈비과 신뢰구간을 구해보자. 사례-대조 연구의 자료인 경우 method = \"case.control\" 으로 저장한다. 사례-대조 연구로 지정하면 상대위험이 출력되지 않는다. 관심이 있는 사건(심장발작, outcome)의 도수가 첫 번째 열(column)에 있으니 outcome = \"as.columns\"이라고 지정한다.\n\nepi.2by2(dat = ex2dat, method = \"case.control\", conf.level = 0.95, units = 100, \n   interpret = FALSE, outcome = \"as.columns\")\n\n             Outcome +    Outcome -      Total                       Odds\nExposed +           73           18         91        4.06 (2.50 to 7.27)\nExposed -          141          196        337        0.72 (0.57 to 0.89)\nTotal              214          214        428        1.00 (0.83 to 1.21)\n\nPoint estimates and 95% CIs:\n-------------------------------------------------------------------\nExposure odds ratio                            5.64 (3.22, 9.86)\nAttrib fraction (est) in the exposed (%)      82.19 (68.26, 90.44)\nAttrib fraction (est) in the population (%)   28.06 (20.13, 35.21)\n-------------------------------------------------------------------\nUncorrected chi2 test that OR = 1: chi2(1) = 42.218 Pr&gt;chi2 = &lt;0.001\nFisher exact test that OR = 1: Pr&gt;chi2 = &lt;0.001\n Wald confidence limits\n CI: confidence interval",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연관성의 측도</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#필요한-패키지",
    "href": "notes/association-test.html#필요한-패키지",
    "title": "3  연관성의 검정",
    "section": "3.1 필요한 패키지",
    "text": "3.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#카이제곱-검정",
    "href": "notes/association-test.html#카이제곱-검정",
    "title": "3  연관성의 검정",
    "section": "3.2 카이제곱 검정",
    "text": "3.2 카이제곱 검정\n일단 2개의 이항변수 \\(X\\) 와 \\(Y\\) 를 고려하고 가능한 결과의 조합과 그 확률은 다음과 같은 \\(2 \\times 2\\) 분할표로 나타낼 수 있다.\n\n\n\n그림 3.1: 2 x 2 분할표\n\n\n\n\n\n\n일반적으로 \\(2 \\times 2\\) 분할표에서 다음과 같은 두 가지 가설이 가능하다.\n\n동질성 검정(homogeneuty test)\n변수 \\(X\\) 가 단순하게 독립 집단을 나누는 변수인 경우 (예를 들어 실험약 집단과 위약 집단) 두 그룹 간에 이항변수 \\(Y\\)의 성공확률이 같은지 검정하는 경우이다. 실험약 집단과 위약 집단에서 심장병이 발병할 확률이 같은지 검정을 수행할 때 귀무가설은 다음과 같다.\n\n\\[ H_0: p_{1j} = p_{2j} = p_j \\]\n\n독립성 검정(independent test)\n변수 \\(X\\) 와 \\(Y\\) 가 모두 확률변수인 경우 두 변수가 독립인지 검정하는 경우이다. 예를 들어 흡연(\\(X\\))과 심근경색(\\(Y\\))의 관계를 연구하는 경우 두 사건이 모두 확률적인 사건이라고 보고 다음과 같이 독립에 대한 가설을 고려한다.\n\n\\[ H_0: p_{ij} = p_{i+} p_{+j} \\]\n다음과 같이 \\(n\\) 개의 관측값으로 구성된 \\(2 \\times 2\\) 분할표에서 동질성과 독립성 가설을 검정하는 방법은 동일하며 따라서 굳이 두 가지 가설을 엄격하게 구별할 이유는 없다. 만약 귀무가설이 기각되면 두 변수의 연과성은 유의하다고 결론을 내린다.\n\n\n\n그림 3.2: 2 x 2 분할표: 관측 도수\n\n\n\n\n\n\n동질성과 독립성에 대한 검정은 다음과 같은 카이제곱 통계량을 사용한다.\n\\[\n\\chi^2 = \\sum_{i=1}^2 \\sum_{j=1}^2 \\frac{(O_{ij} - E_{ij})^2}{E_ij}  \n\\tag{3.1}\\]\n위의 카이제곱 통계량에서 \\(O_{ij} = n_{ij}\\) 는 각 셀의 관측도수이며 \\(E_{ij}\\)는 귀무가설 하에서의 셀 도수의 예측값이다.\n동질성 검정을 고려할 때 만약 귀무가설이 참이라면 확률 \\(p_{1j} =p_{2j}=p_j\\) 는 다음과 같이 추정할 수 있다.\n\\[ \\hat p_{j} = \\frac{n_{+j}}{n} \\]\n따라서 셀 \\((i,j)\\) 에 대한 기데 돗수 \\(E_{ij}\\) 는 다음과 같이 계산된다.\n\\[\nE_{ij} =n_{i+} \\hat p_j =\\frac{n_{i+} n_{+j}}{n}\n\\tag{3.2}\\]\n귀무가설 하에서 표본의 크기가 충분히 크면 식 식 3.1 의 카이제곱 검정통계량 \\(\\chi^2\\) 는 자유도가 1인 카이제곱 분포를 따른다. 그러므로 이 사실을 이용하여 p-값을 계산하거나 기각역을 구하여 검정한다.\n일반적인 \\(I \\times J\\) 분할표도 동일한 방법으로 가설검정을 할 수 있다. 카이제곱 통계량을 구하는 방법은 \\(2 \\times 2\\) 분할표와 유사하다. 다만 귀무가설이 참인 경우 검정통계량은 자유도가 \\((I-1)(J-1)\\) 인 카이제곱 분포를 따른다.\n\\[\n\\chi^2 = \\sum_{i=1}^I \\sum_{j=1}^J \\frac{(O_{ij} - E_{ij})^2}{E_ij}  \n\\]\n이제 실제 분할표에서 카이제곱 검정을 수행해 보자. 아스피린 임상실험 결과가 주어진 표 표 2.4 에서 아스피린의 횩과사 없는 경우, 즉 귀무가설이 참인 경우 다음과 같이 심근경색의 유무에 대한 예측 확률을 구할 수 있다.\n\\[ \\hat p_1 = \\frac{n_{+1}}{n} = \\frac{139+239}{22071} = 0.0171 \\] \\[\\hat p_2 = \\frac{n_{+2}}{n} = \\frac{10898+10795}{22071} = 0.9829 \\]\n이제 각 셀의 기대도수를 식 식 3.2 에 의하여 계산할 수 있다. 예를 들어 \\(E_{11}\\) 은 다음과 같이 계산된다.\n\\[ E_{11} = \\frac{n_{1+}n_{+1}}{n} =  n_{1+} \\hat p_1 = (11037)(0.0171) = 189.03 \\]\n각 셀에 대한 기대도수 \\(E_{ij}\\) 를 구하고 식 식 3.1 의 카이제곱 통계량을 구하면 다음과 같다.\n\\[\\begin{align*}\n\\chi^2 & = \\frac{(139-189.03)^2}{189.03} +  \\frac{(10898-10848.00)^2}{10848.00}  \\\\\n& \\quad + \\frac{(239-188.97)^2}{188.97} +  \\frac{(10795-10845.03)^2}{10845.03}  \\\\\n& = 26.94\n\\end{align*}\\]\n자유도가 1인 카이제곱 분포의 상위 5% 백분위수 \\(3.84\\) 이다. 위에서 구한 카이제곱 통계량의 값이 \\(26.94\\) 로서 \\(3.84\\) 보다 크므로 귀무가설을 기각한다. 즉 아스프린과 위약을 복용한 두 그룹 사이에는 심근경색이 일어날 비율에 유의한 차이가 있다.\nR 에서도 카이제곱 검정을 쉽게 수행할 수 있다. 앞에서 표 표 2.4 의 자료를 행렬의 형태로 저장하였는데 함수 chisq.test() 를 사용하면 결과를 쉽게 구할 수 있다.\n\nex1dat &lt;- matrix( c(139, 10898, 239, 10795), 2, 2, byrow=TRUE)\nex1dat\n\n     [,1]  [,2]\n[1,]  139 10898\n[2,]  239 10795\n\n\n\nchisq.test(ex1dat)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  ex1dat\nX-squared = 26.408, df = 1, p-value = 2.764e-07\n\n\n분할표에서의 기대도수 \\(E_{ij}\\) 는 다음과 같이 얻을 수 있다.\n\nchisq.test(ex1dat)$expected\n\n         [,1]     [,2]\n[1,] 189.0257 10847.97\n[2,] 188.9743 10845.03",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#코크란-맨텔-헨젤-검정",
    "href": "notes/association-test.html#코크란-맨텔-헨젤-검정",
    "title": "3  연관성의 검정",
    "section": "3.3 코크란-맨텔-헨젤 검정",
    "text": "3.3 코크란-맨텔-헨젤 검정\n임상실험이나 의학연구는 여러 나라 또는 여러 병원들에서 진행되는 경우가 있다. 이러한 경우 국가나 병원의 고유한 특성에 따라서 실험의 결과가 다르게 나타날 수 있다. 이렇게 그룹에 의한 효과를 그룹 효과 또는 층(strata)에 의한 효과라고 한다. 예를 들어 진통제에 대한 효과는 그 나라의 문화나 관습에 따라서 효과의 차이가 나타날 수 있다. 또한 여러 개의 변원에서 연그ㅜ가 동시에 진행된다면 병원의 규모, 위치, 환자들의 특성에 따라서 치료 효과의 차이가 나타날 수 있다.\n이렇게 그룹에 따른 차이가 예상되는 경우 그룹의 효과를 제어하면서 처리 효과의 차이를 검정하는 방법이 필요하다. 이렇게 여러 개의 층으로 구성된 독립집단에서 얻은 자료에서 층에 의한 횩과를 통제하면서 동질성 또는 독립성 검정을 수행하는 방법을 코크란-맨텔-헨젤 검정 (Cochran-Mantel-Haenzel test)라고 한다.\n아래와 같이 \\(K\\) 개의 독립집단(또는 층)에서 각각 얻은 \\(K\\) 개의 \\(2 \\times2\\) 분할표가 있다고 하자.\n\n\n\n그림 3.3: K 개의 2 x 2 분할표\n\n\n\n\n\n\n\\(K\\) 개의 독립집단이 있고 성공의 확률이 \\(p_1\\), 실패의 학률이 \\(p_2\\) 라고 한다면 처리의 효과를 전체적으로 비교하는 가설은 다음과 같다.\n\\[ H_0: p_1 =p_2 \\quad \\text{sv.} \\quad H_1: p_1 \\ne p_2 \\]\n이제 귀무가설의 가정 하에서 각 분할표에서 \\(n_{k11}\\) 에 대한 기대도수 \\(\\mu_{k11}\\) 와 그 분산 \\(v_{k11}\\) 을 다음과 같이 계산한다.\n\\[\n\\mu_{k11} = E(n_{k11} | H_0) = \\frac{ n_{k1+} n_{k+1} }{ n_k}\n\\]\n\\[\nv_{k11} = V ( n_{k11} | H_0)  = \\frac{ n_{k1+} n_{k2+} n_{k+1} n_{k+2} }{n^2_k (n_k-1)}\n\\]\n이제 가설검정을 위한 통계량 \\(Q_{CMH}\\) 은 다음과 같다.\n\\[\nQ_{CMH} = \\frac{ \\left [  \\sum_{k=1}^K  (n_{k11} - \\mu_{k11}) \\right ]^2 }{\\sum_{k=1}^K v_{k11}}\n\\tag{3.3}\\]\n귀무가설이 참인 경우 검정통계량 \\(Q_{CMH}\\) 은 자유도가 \\(1\\) 인 카이제곱 분포를 따른다.\n이제 Agresti (2012) 의 6.3절에 있는 다기관 임상시험(multi-center clinical trial) 의 예제를 살펴보자. 아래 표는 모두 8개의 독립적인 병원에서 감염 치료제에 대한 효과에 대한 실험을 실시하여 얻은 자료이다.\n\n\n\n그림 3.4: 8개 병원의 임상실험 결과\n\n\n\n\n\n\n마지막 병원을 제외한 7개의 병원에서 치료제의 효과가 긍정적으로 나타났다. 여기서 주목할 점은 병원에 따라서 연관성의 강도가 매우 다르게 나타날 수 있다는 것이다.\n이제 각 병원을 층(strata)로 고려하고 병원의 효과를 제어하면서 식 식 3.3 의 검정 통계량 \\(Q_{CMH}\\) 를 이용하여 치료제의 효과가 있는지 검정해보자. 검정은 아래와 같이 R 프로그램을 이용한다. 함수 mantelhaen.test() 는 코크란-맨텔-헨젤 검정을 수행하는 함수이다.\n\nbeitler &lt;- c(11,10,25,27,16,22,4,10,14,7,5,12,2,1,14,16,6,0,11,12,1,0,10,10,1,1,4,8,4,6,2,1)\nbeitler &lt;- array(beitler, dim=c(2,2,8))\nbeitler\n\n, , 1\n\n     [,1] [,2]\n[1,]   11   25\n[2,]   10   27\n\n, , 2\n\n     [,1] [,2]\n[1,]   16    4\n[2,]   22   10\n\n, , 3\n\n     [,1] [,2]\n[1,]   14    5\n[2,]    7   12\n\n, , 4\n\n     [,1] [,2]\n[1,]    2   14\n[2,]    1   16\n\n, , 5\n\n     [,1] [,2]\n[1,]    6   11\n[2,]    0   12\n\n, , 6\n\n     [,1] [,2]\n[1,]    1   10\n[2,]    0   10\n\n, , 7\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    1    8\n\n, , 8\n\n     [,1] [,2]\n[1,]    4    2\n[2,]    6    1\n\nmantelhaen.test(beitler, correct=FALSE)\n\n\n    Mantel-Haenszel chi-squared test without continuity correction\n\ndata:  beitler\nMantel-Haenszel X-squared = 6.3841, df = 1, p-value = 0.01151\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 1.177590 3.869174\nsample estimates:\ncommon odds ratio \n         2.134549 \n\n\n검정 통계량 \\(Q_{CMH}\\)의 값이 \\(6.3841\\) 이고 p-값은 \\(0.0115\\) 이므로 귀무가설을 기각한다.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/association-test.html#맥나마-검정",
    "href": "notes/association-test.html#맥나마-검정",
    "title": "3  연관성의 검정",
    "section": "3.4 맥나마 검정",
    "text": "3.4 맥나마 검정\n연속형 변수에서 짝지은 자료를 비교할 때 사용하는 방법이 대응 t-검정(paired t-test) 또는 짝표본 t-검정이다. 예를 들어 천식환자가 A약을 먹고 폐활량을 측정하고 일정 기간이 지나서 같은 환자가 B약을 먹고 폐활량을 측정하면 두 관측값은 독립이 아나다. 따라서 이러한 경우 독립 t-검정이 아닌 대응 t-검정을 시용한다.\n이제 이산형 변수가 짝으로 나타나는 경우를 생각해보자. 예를 들어 눈병 치료에 사용되는 A약과 B약의 효과를비교하기 위하여 각각의 약을 환자의 오른쪽 눈과 왼쪽 눈에 처치를 하고 치료의 여부를 관측하였다고 하자.\n\n\n\n그림 3.5: 짝표본 실험에 의한 2 x 2 분할표\n\n\n\n\n\n\n위의 표에서 \\(n_{11}\\) 은 A약과 B약의 효과가 모두 나타난 환자의 도수이다. \\(n_{12}\\) 은 A약은 효과가 있고 B약은 효과가 없는 환자의 도수이다. 이러한 자료는 앞에서 배운 카이제곱 검정을 적용할 수 없다.\n이제 일반적으로 짝표본에서 나온 자료가 다음 표와 같이 얻어졌다고 가정하자.\n\n\n\n그림 3.6: 짝표본 실험에 의한 2 x 2 분할표\n\n\n\n\n\n\n이제 조건 1 에서 성공의 확률을 \\(p_1\\) 이라고 하고 조건 2에서 성공의 확률을 \\(p_2\\) 라고 하면 짝표본에서 얻어진 분할표 그림 3.6 에서 관심있는 가설은 다음과 같다.\n\\[ H_0: p_1 =p_2 \\quad \\text{sv.} \\quad H_1: p_1 \\ne p_2 \\]\n분할표 그림 3.6 에서 \\(p_1\\) 과 \\(p_2\\)의 추정량은 다음과 같다.\n\\[ \\hat p_1 = \\frac{n_{1+}}{n}, \\quad \\hat p_2 = \\frac{n_{+1}}{n} \\]\n\\(p_1\\) 과 \\(p_2\\)의 추정량의 차이는 두 조건에 따른 결과가 일치하지 않는 도수 \\(n_{12}\\)와 \\(n_{21}\\)의 차이에 의존한다.\n\\[ \\hat p_1 -\\hat p_2 = \\frac{n_{1+}}{n} - \\frac{n_{+1}}{n} =\n\\frac{n_{11} + n_{12}}{n} - \\frac{n_{11} + n_{21}}{n} = \\frac{n_{12} - n_{21}}{n}\n\\]\n맥나마 검정(McNemar Test)는 도수 \\(n_{12}\\)와 \\(n_{21}\\)에 의거하여 두 확률이 같은지 검정하는 방법을 제시하였다. 맥나마 검정을 위한 통계량은 다음과 같다.\n\\[\nQ_{M} = \\frac{ (n_{12}-n_{21})^2}{n_{12} + n_{21}}\n\\tag{3.4}\\]\n맥나마 검정 통계량 \\(Q_{M}\\)은 귀무가설 하에서 근사적으로 자유도가 1인 카이제곱 분포를 따른다.\n다음은 1600명 영국 시민들의 수상에 대한 지지 여부를 두 개의 연속된 여론 조사에서 수집한 자료이다 (Agresti 2012 의 10장 참조). 이제 두 시점에서 수상에 대한 지지율이 같은지 아닌지 R 을 이용하여 맥나마 검정을 해보자. 맥나마 검정은 함수 mcnemar.test()를 사용하여 수행할 수 있다.\n\n\n\n그림 3.7: 영국시민의 수상에 대한 지지도 조사 자료\n\n\n\n\n\n\n\nex3dat &lt;- matrix(c(794,150,86,570),byrow=T,ncol=2)\nex3dat\n\n     [,1] [,2]\n[1,]  794  150\n[2,]   86  570\n\nmcnemar.test(ex3dat ,correct=F)\n\n\n    McNemar's Chi-squared test\n\ndata:  ex3dat\nMcNemar's chi-squared = 17.356, df = 1, p-value = 3.099e-05\n\n\n검정의 p-값이 매우 작으므로 귀무가설을 기각한다. 두 시점에서 수상에 대한 지지율이 하락했다고 할 수 있다. 참고로 첫 번째 조사에서의 지지율의 추정치는 \\(\\hat p_1=944/1600= 0.59\\) 이고 두 번째 조사에서의 지지율의 추정치는 \\(\\hat p_2=880/1600= 0.55\\) 이다. 또한 의견을 바꾸지 않은 사람의 비율은 \\((794+570)/1600=0.8225\\)로 대부분의 시민들이 지지 의견을 바꾸지 않았다.\n\n\n\n\nAgresti, Alan. 2012. Categorical data analysis. Vol 792. John Wiley & Sons.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>연관성의 검정</span>"
    ]
  },
  {
    "objectID": "notes/diagnose.html#민감도와-특이도",
    "href": "notes/diagnose.html#민감도와-특이도",
    "title": "4  진단의 평가",
    "section": "4.1 민감도와 특이도",
    "text": "4.1 민감도와 특이도\n진단 기법을 평가하는 경우 다음과 같은 두 질문에 대해서 생각해 보아야 한다.\n\n양성인 사람을 얼마나 잘 양성으로 판단하는가?\n음성인 사람을 얼마나 잘 음성으로 판단하는가?\n\n양성인 사람을 얼마나 잘 양성으로 판단하는지에 대한 평가 기준이 민감도(sensitivity) 이고 음성인 사람을 얼마나 잘 음성으로 판단하는지에 대한 평가 기준이 특이도(specificity) 이다. 민감도와 특이도의 정도는 확률로서 나타낼 수 있다.\n진단 기법에 대한 실험 연구를 수행하면 그 결과는 \\(2 \\times 2\\) 분할표로 다음과 같이 요약할 수 있다. 일반적으로 진단 기법의 효과를 측정하는 실험은 대상자에 대한 질병의 유무를 알고 시작한다.\n\n\n\n표 4.1: 진단 기법의 실험 결과\n\n\n\n\n\n진단(T) / 질병(D)\n양성 (\\(D+\\))\n음성 (\\(D-\\))\n\n\n\n\n양성 (\\(T+\\))\n\\(TP\\)\n\\(FP\\)\n\n\n음성 (\\(T-\\))\n\\(FN\\)\n\\(TN\\)\n\n\n\n\n\n\n위의 표에서 각 셀에 해당하는 진단 결과는 다음과 같이 나타낼 수 있다.\n\n\\(TP\\) : True Positive\n\\(FP\\) : False Positive\n\\(FN\\) : False Nagative\n\\(TN\\) : True Negative\n\n이제 분할표 표 4.1 에서 민감도와 특이도는 다음과 같이 정의된다.\n\\[\\begin{align}\n\\text{Sensitivity}(민감도) & = \\frac{TP}{TP+FN} \\\\\n\\text{Specificity}(특이도) & = \\frac{TN}{FP+TN}\n\\end{align}\\]\n다음은 코로나 바이러스 검사법에 대한 여러 연구에서 나온 민감도와 특이도 결과를 보여 준다 (Butler-Laporte 기타 (2021)).\n\n\n\n그림 4.1: 코로나 검사의 민감도와 특이도\n\n\n\n\n\n\n예제로서 그림 그림 4.1 에 제시한 종합적인 결과(pooled counts)를 이용하여 민감도와 특이도를 구해보자.\n\n\n\n표 4.2: 코로나 바이러스 검사법의 결과\n\n\n\n\n\n진단(T) / 질병(D)\n양성 (\\(D+\\))\n음성 (\\(D-\\))\n\n\n\n\n양성 (\\(T+\\))\n\\(664\\)\n\\(157\\)\n\n\n음성 (\\(T-\\))\n\\(120\\)\n\\(4981\\)\n\n\n\n\n\n\n민감도와 특이도는 다음과 같이 구할 수 있다.\n\\[\\begin{align*}\n\\text{Sensitivity} & = \\frac{664}{664+120} =  0.8469 \\\\\n\\text{Specificity} & = \\frac{4891}{157+4891} =  0.9689\n\\end{align*}\\]\n위에서 구한 민감도와 특이도는 Butler-Laporte 기타 (2021) 에서 제시한 민감도(83.2%), 특이도(99.2%) 와 유사하지만 약간의 차이가 있다. 그 이유는 Butler-Laporte 기타 (2021) 는 모든 실험 결과를 단순하게 더한 것이 아니라 메타분석(meta analysis)을 사용하여 얻은 결과이기 때문이다. 메타분석은 같은 주제에 대한 여러 개의 독립적인 연구 결과들을 결합하여 결론을 추론하는 연구 방법이다.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>진단의 평가</span>"
    ]
  },
  {
    "objectID": "notes/diagnose.html#양성예측도와-음성예측도",
    "href": "notes/diagnose.html#양성예측도와-음성예측도",
    "title": "4  진단의 평가",
    "section": "4.2 양성예측도와 음성예측도",
    "text": "4.2 양성예측도와 음성예측도\n앞에서 살펴본 민감도와 특이도를 구하는 실험에서는 실험 대상자가 질병이 있는지 없는지 알고 있다. 하지만 실제 검사는 진단을 받는 사람이 질병이 있는지 모르는 상태에서 진행된다.\n따라서 우리가 정말 관심 있는 확률은 양성으로 진단된 사람이 실제로 양성인지?에 대한 확률이다.\n양성으로 판정되었을 때 실제로 병에 걸렸을 확률을 양성예측도(\\(PV+\\)) (predicted value of positive test, predictive value positive) 라고 부르며 음성으로 판정되었을 때 실제로 병에 걸리지 않았을 확률을 음성예측도(\\(PV-\\)) (predicted value of negative test, predicted value negative) 라고 부른다. 양성예측도와 음성예측도는 조건부 확률로 표현할 수 있다.\n\\[\\begin{align}\nPV+ & = P( D+ | T+) \\\\\nPV- & = P( D- | T-)\n\\end{align}\\]\n이제 앞에서 살펴본 민감도와 특이도도 다음과 같이 조건부 확률로 나타낼 수 있다.\n\\[\\begin{align}\n\\text{Sensitivity} & =  P(T+|D+) \\\\\n\\text{Specificity} & =  P(T-|D-)\n\\end{align}\\]\n이제 실제로 중요한 양성예측도와 음성예측도를 민감도와 특이도를 이용하여 유도해 보자. 두 확률은 사건과 조건이 바뀐 확률이기 때문에 베이즈 정리(Bayes’ Theorem)을 이용하여 구할 수 있다.\n일단 양성예측도를 구하는 식을 베이즈 정리를 적용하여 유도해 보자.\n\\[\nP( D+ | T+)  = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) +  P(T+|D-)P(D-)}\n\\]\n위의 식에서 나타나는 확률 \\(P(D+)\\) 는 모집단에서 질병에 걸린 사람들의 비율을 의미하며 이를 유병률(prevalence) 이라고 부른다. 즉 양성예측도를 구하려면 질병의 유병률을 알아야 한다.\n다시 식을 정리해 보면 양성예측도에 대한 공식은 다음과 같다.\n\\[\\begin{align}\nP( D+ | T+)  & = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) +  P(T+|D-)P(D-)} \\\\\n         & = \\frac{ P(T+|D+)P(D+)} {  P(T+|D+)P(D+) + [1- P(T-|D-)][1-P(D+)]} \\\\\n         & = \\frac{(민감도)(유병률)}{(민감도)(유병률) + (1-특이도)(1-유병률)}\n\\end{align}\\]\n비슷한 계산 방법으로 음성예측도는 다음과 같이 주어진다.\n\\[\\begin{align}\nP( D - | T -)  & = \\frac{ P(T -|D -)P(D -)} {  P(T-|D-)P(D-) +  P(T-|D+)P(D+)} \\\\\n         & = \\frac{ P(T-|D-)[1-P(D+)]} {  P(T-|D-)[1-P(D+)] + [1- P(T+|D-)] P(D+)} \\\\\n         & = \\frac{(특이도)(1- 유병률)}{(특이도)(1-유병률) + (1-민감도)(유병률)}\n\\end{align}\\]\n이제 표 표 4.2 의 결과를 이용하여 코로나 검사의 양성예측도와 음성예측도를 구해보자.\n코로나 유병률은 나라마다 다르고 추정하기도 힘들다. 따라서 쉽게 현재 까지 누적환자수를 전체 인구로 나눈 단순한 비율을 유병률로 사용해 보자(주의! 우리가 여기서 사용한 비율은 실제 유병률을 계산하는 방법과 다르다). 2021년 현재 누적 환자 수가 274,415 명이고 2020년 기준 총인구는 51,829,136 명이므로 유병률을 \\(274415/51829136= 0.0053\\) 이라고 하자.\n이제 표 표 4.2 의 결과를 이용하면 코로나 검사의 양성예측도와 음성예측도는 다음과 같이 추정할 수 있다.\n\\[\\begin{align*}\nP( D+ | T+)  & = \\frac{(민감도)(유병률)}{(민감도)(유병률) + (1-특이도)(1-유병률)} \\\\\n     & = \\frac{(0.8469 )(0.0053)}{(0.8469 )(0.0053) + (1-0.9689)(1-0.0053)} \\\\\n     & = 0.1267\n\\end{align*}\\]\n\n(0.8469 )*(0.0053)/((0.8469 )*(0.0053) + (1-0.9689)*(1-0.0053))\n\n[1] 0.1267108\n\n\n\\[\\begin{align}\nP( D - | T -)  & = \\frac{(특이도)(1- 유병률)}{(특이도)(1-유병률) + (1-민감도)(유병률)}\\\\\n& = \\frac{(0.9689)(1- 0.0053)}{(0.9689)(1-0.0053) + (1-0.8469)(0.0053)} \\\\\n& = 0.9992\n\\end{align}\\]\n\n(0.9689)*(1- 0.0053)/((0.9689)*(1-0.0053) + (1-0.8469)*(0.0053))\n\n[1] 0.9991588\n\n\n사실 코로나 유병률은 정확하게 알 수도 없고 시간에 따라 변할 것이다. 이제 다양한 유병률에 따라서 양성예측도와 음성예측도가 어떻게 변하는지 계산해 보자.\n\ncalpred &lt;- function(prev, sen, spe){\n    pred.pos &lt;- sen*prev/(sen*prev + (1-spe)*(1-prev))\n  pred.neg &lt;- spe*(1-prev)/(spe*(1-prev) + (1-sen)*(prev))\n  res &lt;- data.frame(sen, spe, prev, pred.pos, pred.neg)\n  colnames(res) &lt;- c(\"Sensitivity\", \"SPecificity\",\"Prevalnce\", \"Pred. Post.\", \"Pred. Nega.\")\n  res\n}\n\npreval.range &lt;- seq(0, 0.02, 0.002)\ncalpred(preval.range ,0.8469, 0.9689 )\n\n   Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1       0.8469      0.9689     0.000  0.00000000   1.0000000\n2       0.8469      0.9689     0.002  0.05174816   0.9996834\n3       0.8469      0.9689     0.004  0.09858220   0.9993658\n4       0.8469      0.9689     0.006  0.14117039   0.9990471\n5       0.8469      0.9689     0.008  0.18006506   0.9987273\n6       0.8469      0.9689     0.010  0.21572673   0.9984064\n7       0.8469      0.9689     0.012  0.24854242   0.9980845\n8       0.8469      0.9689     0.014  0.27883973   0.9977614\n9       0.8469      0.9689     0.016  0.30689786   0.9974372\n10      0.8469      0.9689     0.018  0.33295620   0.9971120\n11      0.8469      0.9689     0.020  0.35722119   0.9967856\n\n\n\ncalpred(0.0053, 0.8469, 0.9689  )\n\n  Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1      0.8469      0.9689    0.0053   0.1267108   0.9991588\n\n\n\n\n\n\nButler-Laporte, Guillaume, Alexander Lawandi, Ian Schiller, Mandy Yao, Nandini Dendukuri, Emily G McDonald, 와/과 Todd C Lee. 2021. “Comparison of saliva and nasopharyngeal swab nucleic acid amplification testing for detection of SARS-CoV-2: a systematic review and meta-analysis”. JAMA Intern Med 181 (3): 353–58.",
    "crumbs": [
      "분할표의 분석",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>진단의 평가</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#필요한-패키지",
    "href": "notes/logistic.html#필요한-패키지",
    "title": "5  로지스틱 회귀모형",
    "section": "5.1 필요한 패키지",
    "text": "5.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#이항변수-예제",
    "href": "notes/logistic.html#이항변수-예제",
    "title": "5  로지스틱 회귀모형",
    "section": "5.2 이항변수: 예제",
    "text": "5.2 이항변수: 예제\n먼저 R을 이용한 로지스틱 회귀분석을 소개하기 위하여 다음의 예제를 이용하고자 한다.\n\n5.2.1 챌린져호 O-ring 자료\n1986년 미국우주항공국(NASA)이 발사한 우주왕복선 챌린져호(Spache Shuttle Challenger)가 로켓 엔진에 주요부품인 O-rings의 손상으로 인하여 공중에서 폭팔하는 사고가 일어났다. 다음 데이타는 미국우주항공국이 챌린져호를 발사하기 전에 실험을 통하여 얻은자료이다. 디음의 자료는 교과서의 R package faraway에서 orings에서 볼 수 있다.\n\n#data(orings)\norings %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\ntemp\ndamage\n\n\n\n\n53\n5\n\n\n57\n1\n\n\n58\n1\n\n\n63\n1\n\n\n66\n0\n\n\n67\n0\n\n\n67\n0\n\n\n67\n0\n\n\n68\n0\n\n\n69\n0\n\n\n70\n1\n\n\n70\n0\n\n\n70\n1\n\n\n70\n0\n\n\n72\n0\n\n\n73\n0\n\n\n75\n0\n\n\n75\n1\n\n\n76\n0\n\n\n76\n0\n\n\n78\n0\n\n\n79\n0\n\n\n81\n0\n\n\n\n\n\n\n\n위의 자료에서 temp는 실험에서 적용된 온도(화씨 F)이고 damage는 각 실험마다 6개의 링중에서 손상된 개수를 나타낸다. 참고로 1986년 챌린져호가 발사될 때의 온도는 31F 였다.\n먼저 그림을 통하여 온도의 변화에 따른 손상비율을 살펴보자.\n\nplot(damage/6 ~ temp, orings, xlim=c(25,85), ylim = c(0,1), xlab=\"Temperature\", ylab=\"Prob of damage\")\n\n\n\n\n\n\n\n\n\n\n5.2.2 강풍에 의한 나무 피해 자료\n1999년 미국 Misnnesota주의 Boundary Waters Canoe Area Wilderness (BWCAW)에서 심한 폭풍으로 생긴 강한 바람에 의해 쓰러진 나무들에 대한 자료를 수집하였다. 이 자료는 Weisberg (2014) (R package alr4) 에 수록된 자료이다.\n연구의 목적은 폭풍이 나무의 생존에 미치는 영향을 알아보는 것이다. 666 그루의 나무들에 대하여 나무가 바람에 의해 쓰러저 죽었는지 여부, 나무의 종, 나무의 지름, 폭풍의 국지적인 강도에 대한 자료를 수집하였다.\n\nd: Tree diameter, in cm\ns : Proportion of basal area killed for the four species balsam fir, cedar, paper birch and blue spruse, a measure of local severity of the storm.\nspp : Tree species, a factor with 9 levels\ny : 1 if the tree died, 0 if it survived\n\n\nhead(Blowdown) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ns\ny\nspp\n\n\n\n\n9\n0.0217509\n0\nbalsam fir\n\n\n14\n0.0217509\n0\nbalsam fir\n\n\n18\n0.0217509\n0\nbalsam fir\n\n\n23\n0.0217509\n0\nbalsam fir\n\n\n9\n0.0217509\n0\nbalsam fir\n\n\n16\n0.0217509\n0\nbalsam fir\n\n\n\n\n\n\n\n반응변수 \\(y\\) 를 쓰러진 나무는 \\(y=1\\)로하고 살아남은 나무를 \\(y=0\\)으로 코딩하였다. 나무의 상태 y에 나무의 지름 d이 미치는 영향을 살펴보려고 한다.\n수집된 자료중에서 나무의 종류가 black spruce인 자료만를 분석하기로 한다. 아래 코드는 black spruce인 자료만를 모아서 데이터프레임 BlowBS_raw 를 만드는 것이다.\n\nBlowBS_raw &lt;- Blowdown %&gt;% dplyr::filter(spp=='black spruce')\n\ndim(BlowBS_raw)\n\n[1] 659   4\n\nhead(BlowBS_raw) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ns\ny\nspp\n\n\n\n\n9\n0.0242120\n0\nblack spruce\n\n\n11\n0.0305947\n0\nblack spruce\n\n\n9\n0.0305947\n0\nblack spruce\n\n\n9\n0.0341815\n0\nblack spruce\n\n\n5\n0.0341815\n0\nblack spruce\n\n\n8\n0.0341815\n0\nblack spruce\n\n\n\n\n\n\n\n아래 그림은 쓰러진 나무와 살아남은 나무들의 지름의 분포를 비교한 것이다. 이를 통하여 지름이 큰 나무가 살아남을 확률이 더 커짐을 알수 있다.\n\nsm.density.compare(BlowBS_raw$d, BlowBS_raw$y,lty=c(1,2), xlab=\"D\")\nlegend(30,.1,legend=c(\"Y=0\",\"Y=1\"),lty=c(1,2))\n\n\n\n\n\n\n\n\n\nsm.density.compare(log(BlowBS_raw$d), BlowBS_raw$y,lty=c(1,2), xlab=\"log(D)\")\nlegend(3.2,.9,legend=c(\"Y=0\",\"Y=1\"),lty=c(1,2))\n\n\n\n\n\n\n\n\n또한 R package alr4 에 수록된 데이터셋 BlowBS 는 위에서 본 O-rings 예제와 동일하게 black spruce인 자료만 모아서 전체 횟수와 성공의 횟수로 요약된 자료이다.\n\nhead(BlowBS) %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nd\ndied\nm\n\n\n\n\n5.0\n6\n88\n\n\n5.5\n1\n2\n\n\n6.0\n6\n91\n\n\n6.5\n1\n1\n\n\n7.0\n17\n90\n\n\n7.5\n1\n1\n\n\n\n\n\n\n\n\nd :Tree diameter, in cm\ndied : Number of trees of this value of d that died (blowdown)\nm : number of trees of this size class measured\n\n이제 데이터셋 BlowBS 를 이용하여 나무의 지름과 나무 피해의 관계에 대해서 살펴보자.\n\nplot( died/m~ d, BlowBS, ylim = c(0,1), xlab=\"D\", ylab=\"Prob of Blow Down\")\n\n\n\n\n\n\n\n\n나무의 지름 \\(d\\)을 \\(\\log(d)\\)로 변환하여 예측변수(predictor) \\(x\\)로 하려고 한다.\n\nplot( died/m~ I(log(d)), BlowBS, ylim = c(0,1), xlab=\"log(D)\", ylab=\"Prob of Blow Down\")\n\n\n\n\n\n\n\n\n나무의 상태 \\(y\\)는 두 가지의 반응 결과를 가지는 이항변수이고 그 평균 \\(E(y)\\)는 0과 1사이의 값을 가지는 확률이지만 나무의 지름 \\(x=\\log(D)\\)는 연속형 변수이다.\n이러한 경우에 회귀분석의 모형은 어떻게 세울까?에 대하여 생각해보자.\n\\[ 0 \\le E(y|x) = p(x) \\le 1, \\quad \\quad -\\infty &lt; \\beta_0 + \\beta_1 x &lt; \\infty \\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#로지스틱-회귀모형",
    "href": "notes/logistic.html#로지스틱-회귀모형",
    "title": "5  로지스틱 회귀모형",
    "section": "5.3 로지스틱 회귀모형",
    "text": "5.3 로지스틱 회귀모형\n\n5.3.1 이항변수와 연결함수\n일반적으로 지금까지 배워온 회귀분석의 확률 모형에서는 반응변수 \\(y\\)는 연속형 확률변수이다. 따라서 예측변수 \\(x\\)의 값과 반응변수의 관계를 다음과 같은 회귀식으로 설명한다.\n\\[ E(y|x) =  \\beta_0 + \\beta_1 x  \\tag{5.1}\\]\n하지만 앞에서 살펴본 예제에서와 같이 반응변수의 값이 연속형 변수가 아니라 두 개의 가능한 결과만을 가지는 이항변수라면 위에서 주어진 회귀식은 적절하지 못하다.\n\\[\ny =\n\\begin{cases}\n1 & \\text{ with probabilty } p \\\\\n0 & \\text{ with probabilty } 1-p\n\\end{cases}\n\\]\n왜냐하면 반응변수의 기대값이 0과 1사이의 확률로 나타나기 때문이다.\n\\[ E(y|x) = 1\\cdot P(y=1|x) + 0 \\cdot P(y=0|x) = P(y=1|x) \\]\n따라서 반응변수의 기대값의 범위와 예측변수가 있는 선형예측식(linear predictor) \\(\\beta_0 + \\beta_1 x\\)의 범위가 일치하지 않아서 선형회귀식 식 5.1 을 그대로 사용할 수 없다.\n\n\n\n\n범위의 불일치\n\n\n\n\n\n위의 문제를 해결하기 위한 방법중의 하나는 다음과 같은 함수 \\(m\\)를 생각하여 변환된 선형예측식의 범위를 \\([0,1]\\)로 만드는 것이다.\n\\[ m:\\Re \\rightarrow [0,1]  \\quad \\text{and } \\quad m(x) \\text{ is monotone function}. \\]\n따라서 다음과 같은 이항변수를 반응변수로 하는 새로운 회귀식을 만들 수있다.\n\\[  E(y|x) = m(\\beta_0 + \\beta_1 x)  \\tag{5.2}\\]\n주로 쓰이는 변환함수로 다음과 같은 로지스틱 함수(logistic function)가 있다.\n\\[ m(x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) }  \\tag{5.3}\\]\n반응변수가 베르누이 분포를 따를 때 위의 로지스틱홤수를 사용하는 회귀식을 로지스틱 회귀식이라고 한다.\n\\[\nP(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\{ 1+ \\exp[-(\\beta_0 + \\beta_1 x)] \\}^{-1}\n\\tag{5.4}\\]\n위의 로지스틱 회귀식을 다시 역으로 정리하면 다음과 같은 식을 얻을 수 있다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] = \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x\n\\tag{5.5}\\]\n식 식 5.5 에서 나타난 함수 \\(g\\),\n\\[ g(p)=\\log \\frac{p}{1-p} \\]\n를 로짓함수(logit function) 라고 부르며 이는 로지스틱 함수의 역함수로서 0과 1 사이의 값을 가지는 확률을 실수 전체로 변환하는 함수로서 선형 예측식의 범위와 일치하게 한다.\n\n\n\n\n로지스틱 연결함수\n\n\n\n\n\n이렇게 관측값의 평균 (베르누이분포에서는 성공확률)과 선형예측식의 관계를 설정하는 함수를 연결함수(link function) 라고 하며 \\(g\\) 라고 표시한다.\n\\[\ng[E(y|x)] = g[p(x)] =  \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x\n\\tag{5.6}\\]\n따라서 로짓함수는 연결함수의 하나이며 다른 종류의 연결함수도 생각할 수 있다. 예를 들어 \\(\\Phi(x)=P(Z \\le x)\\)를 표준정규분포의 분포함수라 한다면 다음과 같은 연결함수를 생각할 수 있고 이를 probit 함수라고 부른다.\n\\[ g[p(x)] = \\Phi^{-1}(p(x)) = \\beta_0 + \\beta_1 x \\]\n만약 예측변수가 하나가 아닌 \\(p\\)개라면, 즉 예측변수 \\({\\pmb x}=(x_1,x_2,\\dots,x_{p})^t\\) 에 대한 로지스틱 회귀모형은 다음과 같이 확장할 수 있다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1 | x)} \\right  ] = \\pmb x^t \\pmb \\beta = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_2 +  \\dots \\beta_p x_{p}\n\\]\n\n\n5.3.2 예제\n위의 o-ring 예제(섹션 5.2.1)에서 성공(\\(y=1\\))은 O-ring이 손상된 경우이며 주어진 온도 \\(x\\)에서의 손상확률을 \\(p=(Y=1|x)=p(x)\\)라고 하면 다음과 같은 로지스틱회귀식을 생각할 수 있다.\n\\[ \\log \\frac{p(x)}{1-p(x)}=\\beta_0 + \\beta_1 x \\]\n다음과 같은 함수 glm을 이용하여 위의 로지스틱 회귀식을 적합할 수 있다.\n\nlogit1 &lt;- glm(cbind(damage,6-damage) ~ temp, family=binomial, orings)\nsummary(logit1)\n\n\nCall:\nglm(formula = cbind(damage, 6 - damage) ~ temp, family = binomial, \n    data = orings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 11.66299    3.29626   3.538 0.000403 ***\ntemp        -0.21623    0.05318  -4.066 4.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.898  on 22  degrees of freedom\nResidual deviance: 16.912  on 21  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 6\n\ncoef(logit1)\n\n(Intercept)        temp \n 11.6629897  -0.2162337 \n\n\n위의 결과에서 회귀식 기울기의 추정치는 \\(\\hat \\beta=\\) -0.2162337이다. 따라서 다음과 같은 회귀식을 얻을 수 있다.\n\\[ \\log \\frac{p(x)}{1-p(x)}=11.6629897+ (-0.2162337) x \\] 위의 회귀식을 이용하여 추정된 고장확률을 그림으로 그려보면 다음과 같다.\n여기서 ilogit은 로짓함수의 역함수를 계산해주며 다음과 같이 주어진 회귀식을 이용하여 확률을 계산한다.\n\\[ P(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\frac{1}{ 1+ \\exp[-(11.6629897+ (-0.2162337) x)] }\\]\n\nplot(damage/6 ~ temp, orings, xlim=c(25,85), ylim = c(0,1), xlab=\"Temperature\", ylab=\"Prob of damage\")\nx &lt;- seq(25,85,1)\nlines(x,ilogit(coef(logit1)[1]+coef(logit1)[2]*x))\n\n\n\n\n\n\n\n\n또한 온도가 31F인 경우 고장확률의 추정값은 \\(\\hat p =\\) 0.9930342이며 R 에서 다음과 같이 계산한다.\n\nx &lt;- 31\nilogit(coef(logit1)[1]+coef(logit1)[2]*x)\n\n(Intercept) \n  0.9930342 \n\n\n이제 강풍에 의한 나무의 피해에 대한 예제(섹션 5.2.2)에 대하여 로지스틱 회귀식을 적합해보자.나무의 상태 \\(y\\) 가 이항 변수이고 나무의 지름 \\(x=\\log(d)\\)을 예측변수로 하는 로지스틱회귀 모형을 고려하고 추정해보면 다음과 같은 회귀식을 얻는다\n\nlogit2 &lt;- glm(y~ I(log(d)),family=binomial(),data=BlowBS_raw)\nsummary(logit2)\n\n\nCall:\nglm(formula = y ~ I(log(d)), family = binomial(), data = BlowBS_raw)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -7.8925     0.6325  -12.48   &lt;2e-16 ***\nI(log(d))     3.2643     0.2761   11.82   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 856.21  on 658  degrees of freedom\nResidual deviance: 655.24  on 657  degrees of freedom\nAIC: 659.24\n\nNumber of Fisher Scoring iterations: 4\n\n\n\\[ \\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ]  =-7.892464+ (3.2642653) x \\] 위의 회귀식을 이용하여 추정된 나무가 부러져서 피해를 입을 확률은 다음과 같다.\n\\[ P(y=1|x) = \\frac{ \\exp(\\beta_0 + \\beta_1 x) }{ 1+ \\exp(\\beta_0 + \\beta_1 x) } =  \\frac{1}{ 1+ \\exp[-(-7.892464+ (3.2642653) x)] }\\] 이제 나무의 지름에 변화에 대하여 나무가 부러져서 피해를 입을 확률의 추정값을 그림으로 그려보자.\n\nplot( died/m~ I(log(d)), BlowBS, ylim = c(0,1), xlab=\"log(D)\", ylab=\"Prob of Blow Down\")\nx &lt;- seq(0,3.5,0.1)\nlines(x,ilogit(coef(logit2)[1]+coef(logit2)[2]*x))\n\n\n\n\n\n\n\n\n\n\n5.3.3 회귀계수의 해석\n일반적인 회귀분석의 모형 식 5.1 에서 계수 \\(\\beta_1\\)은 기울기로서 예측변수 \\(x\\)의 단위가 1 증가할 때 반응변수의 평균이 \\(\\beta_1\\)만큼 증가하는 것으로 해석할 수 있다. 하지만 로지스틱 회귀모형 식 5.4 에서는 이러한 해석을 할 수 없다.\n로지스틱 회귀모형에서 기울기 \\(\\beta_1\\)의 의미를 알아보기 위하여 예측변수 \\(x\\) 에 대한 베르누이 변수 \\(y\\)의 성공 확률 \\(P(y=1|x)\\)에 대한 오드(odd)를 정의하자.\n\\[ odd(x) = \\frac{P(y=1|x)}{1-P(y=1|x)} \\]\n이제 단순 로지스틱 회귀식 식 5.5 을 생각하고 예측변수 \\(x\\)를 0과 1의 값을 가지는 이항변수로 가정한다.\n\\(x=1\\) 인 경우는\n\\[  \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}  = \\exp( \\beta_0 + \\beta_1)  \\]\n이며 \\(x=0\\) 인 경우는\n\\[ \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} = \\exp(\\beta_0)   \\]\n위에서 주어진 두 개의 오드, 즉 \\(x=1\\)인 경우와 \\(x=0\\)인 경우의 두 오드의 비(odd ratio)를 구하면 다음과 같다.\n\\[   \\frac{ \\frac{P(y=1|x=1)}{1-P(y=1|x=1)} } {\\frac{P(y=1|x=0)}{1-P(y=1|x=0)}}  = \\exp (\\beta_1) \\]\n이는 다시 쓰면\n\\[   \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}   = \\exp (\\beta_1) \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} \\]\n위의 식에서 볼 떄 예측변수 \\(x\\)가 1 의 값을 가질 때 반응 변수의 오드가 예측변수 \\(x\\)가 0일 경우의 오드의 \\(\\exp (\\beta_1)\\)배로 변하는 것을 알 수 있다.\n따라서 \\(\\exp (\\beta_1)\\)는 반응변수의 오드의 증가량으로 볼 수 있다. 이는 두 성공확률의 오즈비가 \\(\\exp (\\beta_1)\\)을 말한다. 위의 식에 로그를 취하면 다음과 같은 관계를 얻는다.\n\\[  \\log   \\left [ \\frac{P(y=1|x=1)}{1-P(y=1|x=1)}  / \\frac{P(y=1|x=0)}{1-P(y=1|x=0)} \\right ]  = \\beta_1 \\]\n즉 오즈비의 로그값이 단순 로지스틱 회귀식에서 기울기 \\(\\beta_1\\)으로 나타난다.\n간단한 예제를 통하여 오즈비와 로지스틱 회귀의 기울기의 관계를 명확히 해보자. 100명의 사람들을 55세 이상의 사람(\\(x=1\\))과 55세 미만의 사람(\\(x=0\\))의 그룹으로 나누었을 떄 각 그룹에서 만성심장질환(CHD)가 있는 사람(\\(y=1\\))과 없는 사람(\\(y=0\\))의 수가 표 표 5.1 에 주어져있다.\n\n\n\n표 5.1: 나이와 만성심장질환의 관계\n\n\n\n\n\nCHD/나이\n나이 \\(\\ge 55\\) (\\(x=1\\))\n나이 \\(&lt; 55\\) (\\(x=0\\))\n합계\n\n\n\n\nCHD 있음 \\(y=1\\)\n21\n22\n43\n\n\nCHD 없음 \\(y=0\\)\n6\n51\n57\n\n\n합계\n27\n73\n100\n\n\n\n\n\n\n여기서 나이에 대한 CHD 유무의 오즈비는 다음과 같이 계산된다.\n\\[ \\text{Odds Ratio } = \\frac{ \\tfrac{21/27}{6/27}}{ \\tfrac{22/73}{51/73}} =  \\frac{(21)(51)}{(6)(22)} = 8.11 \\]\n위의 표 표 5.1 의 자료를 이용하여 로지스틱회귀를 적합시키면 결과가 아래와 같고 회귀계수 \\(\\beta_1\\)의 추정값은 오즈비의 로그값임을 알 수 있다.\n\\[ \\hat \\beta_1 = \\log (8.11) = 2.094  \\]\n표 표 5.1 의 자료에 대하여 로지스틱 회귀모형은 다음과 같이 적합할 수 있다.\n\nyes &lt;- c(21,22)\nno  &lt;- c(6,51)\nx &lt;- c (1,0)\nm1 &lt;- glm( cbind(yes,no) ~ x, family=binomial() )\nsummary(m1)\n\n\nCall:\nglm(formula = cbind(yes, no) ~ x, family = binomial())\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.8408     0.2551  -3.296  0.00098 ***\nx             2.0935     0.5285   3.961 7.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1.8704e+01  on 1  degrees of freedom\nResidual deviance: 1.4211e-14  on 0  degrees of freedom\nAIC: 11.987\n\nNumber of Fisher Scoring iterations: 3",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#추정과-검정",
    "href": "notes/logistic.html#추정과-검정",
    "title": "5  로지스틱 회귀모형",
    "section": "5.4 추정과 검정",
    "text": "5.4 추정과 검정\n\n5.4.1 이항분포와 가능도 함수\n주어진 예측변수 \\(x_i\\)에서 실행횟수가 \\(m_i\\)인 이항분포\\(B(m_i, p(x_i))\\)를 생각하자. \\(m_i\\)의 시행 중에 성공의 횟수가 \\(y_i\\)라고 하면 \\(y_i\\)의 확률밀도함수는 다음과 같다.\n\\[ {{m_i}\\choose{y_i}} {p(x_i)}^{y_i} [(1-p(x_i)]^{m_i-y_i} \\]\n그리고 \\(y_i\\)의 평균과 분산은 다음과 같다.\n\\[ E(y_i | x_i ) = m_i p(x_i), \\quad \\quad Var(y_i | x_i) = m_i p(x_i) [1-p(x_i)] , \\quad i=1,2,\\dots,n \\]\n이항분포를 위한 로지스틱 회귀방정식은 선형예측식과 성공의 확률의 관계를 다음과 같이 정한다.\n\\[ \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] =  \\beta_0 + \\beta_1 x_{i}  \\]\n서로 독립인 관측값 \\((y_1,y_2,\\dots,y_n)\\)의 가능도함수(likelihood function) \\(L\\)은 이항분포들의 결합확률밀도함수와 같고 아래와 같이 주어지며\n\\[ L = \\prod_{i=1}^n f(y_i|p(x_i)) = \\prod_{i=1}^n \\left [  {{m_i}\\choose{y_i}} \\right] {p(x_i)}^y_i {(1-p(x_i))}^{m-y_i}\n\\]\n로그가능도함수(log likelihood function) \\(l\\) 은 다음과 같이 나타낼 수 있다.\n\\[\\begin{align}\nl  & = \\log L \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log p(x_i) + \\sum_i (m_i -y_i) \\log [1-p(x_i)]  \\notag  \\\\\n   & = c(\\pmb y,\\pmb m) + \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)]  \\end{align}\\]\n결론적으로\n\\[ l(\\pmb \\mu|\\pmb y)  = \\log L(\\pmb \\mu|\\pmb y) =  c(\\pmb y,\\pmb m) + \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)]   \\tag{5.7}\\]\n위의 로그가능도함수에서 볼 수 있듯이 충분통계량인 성공의 횟수 \\(y_i\\)와 곱으로 나타내어진 함수가 로짓함수이며 이렇게 가능도함수에서 얻어진 결합함수를 자연 연결함수(natural link function)이라고 한다.\n회귀계수의 추정량은 최대가능도 추정법을 이용하여 구할 수 있으며 로그 가능도 함수가 회귀계수에 대하여 비선형이므로 반복을 이용한 계산법에 의하여 추정량을 얻을 수 있다.\n\\[ \\max_{\\pmb \\beta } \\log L = \\max_{\\pmb \\beta } \\sum_i y_i \\log \\left [ \\frac{p(x_i)}{1-p(x_i)} \\right  ] + \\sum_i m_i \\log [1-p(x_i)] \\]\n\n\n5.4.2 편차\n선형모형에서 잔차제곱합(residual sum of square; SSE)에 대한 의미를 살펴보고 이를 일반화 선형모형에 확장하는 개념인 편차(deviance)의 정의를 알아보자.\n먼저 다음과 같은 선형회귀식을 고려한다.\n\\[ y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots \\beta_p x_{pi} + e_i , \\quad i=1,2,\\dots,n \\]\n여기서 오차항 \\(e_i\\)를 서로 독립이며 평균이 0이고 분산이 \\(\\sigma^2\\)인 정규분포를 따른다고 가정하고 (\\(\\sigma^2\\)는 알고있다고 가정하자) 각 관측변수의 평균을 다음과 같이 \\(\\mu_i\\)로 하자.\n\\[   \\mu_i =E(y_i|x_i)= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots +\\beta_p x_{pi} \\]\n서로 독립인 관측변수 \\(y_i\\)의 분포는 정규분포를 따르므로\n\\[ y_i \\sim N(\\mu_i,\\sigma^2)   \\]\n관측치 \\(\\pmb y=(y_1,y_2,\\dots,y_n)^t\\)의 로그가능도함수는 다음과 같이 나타낼 수 있다.\n\\[ l(\\pmb \\mu|\\pmb y) = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu_i)^2 \\]\n예측변수 \\(x_1,x_2,\\dots,x_p\\)를 고려한 선형회귀모형에서 각 반응변수 평균의 예측식은 다음과 같다.\n\\[ \\hat \\mu_i = \\hat \\beta_0 + \\hat \\beta_1 x_{1i} + \\hat \\beta_2 x_{2i} + \\dots +\\hat \\beta_p x_{pi} \\equiv \\hat y_i \\]\n이 때 선형회귀모형의 로그가능도함수의 최대값는 다음과 같다.\n\\[\\begin{align*}\nl(\\hat{\\pmb \\mu}|\\pmb y) & = l_{regession}(\\hat {\\pmb \\beta}|y) \\\\\n& = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat \\mu_i)^2  \\\\\n  &= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2  \\\\\n   &= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} SSE\n\\end{align*}\\]\n이제 위의 선형회귀모형에서 예측변수 \\(x_1,x_2,\\dots,x_p\\)를 고려하지 않는 포화 모형을 생각해보자.\n\\[ y_i = \\beta_{0i} +e_i \\quad \\text{or} \\quad E(y_i) = \\beta_{0i} \\]\n이러한 포화 모형은 \\(n\\)개의 반응변수의 평균을 \\(n\\)개의 모수를 가진 모형으로 추정하는 것으로 위와 같은 모형을 포화 모형(saturated model)이라고 한다. 포화 모형에서 모수 \\(\\beta_{0i}\\)의 최소제곱 추정량(또는 최대가능도 추정량)는 관측값 \\(y_i\\)임을 쉽게 알수 있다.\n\\[ \\min_{\\beta_{0i}} \\sum_{i=1}^n (y_i -\\beta_{0i})^2 \\quad \\Rightarrow \\hat \\beta_{0i} = y_i, \\quad i=1,2,\\dots,n\n\\]\n포화 모형의 의미는 우리가 생각할 수 있는 모형 중에 가장 큰 모형으로 포화모형보다 큰 모형을 생각할 수 없다. 위에서 언급한 바와 같이 \\(n\\)개의 관측값에 대하여 모수의 수가 \\(n\\)개보다 큰 모형을 생각하면 유일한 모수의 추정이 불가능하다.\n선형회귀모형에서 포화모형은 \\(\\hat \\beta_{0i}=y_i\\)이며 로그가능도함수의 최대값은 \\(l(\\pmb y | \\pmb y)\\)로 표시하며 다음과 같다.\n\\[\\begin{align*}\nl(\\pmb y | \\pmb y) & = l_{saturated}(\\hat {\\pmb \\beta_{0}} | y) \\\\\n& = C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat \\beta_{0i})^2  \\\\\n&= C -\\frac{n}{2} \\log \\sigma^2 -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - y_i)^2  \\\\\n   &= C -\\frac{n}{2} \\log \\sigma^2 + 0\n\\end{align*}\\]\n포화모형은 설정할 수 있는 최대의 모수를 가진 가장 큰 모형이므로 우리가 생각할 수 있는 모형 중에서 관측값을 예측하는 예측력은 가장 좋다는 것을 알 수 있다(하지만 과적합모형이다).\n따라서 예측변수 \\(\\pmb x\\)들을 사용하는 선형회귀모형의 예측력이 포화모형이 가지는 예측력에 가까우면 좋은 모형이라고 생각할 수 있다. 반응변수의 평균을 예측하는 예측력은 로그가능도함수의 크기로서 나타낼 수 있다. 포화모형과 선형회귀모형의 로그가능도함수를 비교하면 포화모형의 로그가능도함수가 크다는 것을 알수 있고 (why?) 두 로그가능도함수의 의 차이를 비교하면 다음과 같다.\n\\[\nl(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) = l_{saturated}(\\hat {\\pmb \\beta_{0}} | y) -l_{regession}(\\hat {\\pmb \\beta}|y) = \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2 = \\frac{1}{2\\sigma^2}  SSE\n\\]\n위의 식을 가능도 함수의 비율로 다음과 같이 나타낼 수 있다.\n\\[ 2 \\log \\frac{L_{saturated}}{L_{regession}} =\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\hat y_i)^2 = \\frac{1}{\\sigma^2}  SSE  \\]\n따라서 포화모형과 로그가능도함수의의 차이가 작다는 것은 선형회귀모형의 잔차제곱합(SSE)이 작다는 것을 의미한다. 보통 잔차제곱합이 작으면 선형회귀모형의 예측력이 좋은 모형이며 이는 선형회귀모형의 가능도함수가 포화모형의 가능도함수에 가깝다는 의미이다.\n이렇게 모형의 예측능력을 평가하는 측도로서 편차(deviance)를 포화모형과 고려한 회귀모형의 로그가능도함수의 차이에 2를 곱한 양으로 정의한다. 따라서 편차는 작을 수록 좋다.\n\\[ deviance \\equiv D(\\pmb y;\\hat {\\pmb \\mu}) = 2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] = 2 \\log \\frac{L_{saturated}}{L_{regession}}\n\\tag{5.8}\\]\n정규분포인 경우 편차는 다음과 같이 주어진다.\n\\[\nD(\\pmb y;\\hat {\\pmb \\mu}) = 2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] =\n\\frac{1}{\\sigma^2}  SSE \\]\n이제 이항분포들에서 나온 관측값에 대한 포화모형을 생각해 보자.\n\\[ y_i \\sim B(m_i, p_i(x_i)), \\quad i=1,2,\\dots,n \\]\n위의 모형에서 포화모형은 어떤 모형일까? 포화모형은 \\(n\\)개의 관측변수의 평균, 여기서 \\(E(y_i/m_i) = p(\\pmb x_i)\\)를 \\(n\\)개의 관측치 \\(y_i\\)를 이용하여 추정한 모형으로서 각 성공확률은 해당하는 관측된 성공의 비율에 의해 추정된다. 즉,\n\\[ \\hat p(x_i) = \\frac{y_i}{m_i} \\]\n이러한 경우의 로그가능도함수의 값은 다음과 같이 주어진다.\n\\[\\begin{align*}\nl(\\pmb y | \\pmb y)  & =l_{saturated} \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log \\hat p(x_i) + \\sum_i (m_i -y_i) \\log (1- \\hat p(x_i))  \\\\\n& = \\sum_i \\log {{m_i}\\choose{y_i}} + \\sum_i y_i \\log  \\frac{y_i}{m_i} + \\sum_i (m_i -y_i) \\log (1- \\frac{y_i}{m_i})\n\\end{align*}\\]\n따라서 위에서 주어진 포화함수의 로그가능도함수에서 로지스틱회귀식의 로그가능도함수 식 5.7 를 빼고 2를 곱해서 편차를 정의할 수 있다.\n\\[\\begin{align*}\nD(\\pmb y;\\hat {\\pmb \\mu}) &=  2 \\left [ l(\\pmb y | \\pmb y) - l(\\hat {\\pmb \\mu} | \\pmb y) \\right ] \\\\\n&= 2 ( l_{saturated}-l_{regession})  \\\\\n   & = 2 \\left [\\sum_i y_i \\log  \\frac{y_i}{m_i} + \\sum_i (m_i -y_i) \\log (1- \\frac{y_i}{m_i})\n    -\\sum_i y_i \\log \\hat p(x_i) - \\sum_i (m_i -y_i) \\log (1-\\hat p(x_i)) \\right ]\\\\\n   & = 2\\left  [\\sum_i y_i \\log \\frac{y_i}{m_i \\hat p(x_i) } + \\sum_i (m_i -y_i) \\log \\frac{1-y_i/m_i}{1-\\hat p(x_i)}\\right ] \\\\\n   & = 2\\left [\\sum_i y_i \\log  \\frac{y_i}{m_i \\hat p(x_i) } + \\sum_i (m_i -y_i) \\log \\frac{m_i-y_i}{m_i- m_i \\hat p(x_i)} \\right ] \\\\\n   & = 2\\left  [\\sum_i y_i \\log   \\frac{y_i}{\\hat y_i } + \\sum_i (m_i -y_i) \\log \\frac{m_i-y_i}{m_i- \\hat y_i } \\right ]\\\\\n\\end{align*}\\]\n위에서 \\(\\hat y_i = m_i \\hat p(x_i)\\)으로 로지스틱 회귀에서 성공의 횟수의 평균에 대한 예측값이다.\n위의 논의에서 알 수 있듯이 로지스틱 회귀에서의 편차는 선형회귀 분석에서 잔차 제곱합 SSE의 의미로 해석할 수 있으며 작을 수록 모형의 예측력이 좋다는 것을 알 수 있다.\n\n\n\n\n\n\n편차의 점근적 분포\n\n\n\n편차는 표본의 개수 \\(m_i\\)가 충분히 크고 회귀식이 옳다는 가정 하에서 자유도가 \\(n-p\\) 인 카이제곱분포를 따른다. 여기서 \\(p\\)는 회귀계수 벡터 \\(\\pmb \\beta\\)의 크기이다.\n\\[  D(\\pmb y;\\hat {\\pmb \\mu}) \\sim \\chi^2_{n-p} \\]\n여기서 \\(n= \\sum_i m_i\\) 이고 \\(p\\) 는 회귀계수의 갯수이다.\n\n\n정규분포와 이항분포의 편차를 비교하면 정규분포의 편차에는 산포를 나타내는 모수 \\(\\sigma^2\\) 이 포함되어 있지만 이항분포의 편차에는 다른 모수가 나타나지 않는다. 식 식 5.8 에서 주어진 편차를 척도 모수(scaled parameter) 또는 산포 모수(dispersion parameter) \\(\\phi\\) 를 곱해준 값을 척도화 편차(scaled deviance) \\(D^*(\\pmb y;\\hat {\\pmb \\mu})\\) 라고 부른다.\n\\[ D^*(\\pmb y;\\hat {\\pmb \\mu}) = \\phi D(\\pmb y;\\hat {\\pmb \\mu})  \\tag{5.9}\\]\n정규분포에서 산포 모수가 분산 \\(\\phi=\\sigma^2\\) 이므로 척도화 편차는 잔차제곱합 \\(D^*(\\pmb y;\\hat {\\pmb \\mu}) = SSE\\) 가 되며 이항분포에서는 편차와 척도화 편차가 같다.\n이제 다시 o-ring 의 예제(섹션 5.2.1)에 대한 로지스틱 회귀식의ㅣ 결과를 보자.\n\nsummary(logit1)\n\n\nCall:\nglm(formula = cbind(damage, 6 - damage) ~ temp, family = binomial, \n    data = orings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) 11.66299    3.29626   3.538 0.000403 ***\ntemp        -0.21623    0.05318  -4.066 4.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.898  on 22  degrees of freedom\nResidual deviance: 16.912  on 21  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 6\n\n\n마지막에 Residual deviance 는 다음과 같이 절편과 하나의 예측 변수(온도)를 포함한 회귀식에 대한 편차의 값과 자유도를 나타내는 것이다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] =\\beta_0 + \\beta_1 x \\quad \\rightarrow D(\\pmb y;\\hat {\\pmb \\mu}) = 16.9122785\n\\]\n\ndeviance(logit1)\n\n[1] 16.91228\n\ndf.residual(logit1)\n\n[1] 21\n\n\n위에서 언급하였듯이 모형이 옪다는 가정하에서 편차 \\(D(\\pmb y;\\hat {\\pmb \\mu})\\) 는 자유도가 21 인 \\(\\chi^2\\)-분포를 따르므로 아래에서 구한 \\(P(\\chi^2 \\ge 16.9122785 )\\) 가 크게 나오는 것은 모형이 적절하다는 의미이다.\n\npchisq(deviance(logit1), df.residual(logit1),lower=FALSE)\n\n[1] 0.7164099\n\n\n또한 Null deviance 는 다음과 같이 절편만 포함한 회귀식에 대한 편차의 값과 자유도를 나타내는 것이다.\n\\[\n\\log \\left [ \\frac{P(y=1|x)}{1-P(y=1|x)} \\right ] =\\beta_0\n\\]\n\n\n5.4.3 검정과 모형의 선택\n로지스틱 회귀모형에서 하나의 회귀 계수가 유의한 지에 대한 다음 검정은\n\\[ H_0 : \\beta_i =0 \\quad vs. \\quad H_1: \\beta_i \\ne 0 \\] 다음과 같은 표준화된 통계량을 이용하여 정규분포 검정을적용할 수 있다.\n\\[ z = \\frac{ \\hat \\beta_i}{SE(\\hat \\beta_i)} \\] 또한 회귀 계수 \\(\\beta_i\\) 에 대한 \\((1-\\alpha)100\\%\\) 신뢰구간은 다음과 같이 구할 수 있다.\n\\[  [ \\hat \\beta_i - z_{\\alpha/2 } SE(\\hat \\beta_i) , `` \\hat \\beta_i + z_{\\alpha/2 } SE(\\hat \\beta_i) ] \\]\n위의 o-ring 예제(섹션 5.2.1)에서 온도에 대한 회귀 계수의 \\(95\\%\\) 신뢰구간은 다음과 같이 MASS 패키지의 함수 confint를 이용해서 구한다.\n\nconfint(logit1)\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept)  5.575195 18.737598\ntemp        -0.332657 -0.120179\n\n\n이제 회귀모형에서 고려하는 다음과 같은 가설 검정을 고려해 보자.\n\\[ H_0 : \\text{ reduced model} \\quad vs. \\quad H_1: \\text{full model}  \\tag{5.10}\\]\n로지스틱 회귀에서 편차(deviance)의 차이를 이용하여 두 개의 모형 중 하나를 선택하는 방법을 살펴보자.\n다음과 같이 서로 다른 모형과 그에 대한 가설을 생각해 보자. \\[\nH_0: g[p(x)]  = {\\pmb x}_1^t {\\pmb \\beta}_1 \\quad \\text{vs.} \\quad H_1: g[p(x)] = {\\pmb x_1}^t {\\pmb \\beta}_1+ {\\pmb x}_2^t {\\pmb \\beta}_2\n\\]\n가설을 달리 표현하면 다음과 같이 쓸 수 있다.\n\\[\nH_0: {\\pmb \\beta}_2 =0  \\quad \\text{vs.} \\quad H_1: {\\pmb \\beta}_2 \\ne 0\n\\] 위의 가설에서 \\(dim(\\pmb \\beta_1) = p\\), \\(dim(\\pmb \\beta_2) = q\\) 라고 하면 대립가설 \\(H_1\\)의 모형이 귀무가설 \\(H_0\\)의 모형보다 큰 모형이다.\n만약 축소모형(reduced moldel, \\(H_0\\))에 대한 잔차 편차(Residual Deviance)를 \\(D_0\\) 라고 하고 큰 모형(full model, \\(H_1\\))에 대한 잔차 편차를 \\(D_1\\) 라고 하면 귀무가설이 참인 경우 두 편차의 차이 \\(D_0 - D_1\\) 은 근사적으로 자유도가 \\(q\\) 인 카이제곱분포를 따른다. 여기서 자유도 \\(q\\) 는 두 모형의 회귀계수의 갯수 차이 $(p+q)-p=q이다. 이러한 두 편차의 차이의 점근적 분포 가능도비검정 이론에 의하여 유도할 수 있다.\n\\[ D= D_0 - D_1 \\]\n두 모형에 대한 모수의 개수의 차이 \\(q\\)인 경우 귀무가설이 참일 때 deviance의 차인 \\(D= D_0 - D_1\\) 통계량은 자유도가 \\(q\\)인 \\(\\chi^2\\)-분포를 따른다. 따라서 유의수준 \\(\\alpha\\)에서 \\(D\\) 통계량이 \\(\\chi^2_\\alpha(q)\\)보다 크면 귀무가설을 기각한다.\n편차 차이를 이용하여 검정하는방법은 가능도비 검정(likelihood ratio test)과 동일한 검정이다.\n다음 자료는27명의 암환자들에 대한 암의 호전(remission of cancer)이며 종속변수 \\(y\\)는 remiss로 1이면 암이 호전되었다는 표시이다. 나머지 6개의 변수는 환자의 특성을 나타내는 독립변수이다.\n\ncancer &lt;- read.table(\"remission.txt\",header=T, sep=\"\")\ncancer %&gt;% kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nid\nremiss\ncell\nsmear\ninfil\nli\nblast\ntemp\n\n\n\n\n1\n1\n0.80\n0.83\n0.66\n1.9\n1.100\n0.996\n\n\n2\n1\n0.90\n0.36\n0.32\n1.4\n0.740\n0.992\n\n\n3\n0\n0.80\n0.88\n0.70\n0.8\n0.176\n0.982\n\n\n4\n0\n1.00\n0.87\n0.87\n0.7\n1.053\n0.986\n\n\n5\n1\n0.90\n0.75\n0.68\n1.3\n0.519\n0.980\n\n\n6\n0\n1.00\n0.65\n0.65\n0.6\n0.519\n0.982\n\n\n7\n1\n0.95\n0.97\n0.92\n1.0\n1.230\n0.992\n\n\n8\n0\n0.95\n0.87\n0.83\n1.9\n1.354\n1.020\n\n\n9\n0\n1.00\n0.45\n0.45\n0.8\n0.322\n0.999\n\n\n10\n0\n0.95\n0.36\n0.34\n0.5\n0.000\n1.038\n\n\n11\n0\n0.85\n0.39\n0.33\n0.7\n0.279\n0.988\n\n\n12\n0\n0.70\n0.76\n0.53\n1.2\n0.146\n0.982\n\n\n13\n0\n0.80\n0.46\n0.37\n0.4\n0.380\n1.006\n\n\n14\n0\n0.20\n0.39\n0.08\n0.8\n0.114\n0.990\n\n\n15\n0\n1.00\n0.90\n0.90\n1.1\n1.037\n0.990\n\n\n16\n1\n1.00\n0.84\n0.84\n1.9\n2.064\n1.020\n\n\n17\n0\n0.65\n0.42\n0.27\n0.5\n0.114\n1.014\n\n\n18\n0\n1.00\n0.75\n0.75\n1.0\n1.322\n1.004\n\n\n19\n0\n0.50\n0.44\n0.22\n0.6\n0.114\n0.990\n\n\n20\n1\n1.00\n0.63\n0.63\n1.1\n1.072\n0.986\n\n\n21\n0\n1.00\n0.33\n0.33\n0.4\n0.176\n1.010\n\n\n22\n0\n0.90\n0.93\n0.84\n0.6\n1.591\n1.020\n\n\n23\n1\n1.00\n0.58\n0.58\n1.0\n0.531\n1.002\n\n\n24\n0\n0.95\n0.32\n0.30\n1.6\n0.886\n0.988\n\n\n25\n1\n1.00\n0.60\n0.60\n1.7\n0.964\n0.990\n\n\n26\n1\n1.00\n0.69\n0.69\n0.9\n0.398\n0.986\n\n\n27\n0\n1.00\n0.73\n0.73\n0.7\n0.398\n0.986\n\n\n\n\n\n\n\n\n\n\n\n\n\n노트\n\n\n\nR에서 함수 glm 을 사용하여 로지스틱 회귀모형을 적합하는 경우 반응변수의 값이 2개인 경우 어떤 것이 성공을 의미하는 것인지 알려주어야 한다.\nR에서는 반응변수의 값의 순서를 비교하여 마지막 순서를 성공으로 인식한다. 따라서 반응변수 y 의 값이 0과 1인 경우 y=1 인 사건을 성공이라고 인식하게 된다.\n만약 반응변수의 값이 0 과 1 이 아닌 문자로 되어있는 경우 함수 factor() 의 level= 명령어를 이용하여 순서를 정해 주는 것이 좋다.\n\n\n다음은 6개의 독립변수를 모두 적합한 완전모형(full model)의 추정 결과이다.\n\nlogit3_L &lt;- glm(remiss~cell + smear + infil + li + blast + temp,family=binomial,data=cancer)\nsummary(logit3_L)\n\n\nCall:\nglm(formula = remiss ~ cell + smear + infil + li + blast + temp, \n    family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  58.0385    71.2364   0.815   0.4152  \ncell         24.6615    47.8377   0.516   0.6062  \nsmear        19.2936    57.9500   0.333   0.7392  \ninfil       -19.6013    61.6815  -0.318   0.7507  \nli            3.8960     2.3371   1.667   0.0955 .\nblast         0.1511     2.2786   0.066   0.9471  \ntemp        -87.4339    67.5735  -1.294   0.1957  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 21.751  on 20  degrees of freedom\nAIC: 35.751\n\nNumber of Fisher Scoring iterations: 8\n\n\n위의 회귀분석 결과를 보면 변수들 중 세 개의 변수 li, temp , cell 만 포함한 축소된 모형(reduced model)을 생각해보자.\n\nlogit3_S &lt;- glm(remiss~cell + li + temp,family=binomial,data=cancer)\nsummary(logit3_S)\n\n\nCall:\nglm(formula = remiss ~ cell + li + temp, family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   67.634     56.888   1.189   0.2345  \ncell           9.652      7.751   1.245   0.2130  \nli             3.867      1.778   2.175   0.0297 *\ntemp         -82.074     61.712  -1.330   0.1835  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 21.953  on 23  degrees of freedom\nAIC: 29.953\n\nNumber of Fisher Scoring iterations: 7\n\n\n위에서 적합한 두개의 모형이 유의한 차이가 있는지 위에서 논의한 편차의 차이를 이용하여 검정해 보자. 다음과 같은 가설을 검정하는 검정은 다음과 같이 anova함수로 수행할 수 있다.\n앞에서 두 모형을 적합한 결과에서 잔차 편차(Residual deviance)의 차이를 이용하여 검정을 실시하였다.\n\nanova(logit3_S, logit3_L,test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: remiss ~ cell + li + temp\nModel 2: remiss ~ cell + smear + infil + li + blast + temp\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1        23     21.953                     \n2        20     21.751  3  0.20272   0.9771\n\n\n위의 anova 함수의 결과를 보면 p-vlaue가 0.9771497로 매우 크며 귀무가설 \\(H_0\\)를 기각하지 못한다. 따라서 3개의 독립변수만 가진 축소된 모형을 선택할 수 있다.\n다시 하나의 독립변수 li 만 가지는 축소모형을 고려해 보자.\n\nlogit3_S2 &lt;- glm(remiss~li,family=binomial,data=cancer)\nsummary(logit3_S2)\n\n\nCall:\nglm(formula = remiss ~ li, family = binomial, data = cancer)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   -3.777      1.379  -2.740  0.00615 **\nli             2.897      1.187   2.441  0.01464 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 34.372  on 26  degrees of freedom\nResidual deviance: 26.073  on 25  degrees of freedom\nAIC: 30.073\n\nNumber of Fisher Scoring iterations: 4\n\n\n완전모형과의 차이에 대한검정을 실시하며 다음과 같은 결과가 나오고 cencer remission 자료는 사실상 변수 li만으로도 충분히 설명할 수 있다는 결론이다.\n\nanova(logit3_S2, logit3_L,test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: remiss ~ li\nModel 2: remiss ~ cell + smear + infil + li + blast + temp\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1        25     26.073                     \n2        20     21.751  5   4.3223    0.504\n\n\n모형을 선택하는 경우 AIC(Akaike Information Criteria)를 자주 이용한다. AIC는 다음과 같이 정의되며\n\\[ AIC = -2*log(\\text{Likelihood}) +2*(\\text{number of parameter}) \\] 모형의 AIC값이 작을수록 좋은 모형이다.\n\nAIC(logit3_L, logit3_S, logit3_S2)\n\n          df      AIC\nlogit3_L   7 35.75065\nlogit3_S   4 29.95337\nlogit3_S2  2 30.07296\n\n\n위에서 나타난 AIC로 모형을 선택한다면 독립변수가 3개(li, temp , cell )인 모형이 가장 좋은 모형이다. AIC는 모형에 위에서 주어진 두 번째 항에서 독립변수의 수(number of parameter)를 더해주므로 모형이 복잡할수록 그 값이 증가하여 모형의 선택에서 벌칙(penalty)를 주는 것으로 이해할 수 있다.\nAIC는 로그우도함수와 모형의 자유도로 직접 계산할 수 있다.\n\nAIC(logit3_S)\n\n[1] 29.95337\n\n# value of log likelihood\nas.numeric(logLik(logit3_S))\n\n[1] -10.97668\n\n#number of parameter = 3+1\nattr(logLik(logit3_S),\"df\")\n\n[1] 4\n\n#AIC\n-2*as.numeric(logLik(logit3_S))+2*attr(logLik(logit3_S),\"df\")\n\n[1] 29.95337\n\n\n위에서 모형의 자유도는 독립변수의 개수 3개와 절편 1개를 더해서 4개가 된다.\n\n\n5.4.4 적합도 검정\n모형의 적합도를 측정하는 통계량으로 편차(deviance)뿐만 아니라 \\(\\chi^2\\)-통계량도 매우 유용하다. \\(\\chi^2\\)-통계량은 다음과 같이 주어진다.\n\\[ \\chi^2 = \\sum_{i=1}^n \\frac{ (y_i - m_i \\hat p(x_i))^2 }{m_i \\hat p(x_i)[1-\\hat p(x_i)]}  \\tag{5.11}\\]\n위의 식은 다음과 같은 표준화된 피어슨 잔차 \\(r_i\\) 의 제곱합과 같다.\n\\[ r_i = \\frac{ y_i - m_i \\hat p(x_i)}{\\sqrt{var(\\hat y_i)}} \\] 자료의 수가 많으면 \\(\\chi^2\\)-통계량은 \\(\\chi^2\\) 분포를 따른다.\n\\(\\chi^2\\)-통계량은 다음과 같이 계산할 수 있다.\n\nsum(residuals(logit1,type=\"pearson\")^2)\n\n[1] 28.06738",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/logistic.html#과산포",
    "href": "notes/logistic.html#과산포",
    "title": "5  로지스틱 회귀모형",
    "section": "5.5 과산포",
    "text": "5.5 과산포\n\n5.5.1 과산포의 개요\n로지스틱 회귀식을 적합한 뒤에 주어진 모형이 적절한 모형이라고 판단되지만 잔차 편차(residual devince) \\(D\\)가 기대 이상으로 너무 커서 서로 상충되는 결론이 나오면 다음과 같은 원인을 의심할 수 있다.\n\n중요한 예측변수 \\(x\\)가 모형에 포함되지 않았거나 예측함수 \\(\\eta={\\pmb x}^t {\\pmb \\beta}\\)가 잘못 설정된 경우\n이상점(outlier)이 있는 경우\n반복수의 수가 매우 적은 경우\n분포의 가정이 맞지 않는 경우 - 독립이 아닌 경우, 군집효과(cluster effect)\n\n반응변수 \\(y\\)가 이항분포 \\(B(m,p)\\) 를 따르면 그 평균과 분산은 다음과 같이 주어진다.\n\\[ E(y) = mp \\quad \\text{ and } \\quad Var(y) = mp(1-p) \\]\n자료의 확률 구조가 이항분포의 평균과 분산에 대한 가정과 맞지 않는 경우를 분산의 크기에 따라 과산포(overdispersion) 또는 underdispersion이라고 한다.\n\noverdispersion if \\(Var(y) &gt; mp(1-p)\\)\nunderdispersion if \\(Var(y) &lt; mp(1-p)\\)\n\n예를 들어 모집단이 몇 개의 군집으로 이루져 있다면 군집효과로 발생한 성질때문에 관측치의 분산이 이항분포의 분산보다 큰 경우가 생기게 된다. 이러한 경우를 overdispersion이라고 한다.\n군집 효과는 다음과 같은 이유로 발생할 수 있다.\n\n군집간 의 분포가 서로 다른 경우\n관측값이 서로 독립이 아닌 경우\n\n표본의 개수를 \\(n\\)이라고 하고 군집의 크기를 \\(k\\) 라 하면 군집의 개수는 \\(l=n/k\\) 이 된다.\n\n\\(i\\)번째 군집에서 성공의 회수 \\(z_i\\)는 이항분포 \\(B(k,p_i)\\)를 따른다고 하자.\n이 때, 성공의 확률 \\(p_i\\)를 평균이 \\(E(p_i)=p\\)이고 분산이 \\(Var(p_i)=\\tau^2 p(1-p)\\)인 확률변수라고 가정하자.\n이제 총 성공의 횟수 \\(y =z_1+\\dots+z_k\\)의 분포를 살펴보면\n\n\\[ E(y) = \\sum_i E(Z_i) = \\sum_i kp= mp \\]\n로서 평균은 보통의 경우와 같지만 분산은 다음과 같이 overidspersion이 나타난다.\n\\[\\begin{align*}\nVar(y) & = \\sum_i Var(z_i) \\\\\n  &= \\sum_i \\left [ E(Var(z_i|p_i)) + Var(E(z_i|p_i) \\right ] \\\\\n  &= \\sum_i \\left [ E kp_i(1-p_i) + Var(kp_i) \\right ] \\\\\n  & = \\sum_i \\left [ kE(p_i) - kE(p_i^2) + k^2\\tau^2 p(1-p) \\right ] \\\\\n  & = \\sum_i \\left [ kp - k\\{ \\tau^2 p(1-p) + p^2\\}  + k^2\\tau^2 p(1-p) \\right ] \\\\\n  & = \\sum_i \\left [ kp - k\\{ \\tau^2 p(1-p) + p^2\\}  + k^2\\tau^2 p(1-p) \\right ] \\\\\n   & = [1+\\tau^2(k-1)]kp(1-p)\n\\end{align*}\\]\n즉 \\(1+\\tau^2(k-1)\\)의 값이 1보다 크기 때문에 반응변수가 독립인 경우의 분산 \\(kp(1-p)\\)보다 커진다. \\(1+\\tau^2(k-1)\\) 의 값을 산포모수(dispersion parameter) 라고 부른다.\n\n\n\n\n\n\n산포모수\n\n\n\n이항변수에 대한 로지스틱회위에서 다음과 같이 분산이 이항분포의 이론적 분산 \\(kp(1-p)\\) 보다 크게 크게 나타나는 경우 그 계수를 산포모수(dispersion parameter, \\(\\sigma^2\\)) 이라고 부른다.\n\\[Var(y) = \\sigma^2 mp(1-p) &gt; kp(1-p)\\] 산포모수(\\(\\sigma^2\\))는 과산포가 없으면 1 이고 과산포가 존재하면 1 보다 큰 값을 가진다.\n\n\n산포모수는 식 식 5.11 에 주어진 \\(\\chi^2\\)-통계량에 의해 추정될 수 있다.\n\\[ \\hat \\sigma^2 = \\chi^2/(n-p) \\] 주의할 점은 overidspersion이 있다 하더라도 회귀계수의 추정치 \\(\\beta\\)의 추정에는 영향을 미치지 않는다.\n위와 같이 overidspersion이 있다고 판단되는 경우에는 추가로 산포모수(dispersion parameter) \\(\\sigma^2\\)를 고려하고 이를 추정하여 회귀계수 \\(\\beta\\)의 분산 계산 시 다음과 같이 추가해서 계산한다.\n\\[ Var(\\hat {\\pmb \\beta}) = \\hat \\sigma^2(X'\\hat W X)^{-1} \\]\n\n\n5.5.2 예제\n부교재 Faraway (2016) 의 2.11 절에 소개된 자료를 이용하여 과산포에 대한 예제를 살펴보자.\n데이터 trouegg 는 5개의 장소와 4개의 시번에서 관측한 송어(trout) 알의 생존에 대한 자료이다. 데이터를 구성하는 변수의 이름과 의미는 다음과 같다.\n\nsurvive: the number of surviving eggs\ntotal: the number of eggs in the box\nlocation : the location in the stream with levels 1 2 3 4 5\nperiod : the number of weeks after placement that the box was withdrawn levels 4 7 8 11\n\n다음은 데이터 trouegg 이다.\n\ntroutegg %&gt;% dplyr::arrange(location, period) %&gt;% dplyr::relocate(`location`, `period`, `survive`, `total`) %&gt;%\n kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\n\nlocation\nperiod\nsurvive\ntotal\n\n\n\n\n1\n1\n4\n89\n94\n\n\n6\n1\n7\n94\n98\n\n\n11\n1\n8\n77\n86\n\n\n16\n1\n11\n141\n155\n\n\n2\n2\n4\n106\n108\n\n\n7\n2\n7\n91\n106\n\n\n12\n2\n8\n87\n96\n\n\n17\n2\n11\n104\n122\n\n\n3\n3\n4\n119\n123\n\n\n8\n3\n7\n100\n130\n\n\n13\n3\n8\n88\n119\n\n\n18\n3\n11\n91\n125\n\n\n4\n4\n4\n104\n104\n\n\n9\n4\n7\n80\n97\n\n\n14\n4\n8\n67\n99\n\n\n19\n4\n11\n111\n132\n\n\n5\n5\n4\n49\n93\n\n\n10\n5\n7\n11\n113\n\n\n15\n5\n8\n18\n88\n\n\n20\n5\n11\n0\n138\n\n\n\n\n\n\n\n\nsummary(troutegg)\n\n    survive           total        location period\n Min.   :  0.00   Min.   : 86.00   1:4      4 :5  \n 1st Qu.: 74.50   1st Qu.: 96.75   2:4      7 :5  \n Median : 90.00   Median :107.00   3:4      8 :5  \n Mean   : 81.35   Mean   :111.30   4:4      11:5  \n 3rd Qu.:104.00   3rd Qu.:123.50   5:4            \n Max.   :141.00   Max.   :155.00                  \n\n\n이제 자료 troutegg 에 로지스틱 회귀식을 다음과 같이 적합해보자.\n\nbmod &lt;- glm(cbind(survive,total-survive) ~      location+period,         family=binomial,troutegg)\nsummary(bmod)\n\n\nCall:\nglm(formula = cbind(survive, total - survive) ~ location + period, \n    family = binomial, data = troutegg)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.6358     0.2813  16.479  &lt; 2e-16 ***\nlocation2    -0.4168     0.2461  -1.694   0.0903 .  \nlocation3    -1.2421     0.2194  -5.660 1.51e-08 ***\nlocation4    -0.9509     0.2288  -4.157 3.23e-05 ***\nlocation5    -4.6138     0.2502 -18.439  &lt; 2e-16 ***\nperiod7      -2.1702     0.2384  -9.103  &lt; 2e-16 ***\nperiod8      -2.3256     0.2429  -9.573  &lt; 2e-16 ***\nperiod11     -2.4500     0.2341 -10.466  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1021.469  on 19  degrees of freedom\nResidual deviance:   64.495  on 12  degrees of freedom\nAIC: 157.03\n\nNumber of Fisher Scoring iterations: 5\n\n\n앞의 예제와 같이 결과의 잔차 편차가 \\(\\chi^2\\)-분포를 기준으로 얼마나 큰지 살펴보자.\n\npchisq(deviance(bmod), df.residual(bmod),lower=FALSE)\n\n[1] 3.379416e-09\n\n\n잔차 편차가 매우 큰 것을 알 수 있으며 산포모수 \\(\\sigma^2\\) 는 식 식 5.11 에 주어진 것 처럼 다음과 같이 추정될 수 있다.\n\nsigma2 &lt;- sum(residuals(bmod,type=\"pearson\")^2) /12\nsigma2\n\n[1] 5.330322\n\n\n위에서 구한 산포 모수가 크다는 것은 다음과 같이 o-ring 자료에 대한 로지스틱 회귀의 산포 모수와 비교하면 알 수 있다.\n\nsigma2 &lt;- sum(residuals(logit1,type=\"pearson\")^2) /21\nsigma2\n\n[1] 1.336542\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth. Hoboken NJ: Wiley. http://z.umn.edu/alr4ed.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>로지스틱 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#필요한-패키지",
    "href": "notes/poisson.html#필요한-패키지",
    "title": "6  포아송 회귀모형",
    "section": "6.1 필요한 패키지",
    "text": "6.1 필요한 패키지\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(pscl)\nlibrary(here)",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#포아송-분포",
    "href": "notes/poisson.html#포아송-분포",
    "title": "6  포아송 회귀모형",
    "section": "6.2 포아송 분포",
    "text": "6.2 포아송 분포\n반응변수 \\(y\\)가 어떤 사건이 일어난 횟수(count)라면 주로 포아송분포를 확률 모형으로 사용한다.\n\\[\nP(Y=y) = f(y|\\mu)= \\frac{ e^{-\\mu} \\mu^y }{y!}, \\quad y=0,1,2,\\dots\n\\tag{6.1}\\]\n포아송 분포는 다음과 같은 중요한 특성을 가지고 있다.\n\n만약에 어떤 사건이 일어난 횟수가 몇 가지 가능한 수들 중에 하나라면 (예: \\(0 \\le y \\le M\\)) 포아송분포를 이항분포의 근사(approximation)로 생각할 수 있다. 만약 \\(n\\)이크고 성공확률 \\(p\\)가 작으면 이항분포는 평균이 \\(\\mu=np\\)인 포아송 분포와 매우 가깝기 때문에 가능한 횟수가 제한되었다 하더라도 포아송 분포를 적용할 수 있다.\n사건의 일어난 횟수가 주어진 시간의 길이에 비례하고 다른 사건과 독립이면 포아송 분포를 따른다. 또한 포아송 분포는 두 개의 사건이 일어날 때 시간 간격이 지수분포(exponential distribution)을 따른다면 주어진 시간 간격동안 일어난 사건의 횟수는 포아송 분포를 따른다.\n\\(y_i\\)가 서로 독립이고 평균이 \\(\\mu_i\\)인 포아송분포를 따른다면 합 \\(\\sum_i y_i\\)는 평균이 \\(\\sum_i \\mu_i\\)인 포아송분포를 따른다",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#포아송-회귀모형",
    "href": "notes/poisson.html#포아송-회귀모형",
    "title": "6  포아송 회귀모형",
    "section": "6.3 포아송 회귀모형",
    "text": "6.3 포아송 회귀모형\n이러한 포아송 분포에서 나온 반응변수(횟수 \\(y\\))에 대하여 설명변수 \\(x\\)의 영향에 대한 회귀분석을 포아송 회귀모형이라고 한다.\n포아송 분포의 평균 \\(\\mu\\)는 양의 실수이고 선형예측식 \\(\\eta= \\pmb x^t \\pmb \\beta\\)의 범위는 실수이기 때문에 로그함수를 연결함수(link function)으로 이용하여 회귀식을 세운다.\n\\[\n\\log E(y|\\pmb x_i) =\\log \\mu(\\pmb x_i) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n\\tag{6.2}\\]\n포아송 회귀모형에서 회귀 계수의 의미를 알아보기 위하여 다음과 같이 하나의 설명변수만 있으며 그 값이 \\(x=0\\) 과 \\(x=1\\) 인 경우에 회귀식을 보자.\n\\[\n\\log E(y| x = 1 ) = \\log \\mu( x = 1) =  \\beta_0 + \\beta_1, \\quad\n\\log E(y| x = 2) = \\log \\mu( x = 2) =  \\beta_0 + 2\\beta_1\n\\] 따라서 다음과 같은 식이 성립하므로 설명변수 \\(x\\) 가 1 단위 증가하면 반응변수의 평균은 \\(\\exp(\\beta_1)\\) 배 증가한다는 것을 알 수 있다.\n\\[\n\\frac{E(y| x = 2 )}{E(y| x = 1 )}= \\frac{\\mu( x = 2)} {\\mu( x = 1)} = \\frac{\\exp(\\beta_0 + 2\\beta_1)}{\\exp(\\beta_0 + \\beta_1) } = \\exp(\\beta_1)\n\\]\n사실 포아송 분포의 로그가능도함수에서 로그함수가 자연 연결함수임을 쉽게 알 수 있다. 즉, \\(\\pmb y=(y_1,y_2,\\dots,y_n)^t\\)를 서로 독립이고 평균이 \\(\\mu_i = \\mu(\\pmb x_i)\\)인 포아송 확률변수라고 한다면 로그가능도함수는 다음과 같다.\n\\[\n\\begin{aligned}\nl &= \\log \\prod_{i=1}^n  f(y_i|\\mu_i)   \\\\\n   &= \\sum_{i=1}^n [y_i \\log \\mu_i - \\mu_i - \\log y_i!]\n\\end{aligned}\n\\tag{6.3}\\]\n위에서 볼수 있듯이 충분통계량 \\(y_i\\)에 대응하는 모수에 대한 항은 \\(\\log \\mu_i\\) 로서 이는 로그함수가 자연연결함수임을 나타낸다.\n회귀계수 \\(\\pmb \\beta\\)의 추정은 로지스틱 회귀와 같이 최대가능도추정법(maximum likelihood estimation)으로 구한다. 포아송 회귀에서도 최대가능도추정량은 직접 계산으로 구할 수 없기 때문에 수치적인 방법을 이용하여 구한다.\n또한 회귀계수에 대한 검정 \\(H_0: \\beta_i=0\\)은 대표본이론에 의거한 정규근사를 이용한다. 즉 유의수준 \\(\\alpha\\)에서 t-통계량 \\(t=\\hat \\beta_i/se(\\hat \\beta_i)\\)의 절대값 \\(|t|\\)가 \\(z_\\alpha\\)보다 크면 귀무가설을 기각한다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#편차",
    "href": "notes/poisson.html#편차",
    "title": "6  포아송 회귀모형",
    "section": "6.4 편차",
    "text": "6.4 편차\n포아송 회귀분석에서 편차(deviance) \\(D\\)를 구해보기 위하여 포화모형을 생각해보자.\n각 관측값의 평균 \\(\\mu_i\\)를 자신의 관측값 \\(y_i\\)로 추정하는 것이 포화모형이다. 따라서 포화모형의 로그가능도함수는 다음과 같이 주어지고\n\\[\nl_{saturated} = \\sum_{i=1}^n [y_i \\log y_i - y_i - \\log y_i!]  \n\\] 식 6.3 으로 주어진 포아송 회귀분석의 로그가능도함수를 빼주면 \\(D\\)를 얻을 수 있다.\n\\[\n\\begin{aligned}\nD & = 2 [ l_{saturated}(\\hat {\\pmb \\mu} | y)-l_{regession}(\\hat {\\pmb \\mu} | y) ] \\\\\n  & = 2 \\sum_{i=1}^n [y_i \\log y_i - y_i - \\log y_i!]  \n  - \\sum_{i=1}^n [y_i \\log {\\hat \\mu}_i - {\\hat \\mu}_i - \\log y_i!]   \\\\\n  &= 2 \\sum_{i=1}^n [ y_i \\log (y_i / {\\hat \\mu}_i) - (y_i - {\\hat \\mu}_i) ]\n\\end{aligned}\n\\]\n또한 모형의 적합성을 측정하는 양으로서 \\(\\chi^2\\)-통계량을 사용할 수 있다.\n\\[\n\\chi^2 = \\sum_{i=1}^n \\frac{(y_i - \\hat \\mu_i)^2}{\\hat \\mu_i}\n\\]\n로지스틱 회귀에서와 비슷하게 포아송 회귀분석에서도 과포화(overdispersion)가 나타날 수 있다. 즉, 포아송 모형의 가정은 평균과 분산이 같은 것인데 (\\(\\mu_i=E(y_i)=Var(y_i)\\)) 이러한 가정은 실제 자료 분석에서 많은 경우에 만족하지 않을 수 있으며 과포화가 나타난다\n\\[\nE(y_i)= \\mu_i, \\quad \\text{ but} \\quad Var(y_i) &gt; \\mu_i\n\\]\n이렇게 과포화가 나타나는 경우에는 산포모수(dispersion parameter) \\(\\phi\\)를 추정하여 회귀계수의 표준오차 계산에 반영해주어야 한다. 산포모수는 \\(\\chi^2\\)통계량을 통하여 추정할 수 있다.\n\\[ \\hat \\phi = \\frac { \\chi^2}{n-p} \\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#발생율-모형",
    "href": "notes/poisson.html#발생율-모형",
    "title": "6  포아송 회귀모형",
    "section": "6.5 발생율 모형",
    "text": "6.5 발생율 모형\n어떤 사건이 일어날 횟수는 집단이나 시간의 크기(size)에 의존할 수 있다. 예를 들어 각 도시의 1년 범죄 발생 횟수는 그 도시의 인구수나 크기에 비례하게 된다.\n이러한 모형은 이항분포를 이용하여 분석할 수 도 있지만 사건의 발생확률이 매우 작고 집단의 크기가 크면 포아송 근사를 통한 분석도 가능하다. 또한 어떤 경우에는 집단의 크기에 대한 정보가 부족할 수 있다.\n이러한 비율에 대한 회귀모형을 발생율 모형(rate models) 로 부르며 식으로 나타내면 아래와 같고\n\\[\n\\log \\frac {\\text{ 발생횟수} } { \\text{집단의 크기} } = \\pmb x^t \\pmb \\beta \\]\n이는 다시 발생횟수에 대한 포아송 회귀모형의 형태로 나타내면 다음과 같이 쓸 수 있다.\n\\[\n\\log \\text{ 발생횟수} =  (1)(\\log \\text{집단의 크기}) +  \\pmb x^t \\pmb \\beta\n\\]\n따라서 발생횟수에 대한 포아송 회귀분석을 적합할 때 집단의 크기를 안다면 그 \\(\\log\\) 변환값을 회귀식에 포함하여 적합할 수 있다. 위의 식에서 알 수 있듯이 크기의 \\(\\log\\) 변환변수는 회귀계수를 강제로 1로 놓는 제약을 둘 수 있다. 이러한 변수를 오프셋 변수(offset variable)이라고 한다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#음이항-분포",
    "href": "notes/poisson.html#음이항-분포",
    "title": "6  포아송 회귀모형",
    "section": "6.6 음이항 분포",
    "text": "6.6 음이항 분포\n베르누이 독립시행에서 \\(k\\)번째의 성공까지의 시행회수 \\(z\\)는 음이항 분포(negative bionomial)을 따른다. 음이항분포는 포아송 분포에서 모수가 감마를 따를 때 근사분포로 사용될 수 있다.\n\\[\nP(z) = {{z-1}\\choose {k-1}} p^k (1-p)^{z-k},\\quad z=k,k+1,\\dots\n\\tag{6.4}\\]\n위의 분포에서 확률 변수와 모수를 다시 아래와 같이 정의하면\n\\[\ny=z-k, \\quad p= \\frac{1}{1+\\alpha}\n\\]\n\\(y\\)의 확률분포는 다음과 같고\n\\[\nP(y) = {{y+k-1}\\choose {k-1}} \\frac{\\alpha^y}{(1+\\alpha)^{y+k}},\\quad y=0,1,2,\\dots\n\\]\n따라서 \\(y\\)의 평균과 분산은 다음과 같이 주어진다.\n\\[\nE(y) = \\mu =k\\alpha, \\quad Var(y) = k\\alpha + k\\alpha^2= \\mu + \\mu^2/k\n\\]\n또한 로그가능도함수는 다음과 같이 주어지고\n\\[\nl= \\sum_{i=1}^n \\left ( y_i \\log \\frac{\\alpha}{1+\\alpha} -k \\log (1+\\alpha) + \\sum_{j=0}^{y_i-1} \\log (j+k) -\\log y_i! \\right )\n\\]\n연결함수는 다음과 같다.\n\\[\n\\log \\frac{\\alpha}{1+\\alpha} = \\log \\frac{\\mu}{\\mu+k} = \\eta=\\pmb x^t \\pmb \\beta\n\\] 보통의 경우 \\(k\\)는 고정된 상수로 생각할 수도 있고 또는 모수로 보고 추정할 수 도 있다.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#영과잉모형",
    "href": "notes/poisson.html#영과잉모형",
    "title": "6  포아송 회귀모형",
    "section": "6.7 영과잉모형",
    "text": "6.7 영과잉모형\n어떤 사건의 발생횟수에 대한 자료를 수집할 떄 0이 비정상적으로 많이 나타나는 경우가 있다.\n만약 발생횟수의 분포를 포아송분포(식 6.1)로 가정하면 0이 관측될 확률은 크지 않다.\n\\[\nP(y=0) =  e^{-\\mu}\n\\]\n자료에서 0의 발생 빈도가 비정상적으로 많은 자료를 영과잉자료(zero inflated data)라고 하며 이러한 자료에 포아송 분포를 그대로 적용하면 회귀 계수의 추정량에 편이(bias)가 발생할 수 있으며 과포화(overdispersion)가 발생하는 등 여러 가지 문제가 생긴다.\n발생횟수에 0이 많은 이유는 매우 다양하다. 0이 많이 발생하는 대표적인 이유를 살펴보자.\n\n외부 요인에 의하여 사건의 발생이 제약을 받는 경우\n발생은 했는데 관측이 안된 경우\n원래 0이 많은 경우\n\n이렇게 0 과잉 자료를 분석할 수 있는 대표적인 모형은 영과잉 포아송 모형(zero inflated poission model; ZIP)이다\n확률변수 \\(y_i\\)를 사건의 발생 회수라고 하면 ZIP 모형에서 0이 관측될 확률을 다음과 같이 나타낼 수 있다.\n\\[\nP(y=0) = P(\\text{ False zeros }) + [1-P(\\text{ False zeros })] P(\\text{ count process gives a zero })\n\\]\n즉 0이 관측될 확률은 잘못된 0이 관찰 될 확률과 원래 확률 과정에서 0이 관찰 될 확률의 조합(mixture)으로 나타난다. 이제 \\(i\\)번째 관측에서 잘못된 0이 관찰 될 확률을 \\(\\pi_i\\)라 하면\n\\[\nP(y_i=0) = \\pi_i + (1-\\pi_i) P(\\text{ count process gives a zero })\n\\]\n더 나아가 확률 과정이 평균이 \\(\\mu_i\\)인 포아송 분포를 따른다고 가정하고\n\\[\n\\begin{aligned}\nP(y_i=0) &  = \\pi_i + (1-\\pi_i) P(y_i=0 | \\mu_i) =  \\pi _i+ (1-\\pi_i) e^{-\\mu_i} \\\\\nP(y_i=k) &  =  P(y_i=k | \\mu_i)  =  (1-\\pi_i)\\frac{ e^{-\\mu_i} \\mu_i^{y_k} }{y_k!}, \\quad k=1,2,\\cdots\n\\end{aligned}\n\\]\n위의 분포에서 \\(y\\)의 평균과 분산을 구해보면 다음과 같이 주어진다.\n\\[\n\\begin{aligned}\nE(y_i) &  =   (1-\\pi_i)\\mu_i  \\\\\nVar(y_i) &  =   (1-\\pi_i)\\mu_i + (1-\\pi_i)\\pi_i \\mu_i^2\n\\end{aligned}\n\\]\n위의 식에서 볼 수 있듯이 영과잉 포아송 모형은 과포화들 보인다\n\\[ Var(y_i) &gt; E(y_i) \\]\n영과잉 포아송 모형에 대한 회귀분석은 다음 두 모형을 동시에 고려하는 모형이다.\n\n잘못된 0이 관측될 확률 \\(\\pi_i\\)에 대한 로지스틱 회귀모형\n발생회수에 대한 포아송 회귀모형\n\n\\[\n\\begin{aligned}\n\\log \\frac{\\pi_i} {1-\\pi_i}  &  = {\\pmb x}_b^t {\\pmb \\beta}_b  \\\\\n\\log \\mu_i &  =  {\\pmb x}_p^t {\\pmb \\beta}_p  \n\\end{aligned}\n\\]",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/poisson.html#예제",
    "href": "notes/poisson.html#예제",
    "title": "6  포아송 회귀모형",
    "section": "6.8 예제",
    "text": "6.8 예제\n\n6.8.1 Galapagos 군도의 거북이\nGalapagos 군도에 있는 30개의 섬에서 사는 거북이의 개체 수 Species 를 반응변수 \\(y\\)로하고 5개의 지리적 변수를 예측변수로 하는 Poisson 회귀식을 적합하려고 한다. 이 예제는 교재 Faraway (2016) 57페이지에 있는 예제이다.\n데이터 gala 를 구성하는 변수들은 다음과 같다.\n\nSpecies: the number of plant species found on the island\nEndemics : the number of endemic species (아래 분석에서 제외)\nArea : the area of the island (km\\(^2\\))\nElevation : the highest elevation of the island (m)\nNearest : the distance from the nearest island (km)\nScruz : the distance from Santa Cruz island (km)\nAdjacent : the area of the adjacent island (square km)\n\n\ngala_2 &lt;- gala[,-2]\nhead(gala_2)  %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\n\nSpecies\nArea\nElevation\nNearest\nScruz\nAdjacent\n\n\n\n\nBaltra\n58\n25.09\n346\n0.6\n0.6\n1.84\n\n\nBartolome\n31\n1.24\n109\n0.6\n26.3\n572.33\n\n\nCaldwell\n3\n0.21\n114\n2.8\n58.7\n0.78\n\n\nChampion\n25\n0.10\n46\n1.9\n47.4\n0.18\n\n\nCoamano\n2\n0.05\n77\n1.9\n1.9\n903.82\n\n\nDaphne.Major\n18\n0.34\n119\n8.0\n8.0\n1.84\n\n\n\n\n\n\n\n데이터를 일반적인 선형모형과 반응변수에 제곱근 변환을 적용한 결과는 다음과 같다.\n\nmodl &lt;- lm(Species ~ . , gala_2)\nplot(modl, 1)\n\n\n\n\n\n\n\nsummary(modl)\n\n\nCall:\nlm(formula = Species ~ ., data = gala_2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-111.679  -34.898   -7.862   33.460  182.584 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.068221  19.154198   0.369 0.715351    \nArea        -0.023938   0.022422  -1.068 0.296318    \nElevation    0.319465   0.053663   5.953 3.82e-06 ***\nNearest      0.009144   1.054136   0.009 0.993151    \nScruz       -0.240524   0.215402  -1.117 0.275208    \nAdjacent    -0.074805   0.017700  -4.226 0.000297 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 60.98 on 24 degrees of freedom\nMultiple R-squared:  0.7658,    Adjusted R-squared:  0.7171 \nF-statistic:  15.7 on 5 and 24 DF,  p-value: 6.838e-07\n\n\n\nmodt &lt;- lm(sqrt(Species) ~ . , gala)\nplot(modt, 1)\n\n\n\n\n\n\n\nsummary(modt)\n\n\nCall:\nlm(formula = sqrt(Species) ~ ., data = gala)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.77512 -0.67895 -0.07101  0.62771  2.50402 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.3705693  0.4253328   5.573 1.14e-05 ***\nEndemics     0.2002788  0.0217192   9.221 3.45e-09 ***\nArea        -0.0002763  0.0005147  -0.537    0.597    \nElevation   -0.0002509  0.0021483  -0.117    0.908    \nNearest      0.0198908  0.0226069   0.880    0.388    \nScruz       -0.0021423  0.0047791  -0.448    0.658    \nAdjacent     0.0001255  0.0005361   0.234    0.817    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.307 on 23 degrees of freedom\nMultiple R-squared:  0.9537,    Adjusted R-squared:  0.9417 \nF-statistic: 79.03 on 6 and 23 DF,  p-value: 3.457e-14\n\n\n포아송 회귀모형을 적합한 결과는 다음과 같다.\n\nmodp &lt;- glm(Species ~ .,family=poisson, gala_2)\nsummary(modp)\n\n\nCall:\nglm(formula = Species ~ ., family = poisson, data = gala_2)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.155e+00  5.175e-02  60.963  &lt; 2e-16 ***\nArea        -5.799e-04  2.627e-05 -22.074  &lt; 2e-16 ***\nElevation    3.541e-03  8.741e-05  40.507  &lt; 2e-16 ***\nNearest      8.826e-03  1.821e-03   4.846 1.26e-06 ***\nScruz       -5.709e-03  6.256e-04  -9.126  &lt; 2e-16 ***\nAdjacent    -6.630e-04  2.933e-05 -22.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3510.73  on 29  degrees of freedom\nResidual deviance:  716.85  on 24  degrees of freedom\nAIC: 889.68\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n6.8.2 세포의 비정상성\n세포(cells)에 감마 방사능을 쏘였을 떄 비정상성(ca)를 나타내는 횟수에 대하여 발생율 모형을 적합시켰다. 예측변수는 방사능의 양(doseamt)와 비율(doserate)이다. 여기서 세포의 수(cells)를 오프셋 변수(offset variable)로 사용한다. 이 예제는 교재 Faraway (2016) 61페이지에 있는 예제이다.\n\ncells : Number of cells in hundreds\nca : Number of chromosomal abnormalities\ndoseamt : amount of dose in Grays\ndoserate : rate of dose in Grays/hour\n\n\nhead(dicentric) %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\ncells\nca\ndoseamt\ndoserate\n\n\n\n\n478\n25\n1\n0.10\n\n\n1907\n102\n1\n0.25\n\n\n2258\n149\n1\n0.50\n\n\n2329\n160\n1\n1.00\n\n\n1238\n75\n1\n1.50\n\n\n1491\n100\n1\n2.00\n\n\n\n\n\n\n\n다음 표는 방사능의 양(doseamt)와 비율(doserate)의 조합에 따라 비정상 세포의 비율을 나타낸다.\n\nround(xtabs(ca/cells ~ doseamt+doserate, dicentric),2)\n\n       doserate\ndoseamt  0.1 0.25  0.5    1  1.5    2  2.5    3    4\n    1   0.05 0.05 0.07 0.07 0.06 0.07 0.07 0.07 0.07\n    2.5 0.16 0.28 0.29 0.32 0.38 0.41 0.41 0.37 0.44\n    5   0.48 0.82 0.90 0.88 1.23 1.32 1.34 1.24 1.43\n\n\n\nwith(dicentric,interaction.plot(doseamt, doserate, ca/cells, legend= FALSE))\n\n\n\n\n\n\n\n\n먼저 일반적인 선형모형을 적용하고 잔차분석을 수행하자.\n\nlmod &lt;- lm(ca/cells ~ log(doserate)*factor(doseamt), dicentric)\nsummary(lmod)\n\n\nCall:\nlm(formula = ca/cells ~ log(doserate) * factor(doseamt), data = dicentric)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.184275 -0.004212  0.001314  0.021208  0.089076 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      0.063489   0.019528   3.251  0.00382 ** \nlog(doserate)                    0.004573   0.016692   0.274  0.78680    \nfactor(doseamt)2.5               0.276315   0.027616  10.005 1.92e-09 ***\nfactor(doseamt)5                 1.004119   0.027616  36.359  &lt; 2e-16 ***\nlog(doserate):factor(doseamt)2.5 0.063933   0.023606   2.708  0.01317 *  \nlog(doserate):factor(doseamt)5   0.239129   0.023606  10.130 1.54e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05858 on 21 degrees of freedom\nMultiple R-squared:  0.9874,    Adjusted R-squared:  0.9844 \nF-statistic:   330 on 5 and 21 DF,  p-value: &lt; 2.2e-16\n\nplot(residuals(lmod) ~ fitted(lmod),xlab=\"Fitted\",ylab=\"Residuals\")\nabline(h=0)\n\n\n\n\n\n\n\n\n위의 잔차분석에서는 등분산성이 의심되는 결과가 나타난다.\n이제 doseamt 를 범주형 자료로 만들고 세포의 갯수(cells) 를 다음과 같이 log 변환하여 독립변수에 포함시키자. 이제 반응변수는 비정상 세포의 비율이 아니라 비정상 세포의 갯수이다.\n\ndicentric_1 &lt;- dicentric\ndicentric_1$dosef &lt;- factor(dicentric_1$doseamt)\npmod &lt;- glm(ca ~ log(cells)+log(doserate)*dosef,  family=poisson, dicentric_1)\nsummary(pmod)\n\n\nCall:\nglm(formula = ca ~ log(cells) + log(doserate) * dosef, family = poisson, \n    data = dicentric_1)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.76534    0.38116  -7.255 4.02e-13 ***\nlog(cells)              1.00252    0.05137  19.517  &lt; 2e-16 ***\nlog(doserate)           0.07200    0.03547   2.030 0.042403 *  \ndosef2.5                1.62984    0.10273  15.866  &lt; 2e-16 ***\ndosef5                  2.76673    0.12287  22.517  &lt; 2e-16 ***\nlog(doserate):dosef2.5  0.16111    0.04837   3.331 0.000866 ***\nlog(doserate):dosef5    0.19316    0.04299   4.493 7.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 916.127  on 26  degrees of freedom\nResidual deviance:  21.748  on 20  degrees of freedom\nAIC: 211.15\n\nNumber of Fisher Scoring iterations: 4\n\n\n이제 다음과 같은 관계에 따라서 세포의 갯수(cells)를 오프셋 변수로 다시 적합시켜보자.\n\\[\n\\log (\\text{ca}/ \\text{cell}) = {\\pmb x}^t {\\pmb \\beta}\n\\Leftarrow\n\\log (\\text{ca} ) = \\log(\\text{cell}) + {\\pmb x}^t {\\pmb \\beta}\n\\]\n\nrmod &lt;- glm(ca ~ offset(log(cells))+log(doserate)*dosef,  family= poisson, dicentric_1) \nsummary(rmod)\n\n\nCall:\nglm(formula = ca ~ offset(log(cells)) + log(doserate) * dosef, \n    family = poisson, data = dicentric_1)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -2.74671    0.03426 -80.165  &lt; 2e-16 ***\nlog(doserate)           0.07178    0.03518   2.041 0.041299 *  \ndosef2.5                1.62542    0.04946  32.863  &lt; 2e-16 ***\ndosef5                  2.76109    0.04349  63.491  &lt; 2e-16 ***\nlog(doserate):dosef2.5  0.16122    0.04830   3.338 0.000844 ***\nlog(doserate):dosef5    0.19350    0.04243   4.561  5.1e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4753.00  on 26  degrees of freedom\nResidual deviance:   21.75  on 21  degrees of freedom\nAIC: 209.16\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n6.8.3 국립공원 방문자\n국립공원에서 일하는 야생동물 연구원은 공원방문자들이 얼마나 많은 수의 고기(fish)를 잡는지 알고 싶어한다.공원방문자는 공원을 떠날 때 다음과 같은 설문들에 대하여 답하였다. 총 250명의 방문자(group)가 설문에 응답하였다. 이 예제는 교재 Faraway (2016) 94페이지에 있는 예제이다.\n\n며칠동안 공원에 머물렀는가?\n같이 공원에 온 사람들은 총 몇 명인가? (persons)\n같이 공원에 온 사람들 중에 어린이는 몇 명인가? (child)\n공원 방문중에 낚시를 하였는가?\n낚시를 하였다면 고기를 몇 마리 잡았는가? (count)\n공원을 방문할 떄 캠핑카를 가지고 왔는가? (camper)\n\n공원에 방문한 사람들 중에 낚시를 하지 않은 사람들이 많기 때문에 많은 수의 그룹이 잡은 고기의 수가 0이다.\n위의 자료를 영과잉모형으로 분석하기 위하여 다음과 같이 자료를 부르고 히스토그램을 그려보자.\n\nzinb&lt;-read.csv(here::here(\"data/fish.csv\"))\nhead(zinb)  %&gt;%\n  kbl() %&gt;%\n  kable_styling( full_width = F)\n\n\n\n\nnofish\nlivebait\ncamper\npersons\nchild\nxb\nzg\ncount\n\n\n\n\n1\n0\n0\n1\n0\n-0.8963146\n3.0504048\n0\n\n\n0\n1\n1\n1\n0\n-0.5583450\n1.7461489\n0\n\n\n0\n1\n0\n1\n0\n-0.4017310\n0.2799389\n0\n\n\n0\n1\n1\n2\n1\n-0.9562981\n-0.6015257\n0\n\n\n0\n1\n0\n1\n0\n0.4368910\n0.5277091\n1\n\n\n0\n1\n1\n4\n2\n1.3944855\n-0.7075348\n0\n\n\n\n\n\n\n\n\nzinb_1 &lt;- within(zinb, {\n    nofish &lt;- factor(nofish)\n    livebait &lt;- factor(livebait)\n    camper &lt;- factor(camper)\n})\n\nsummary(zinb_1)\n\n nofish  livebait camper     persons          child             xb           \n 0:176   0: 34    0:103   Min.   :1.000   Min.   :0.000   Min.   :-3.275050  \n 1: 74   1:216    1:147   1st Qu.:2.000   1st Qu.:0.000   1st Qu.: 0.008267  \n                          Median :2.000   Median :0.000   Median : 0.954550  \n                          Mean   :2.528   Mean   :0.684   Mean   : 0.973796  \n                          3rd Qu.:4.000   3rd Qu.:1.000   3rd Qu.: 1.963855  \n                          Max.   :4.000   Max.   :3.000   Max.   : 5.352674  \n       zg              count        \n Min.   :-5.6259   Min.   :  0.000  \n 1st Qu.:-1.2527   1st Qu.:  0.000  \n Median : 0.6051   Median :  0.000  \n Mean   : 0.2523   Mean   :  3.296  \n 3rd Qu.: 1.9932   3rd Qu.:  2.000  \n Max.   : 4.2632   Max.   :149.000  \n\n\n\nggplot(zinb_1, aes(count)) + geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(zinb, aes(count)) + geom_histogram() + scale_x_log10() +ggtitle(\"x-axis is log scale\")\n\nWarning: Transformation introduced infinite values in continuous x-axis\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 142 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n다음은 영과잉 포아송모형을 적합한 결과이다. 0에 대한 로지스틱 회귀에서 사용하는 독립변수는 persons이다.\n\nzip1 &lt;- pscl::zeroinfl(count ~ child + camper | persons, data = zinb_1)\nsummary(zip1)\n\n\nCall:\npscl::zeroinfl(formula = count ~ child + camper | persons, data = zinb_1)\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.2369 -0.7540 -0.6080 -0.1921 24.0847 \n\nCount model coefficients (poisson with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.59789    0.08554  18.680   &lt;2e-16 ***\nchild       -1.04284    0.09999 -10.430   &lt;2e-16 ***\ncamper1      0.83402    0.09363   8.908   &lt;2e-16 ***\n\nZero-inflation model coefficients (binomial with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.2974     0.3739   3.470 0.000520 ***\npersons      -0.5643     0.1630  -3.463 0.000534 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 10 \nLog-likelihood: -1032 on 5 Df\n\n\n다음은 일반적인 포아송모형을 적합한 결과이다.\n\npois1 &lt;- glm(count ~ child + camper, family = poisson, data = zinb_1)\nsummary(pois1)\n\n\nCall:\nglm(formula = count ~ child + camper, family = poisson, data = zinb_1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.91026    0.08119   11.21   &lt;2e-16 ***\nchild       -1.23476    0.08029  -15.38   &lt;2e-16 ***\ncamper1      1.05267    0.08871   11.87   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2958.4  on 249  degrees of freedom\nResidual deviance: 2380.1  on 247  degrees of freedom\nAIC: 2723.2\n\nNumber of Fisher Scoring iterations: 6\n\n\n영과잉 모형과 일반적인 포아송 모형의 적합도를 비교하는 가설검정은 Vuong test 를 이용하여 다음과 같이 수행할 수 있다. 아래에서 p-값이 매우 작은 것은 영과잉 모형이 더 적절함을 나타낸다.\n\npscl::vuong(pois1, zip1)\n\nVuong Non-Nested Hypothesis Test-Statistic: \n(test-statistic is asymptotically distributed N(0,1) under the\n null that the models are indistinguishible)\n-------------------------------------------------------------\n              Vuong z-statistic             H_A    p-value\nRaw                   -3.574259 model2 &gt; model1 0.00017561\nAIC-corrected         -3.552397 model2 &gt; model1 0.00019087\nBIC-corrected         -3.513904 model2 &gt; model1 0.00022079\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "일반화 선형모형",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>포아송 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#필요한-패키지와-함수",
    "href": "notes/random_effect.html#필요한-패키지와-함수",
    "title": "7  반복측정자료",
    "section": "7.1 필요한 패키지와 함수",
    "text": "7.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(brms)\n# ggplot2 에서 한글의 사용\nlibrary(showtext)\nfont_add_google(\"Nanum Pen Script\", \"nanum\")\nshowtext_auto()",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#repeatmeasure-paired",
    "href": "notes/random_effect.html#repeatmeasure-paired",
    "title": "7  반복측정자료",
    "section": "7.2 독립표본과 대응표본",
    "text": "7.2 독립표본과 대응표본\n서로 다른 두 처리의 효과(treatment effect)를 비교하기 위하여 주로 사용되는 방법은 두 개의 독립표본(independent sample)을 비교하는 t-검정법이다. 서로 독립인 두개의 집단(구성원이 겹치지 않는 집단)에 서로 다른 처리를 적용한 뒤에 관측된 자료의 표본 평균을 비교하여 두 개의 처리 효과의 차이를 통계적으로 검정하는 방법이다. t-검정을 위한 분포 가정은 다음과 같다.\n\\[\nx_1,x_2, \\dots x_{n} \\sim_{iid} N(\\mu_1, \\sigma^2)\n\\quad\ny_1,y_2, \\dots y_{n} \\sim_{iid} N(\\mu_2, \\sigma^2)\n\\]\n위의 가정을 다음과 같은 평균모형(mean model)로 표현할 수 있다.\n\\[\nx_i = \\mu_1 + e_{i1}, \\quad y_i = \\mu_2 + e_{i2}  \n\\tag{7.1}\\]\n여기서 \\(e_{i1}\\)와 \\(e_{i2}\\)들은 모두 독립이며 \\(N(0,\\sigma^2)\\)을 따르는 오차들이다.\n여기서 확률변수 \\(x\\)와 \\(y\\)는 서로 독립이고 각 관측값 \\(x_1,x_2, \\dots x_{n_1}\\)과 \\(y_1,y_2, \\dots y_{n_2}\\)들도 각각 모두 독립이다. 분포가정에서 다른 것은 확률변수 \\(x\\)와 \\(y\\)의 평균이 다르다.\n이러한 가정 하에서 다음의 두개의 가설검정을 할 수 있는 방법이 t-검정법이며\n\\[\nH_0 : \\mu_1 = \\mu_2 \\quad \\text{vesus} \\quad H_1 : \\mu_1 \\ne \\mu_2  \n\\tag{7.2}\\]\n검정통계량은 다음과 같이 주어진다.\n\\[\nt = \\frac{ \\bar x -\\bar y} {s_p \\sqrt{\\tfrac{1}{n} + \\tfrac{1}{n}}}  \n\\tag{7.3}\\]\n여기서 \\(\\bar x\\)와 \\(\\bar y\\)는 각 집단의 표본 평균이고 \\(s_p^2\\)은 합동분산추정량(pooled variance estimator)이다.\n\\[\ns^2_p = \\frac{\\sum_{i=1}^n (x_i -\\bar x)^2 + \\sum_{i=1}^n (y_i -\\bar y)^2 }{2n-2}\n\\]\n이제 두 개의 처리를 비교하는 경우, 독립 표본이 아닌 경우를 고려해 보자.\n독립 표본이 아닌 대표적인 경우가 대응표본(또는 쌍표본)에 대한 t-검정이다(paired t-test). 대응표본 검정에서는 하나의 개체에 두 개의 처리를 모두 적용하여 각 처리에 대한 반응값을 쌍 \\((x_i,y_i)\\)으로 얻는다.\n예를 들어 최초로 허가 받은 약품과 복제약의 생물학적동등성(bioequivalence)을 입증하는 실험에서는 한 사람에게 최초허가약을 투여하여 약의 효과를 보고 일정 시간이 지난 뒤 복제약을 같은 사람에게 투여하여 그 효과를 측정한다. 다른 예로서 두 개의 눈병 치료제를 각각 누에 투여하여 효과를 비교하는 경우도 이러한 대응표본에 속한다. 넓은 의미에서 일란성 쌍둥이에게 각각 다른 처리를 하여 비교하는 것도 대응비교라고 할 수 있다.\n\n\n생물학적동등성 실험에서 사용되는 교차실험(crossover design) - 개체 당 2개의 관측치 (각 처리에 대하여 한 개의 관측값)\n\n\n\n가장 단순한 대응비교로서 각 개체애 대하여 두 개의 처리에 대한 대응표본 \\((x_i,y_i)\\)를 관측한다고 가정하자.\n이에 대한 분포 모형은 다음과 같다.\n\\[\nd_i = x_i -y_i  \\sim_{iid} N(\\delta,\\sigma^2) \\text { where } \\delta = \\mu_1-\\mu_2 = E(x)-E(y)\n\\]\n대응비교에서 사용되는 t-통계량은 다음과 같다.\n\\[\nt = \\frac{ \\bar d} {s_d / \\sqrt{n}} =\\frac{ \\bar x -\\bar y} {s_d / \\sqrt{n}}\n\\tag{7.4}\\]\n여기서 \\(s^2_d\\)는 \\(d_1,d_2,\\dots ,d_n\\)의 표본분산이다.\n\\[\ns^2_d = \\frac{\\sum_{i=1}^n (d_i -\\bar d)^2}{n-1}\n\\]\n위에서 알아본 독립표본에 의한 비교와 대응표본에 의한 비교가 다른 점은 무었일까 생각해 보자.\n표본의 비교가 다른 개체에서 추출된 독립인 관측치를 이용하는지 또는 같은 개체에서 추출된 대응하는(독립이 아닌) 관측치를 이용하는지에 따라서 서로 다른 t-통계량을 사용한다. 식 7.3 과 식 7.4 에 나타난 t-통계량을 비교하면 분자에 나타난 통계량은 효과의 차이를 나타내는 두 개의 평균의 차이로서 기본적으로 동일하다\\((\\bar d =\\bar x -\\bar y)\\). 하지만 분모에서는 분자에 나타난 통계량의 표본오차(standard error)를 나타내는 양으로서 서로 다르다.\n독립표본에서는 표본의 평균이 서로 독립이므로 다음과 같이 평균의 차이에 대한 분산이 각각의 분산의 합과 같으므로 이에 대한 추정량으로서 합동분산추정량을 이용하였다.\n\\[\nVar(\\bar x - \\bar y) = Var(\\bar x) + Var(\\bar y)   \n\\tag{7.5}\\]\n대응표본에서는 위의 식 7.5 을 적용할 수 없다. 왜냐하면 두개의 표본 평균이 서로 독립이 아닐 가능성이 매우 높기 때문이다. 같은 개체에서 나온 관측치는 어떠한 형태로든 서로 관계가 있을 가능성이 높기 때문에 독립을 함부로 가정할 수 없다. 예를 들어 생물학적동등성 실험에서는 약 효과의 차이보다 약이 몸에 흡수되는 개인적인 체질이 관측값에 더 큰 영향을 줄 수 있다.",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#임의효과",
    "href": "notes/random_effect.html#임의효과",
    "title": "7  반복측정자료",
    "section": "7.3 임의효과",
    "text": "7.3 임의효과\n확률변수 \\(x\\)와 \\(y\\)가 독립이 아닌 경우 두 모형균의 차이를 비교하기 위하여 비교에 사용된 통계양은 두 확률변수의 차이다.\n\\[\nd_i = x_i - y_i\n\\]\n여기서 두 개의 확률변수의 차이를 이용할 때 암시적인 가정은 두 개의 확률변수의 차이를 내면 두 변수에 공통적으로 포함된 개인의 특성이 서로 상쇄되어 처리의 차이만이 확률변수 \\(d_i\\)에 존재한다는 것이다. 지금 설명한 대응비교 모형의 합리적인 가정을 요약하면 다음과 같다.\n\n개인의 특성을 반영하는 공통 요인이 두 변수에 모두 영향을 미친다.\n따라서 두 관측값 \\((x_i,y_i)\\)가 독립이 아니다\n두 관측값의 차이를 내면 공통요인이 서로 상쇄되어 처리효과만 남는다.\n\n\\[\nE(d_i) = \\mu_1 - \\mu_2\n\\]\n위의 가정을 구현할 수 있는 대응비교 모형을 다음과 같은 가법모형(additive models)로 표현할 수 있다.\n\\[  \nx_i = \\mu_1 + a_i + e_{i1}, \\quad y_i = \\mu_2 + a_i + e_{i2}\n\\tag{7.6}\\]\n여기서 \\(a_i\\)는 두 확률변수 \\((x_i,y_i)\\)에 공통으로 포함된 개인적인 특성을 나타내는 요인이며 위의 식 7.6 는 식 7.1 에 공통요인 \\(a_i\\)가 추가된 형태이다.\n두 확률변수 \\((x_i,y_i)\\)가 종속이기 위해서는 다음과 같은 가정을 이용할 수 있다.\n\\[\na_i \\sim N(0, \\sigma^2_a), \\quad  e_{i1} \\sim_{iid}  N(0, \\sigma^2_e)  \\quad e_{i2} \\sim_{iid}  N(0, \\sigma^2_e)\n\\] 여기서 \\(a_i\\)가 평균이 0이고 분산이 \\(\\sigma_a^2\\) 인 확률변수이다. 이러한 요인을 임의효과(random effect) 라고 하며 모수(parameter)인 평균 \\(\\mu_i\\)은 고정효과(fixed effect)라고 부른다. \\(e_{i1}\\)와 \\(e_{i2}\\)들은 모두 독립이며 평균이 \\(0\\) 이고 분산이 \\(\\sigma^2_e\\)인 정규분포를 따르는 오차들이다. 또한 \\(a_i\\)와 (\\(e_{i1}\\),\\(e_{i2}\\))도 독립이다.\n위와 같은 가정에서 두 변수의 차이를 내면 공통요인인 \\(a_i\\)가 제거되어 두 처리의 차이만이 남게되며 \\(x_i\\)와 \\(y_i\\)는 분포의 가정상 독립이 아니다.\n\\[\n\\begin{aligned}\nd_i &= x_i -y_i \\\\\n   &= \\mu_1+ a_i + e_{i1} -(\\mu_2+ a_i + e_{i2}) \\\\\n   &= \\mu_1 -\\mu_2 +(e_{i1}-e_{i2}) \\\\\n   &= \\mu_1 -\\mu_2 +e^*_i\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nCov(x_i,y_i) &= Cov(\\mu_1+ a_i + e_{i1},\\mu_2+ a_i + e_{i2}) \\\\\n    & =  Cov(a_i, a_i) \\\\\n    & =  Var(a_i) \\\\\n    & =  \\sigma^2_a\n\\end{aligned}\n\\]\n다음 절에서는 여기서 논의한 독립표본과 대응표본의 개념 및 추정법을 일반적인 선형모형으로 확장하여 체계적인 비교를 해볼것이다.",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#repeatmeasure-oneway",
    "href": "notes/random_effect.html#repeatmeasure-oneway",
    "title": "7  반복측정자료",
    "section": "7.4 일원배치 모형",
    "text": "7.4 일원배치 모형\n\n7.4.1 고정효과 모형\n먼저 일원배치 요인계획(one-way factor design)이용한 실험을 생각해 보자. 고려하는 요인의 수준의 개수를 \\(I\\)라고 하면 \\(I\\)개의 수준 중에 하나를 임의로 선택하여 실험대상에 적용하는 임의화 방법으로 각 수준마다 \\(J\\)의 관측값을 얻어다고 하자. 다음과 같은 ANOVA모형을 고려하여 분석을 할 수 있다.\n\\[\ny_{ij} = \\mu + \\alpha_i + e_{ij}, \\quad i=1,2,\\dots,I \\text{ and } j=1,2,\\dots, J  \n\\tag{7.7}\\]\n여기서 \\(e_{ij}\\)는 서로 독립이며 \\(N(0,\\sigma_e^2)\\)를 따르는 오차항이다.\nANOVA 모형 식 7.7 에서 \\(\\mu\\)와 \\(\\alpha_i\\)는 고정효과(fixed effect)라고 부르며 추정해야 할 모수(parameter)이다. 세심하게 설계된 실험에서는 수준에 대한 효과 \\(\\alpha_i\\)의 값이 변하지 않게 통제할 수 있는 실험 환경이 가능하다고 생각할 수 있으므로 \\(\\alpha_i\\)의 값을 변하지 않는 고정효과로 보는 것이 합리적이다.\n일원배치 요인계획을 이용한 실험에서는 주요 관심사가 수준간의 차이가 있는지에 대한 것이며 이는 제곱합을 이용한 ANOVA table에서 F-test를 이용하여 검정할 수 있다.\n\\[\nH_0: \\alpha_1 = \\alpha_2 =\\dots = \\alpha_I\n\\]\n\n\n7.4.2 임의효과 모형\n이제 다음과 같은 자료의 추출을 생각해 보자. 서울시 A구에 초등학교가 20개있다고 하자. 20개의 학교중 6개의 학교를을 임의로 추출하고 추출된 학교에 속한 모든 6학년 학생들에게 과학시험을 보게하여 점수를 얻었다. 이러한 자료에서 학생들의 성적은 모두 같지 않을 것이 당연하며 가장 점수가 낮은 학생부터 높은 학생까지 점수의 변동(variation)이 존재한다. 변동의 요인은 무었일까? 학생의 개인의 차이(예:학생의 지능, 노력 정도, 학습 환경)도 변동의 요인이지만 또한 학교의 차이도 변동의 요인이 될 수 있다.\n여기서 학교에 대한 요인은 앞 절에서 본 실험 자료에서 나타나는 고정 효과에 의한 요인과는 성격이 틀리다. 20개의 학교라는 모집단에서 6개의 학교가 추출되었으며 이 때 학교의 차이는 설계된 실험에서는 수준에 대한 효과와는 다르게 표본 추출 때문에 생기는 변동이라고 할 수 있다. 또한 같은 학교에 다니는 학생들은 같은 지역과 교사 등 공통적인 요인에 의하여 영향을 받는다고 가정할 수 있다. 따라서 같은 학교에 다는 학생들의 성적이 독립이 아닐 수도 있다.\n이러한 효과를 임의효과(random effect)라고 부르며 학생들의 과학점수에 대한 모형을 다음과 같은 임의효과모형(random effects model) 또는 혼합효과모형(mixed effects model) 으로 설명할 수 있다.\n\\[\ny_{ij} = \\mu + a_i + e_{ij}, \\quad i=1,2,\\dots,I \\text{ and } j=1,2,\\dots, J  \n\\tag{7.8}\\]\n여기서 \\(a_i\\)는 학교의 효과를 나타내는 임의효과이며 서로 독립이고 \\(N(0,\\sigma_a^2)\\)를 따른다. 또한 개인에 대한 효과 또는 오차항 \\(e_{ij}\\)는 서로 독립이며 \\(N(0,\\sigma_e^2)\\)를 따른다. 임의효과 \\(a_i\\)와 오차항 \\(e_{ij}\\)는 서로 독립이다. 고정효과 \\(\\mu\\)는 전체 평균을 나타내는 모수이다.\n학교를 추출할 때 그 효과를 분산이 \\(\\sigma^2_a\\)를 가지는 정규모집단에서 추출한다고 가정하는 것이다. 학교를 하나의 군집(cluster)로 생각하고 학교의 효과를 군집효과로 보고 총변동의 일부로서 고려하고 나머지 변동은 오차의 변동으로 개인의 효과 등으로 설명한다.\n\\[\nVar(y_{ij}) =Var(\\mu + a_i + e_{ij}) = Var(a_i) + Var(e_{ij}) = \\sigma^2_a + \\sigma^2_e\n\\]\n식 7.8 로 표현된 임의효과를 포함한 혼합모형(일원배치 임의효과 모형; one-way random effect models)의 가장 큰 특징 중에 하나는 같은 군집에 속하는 관측치들은 서로 독립이 아니며 양의 상관관계가 있다.\n위의 예제에서 두 학생 \\(j\\)와 \\(k\\)가 같은 학교 \\(i\\)에 속한다면\n\\[\nCov(y_{ij},y_{ik}) = Cov(  \\mu + a_i + e_{ij}, \\mu + a_i + e_{ik}) =Cov (a_i, a_i)=\\sigma^2_a\n\\]\n따라서\n\\[\ncorr(y_{ij},y_{ik})= \\frac{ Cov(y_{ij},y_{ik})}{\\sqrt{Var(y_{ij})Var(y_{ik})} } = \\frac{\\sigma^2_a }{\\sigma^2_a + \\sigma^2_e }\n\\]\n위의 상관계수를 보면 학교간의 변동의 크기를 나타내는 \\(\\sigma^2_a\\) 가 각 개인간의 변동을 나타내는 \\(\\sigma^2_e\\)보다 상대적으로 클수록 상관계수가 1에 가까와진다.\n보통 \\(\\sigma^2_a\\)을 집단간 변동(between-group variance)라 하고 \\(\\sigma^2_e\\)를 집단내 변동(within-group variance)라고 한다. 따라서 \\(\\sigma^2_a\\)와 \\(\\sigma^2_e\\)의 상대적인 크기의 차이에 따라 군집내 관측값의 상관관계가 달라진다.\n식 7.8 의 임의효과 모형은 임의효과가 2개 이상인 모형으로 확장될 수 있다. 예제에서 학교를 추출하고 학교내에서 학급을 추출하여 추출된 학급내의 학생들이 시험을 보면 다음과 같은 모형을 적용할 수 있다.\n\\[\ny_{ijk} = \\mu + a_i + b_{ij} + e_{ijk}\n\\] 위의 모형에서 \\(a_i\\)는 \\(N(0,\\sigma^2_a)\\)를 따르는 학교에 대한 임의효과, \\(b_{ij}\\)는 \\(N(0,\\sigma^2_b)\\)를 따르는 학급에 대한 임의효과, \\(e_{ijk}\\)는 \\(N(0,\\sigma^2_e)\\)를 따르는 학생에 대한 임의효과 또는 오차항으로 생각할 수 있다.\n임의효과 모형에 고정효과가 같이 포함되어 있는 모형을 혼합모형(mixed model)이라고 부르며 반응변수의 변동에 영향을 미치는 요인들 또는 예측변수 중에서 임의효과와 고정효과를 구별하여 정하고 동시에 모형에 포함시킬수 있다.\n예를 들어서 학교를 선택하여 과학시험을 볼 경우에 학기가 시작할 떄 과학교수법 두가지 중 하나를 임의화해서 각 학교에 배정하여 배정된 교수법으로 학생을 가르친 후에 시험을 보았다면 교수법에 대한 효과는 고정효과로 볼 수 있다. 따라서 다음과 같은 모형을 고려할 수 있다.\n\\[\ny_{ij} = \\mu + \\tau_{k(i)} + a_i + e_{ij}  \n\\tag{7.9}\\]\n여기서 \\(\\tau_{k(i)}\\)는 \\(i\\)번째 학교의 교수법에 대한 고정효과이다(교수법이 배정된 결과에 의하여 \\(k(i)=1\\) 또는 \\(k(i)=2\\)이 된다). 이 교수법에 대한 고정효과에 대해서는 두 교수법이 차이가 있는 지에 대한 검정이 주요한 관심사일 것이다 (\\(H_0: \\tau_1=\\tau_2\\))",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/random_effect.html#반복측정자료",
    "href": "notes/random_effect.html#반복측정자료",
    "title": "7  반복측정자료",
    "section": "7.5 반복측정자료",
    "text": "7.5 반복측정자료\n반복측정자료(longitudinal data, repeated measurements)는 관측단위안에서 여러 개의 관측값을 측정한 자료의 형식을 말한다.\n예를 들어 환자가 병원을 여러 번 방문하고 방문시마다 혈압을 측정하였다면 한 명의 환자에서 반복 측정한 자료는 서로 독립이 아니다. 또한 가구조사(household survey)에서 가구원의 취업 여부, 건겅 상태등을 여러 해동안 매년 측정하는 경우 이러한 자료를 패널자료(panel data) 또는 longitudinal 자료라고 한다.\n이렇게 하나의 관측단위 안에서 측정한 자료들은 서로 독립이 아닌 특징이 있고 자료를 분석하는 경우 이러한 자료들의 종속구조를 고려하는 모형을 사용하는 것이 적절하다. 이렇게 반복측정자료에서 반복자료들의 공분산구조를 설정하는 통계적 방법들은 다양하지만 대표적으로 쉽게 사용할 수 있는 방법이 임의효과를 포함한 혼합모형을 사용하는 방법이다.\nlme4 패키지에 자료인 spleepstudy는 화물트럭 운전사들에 대한 수면부족 현상에 대하여 연구한 자료이다. 18명의 운전자들이 매일 3시간의 수면(부족한 수면)을 하면서 매일 일정한 동작의 반응시간을 10일동안 반복적으로 측정한 자료가 있다.\n한명의 운전사에게 10일 동안의 반응에 대한 측정자료 10개가 존재하므로 이는 반복측정 자료이며 이러한 10개의 자료는 독립이 아니다.\n일단 자료의 구조를 살펴보자. 반응변수 Reaction은 반응시간(ms)를 나타내며 설명변수로서 Days는 날짜(\\(t=0,1,2,\\dots,9\\)), Subject 는 운전자의 고유번호를 나타낸다.\n\nlibrary(lme4)\nlibrary(lmerTest)\nstr(sleepstudy)\n\n'data.frame':   180 obs. of  3 variables:\n $ Reaction: num  250 259 251 321 357 ...\n $ Days    : num  0 1 2 3 4 5 6 7 8 9 ...\n $ Subject : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nhead(sleepstudy,n=20)\n\n   Reaction Days Subject\n1  249.5600    0     308\n2  258.7047    1     308\n3  250.8006    2     308\n4  321.4398    3     308\n5  356.8519    4     308\n6  414.6901    5     308\n7  382.2038    6     308\n8  290.1486    7     308\n9  430.5853    8     308\n10 466.3535    9     308\n11 222.7339    0     309\n12 205.2658    1     309\n13 202.9778    2     309\n14 204.7070    3     309\n15 207.7161    4     309\n16 215.9618    5     309\n17 213.6303    6     309\n18 217.7272    7     309\n19 224.2957    8     309\n20 237.3142    9     309\n\n\n각 운전자에 대한 10일 간의 반응속도가 시간에 따라 어떻게 변하는 가를 알아보자. 전반적으로 시간이 지나면서 운전자들의 반응시간이 증가하고 있음을 알 수 있다. 또한 개인 별로 반응 시간의 변화와 패턴이 다르다는 것을 알 수 있다.\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) +\n     geom_point(size=0.7) +\n     facet_wrap(\"Subject\", labeller = label_both)+ \n     theme_bw()\n\n\n\n\n\n\n\n\n\n7.5.1 선형 회귀모형\n각 운전자 \\(i\\) 에 대하여 10일간 측정한 반응속도 \\(y_{ij}\\)를 시간에 대하여 선형모형으로 적합하면 개체별 선형회귀 모형(individual model) 을 다음과 같이 표시할 수 있다.\n\\[\ny_{ij} = \\beta_{0i} + \\beta_{1i} t_j + e_{ij},\\quad i=1,2,\\dots,18,\\quad j=1,2,\\dots,10\n\\tag{7.10}\\]\n여기서 오차항 \\(e_{ij}\\)은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n행렬식으로는 다음과 같이 나타낼 수 있다.\n\\[  \n\\pmb y_i =\\pmb X_i \\pmb \\beta_{i} +\\pmb e_i ,\\quad i=1,2,\\dots,18\n\\]\n여기서 \\[\n\\pmb y_i=\\begin{bmatrix}\ny_{i1} \\\\\ny_{i2} \\\\\n\\vdots \\\\\ny_{i,10}\n\\end{bmatrix},~ \\pmb X_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix}, \\pmb \\beta_i=\n\\begin{bmatrix}\n\\beta_{0i} \\\\\n\\beta_{1i} \\\\\n\\end{bmatrix}, \\pmb e_i=\n\\begin{bmatrix}\ne_{i1} \\\\\ne_{i2} \\\\\n\\vdots \\\\\ne_{i,10}\n\\end{bmatrix}\n\\]\n위의 식에서 \\(\\beta_{0i}\\)와 \\(\\beta_{1i}\\)는 \\(i\\)번째 운전사의 반응속도를 설명하는 회귀직선의 절편과 기울기이다.\n절편 \\(\\beta_{0i}\\)는 실험 시작때 반응속도를 의미하고 기울기 \\(\\beta_{1i}\\)는 실험이 진행되는 동안 반응속도가 어떻게 변하는 지 변화의 방향과 크기를 보여준다. 함수 lmList를 아래와 같이 이용하면 식 식 7.10 을 각 운전사마다 적합시켜 각각의 절편과 기울기를 구할 수 있다.\n\nlmf1 &lt;- lmList(Reaction ~ Days | Subject, sleepstudy)\nlmf1\n\nCall: lmList(formula = Reaction ~ Days | Subject, data = sleepstudy) \nCoefficients:\n    (Intercept)      Days\n308    244.1927 21.764702\n309    205.0549  2.261785\n310    203.4842  6.114899\n330    289.6851  3.008073\n331    285.7390  5.266019\n332    264.2516  9.566768\n333    275.0191  9.142045\n334    240.1629 12.253141\n335    263.0347 -2.881034\n337    290.1041 19.025974\n349    215.1118 13.493933\n350    225.8346 19.504017\n351    261.1470  6.433498\n352    276.3721 13.566549\n369    254.9681 11.348109\n370    210.4491 18.056151\n371    253.6360  9.188445\n372    267.0448 11.298073\n\nDegrees of freedom: 180 total; 144 residual\nResidual standard error: 25.59182\n\n\n위에서 고려한 개체별 선형회귀 직선들을 그림으로 그려보면 다음과 같이 나타난다.\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.5) + \n  stat_smooth(method = \"lm\",se=F,linewidth=0.5)+ \n  facet_wrap(\"Subject\", labeller = label_both)+ \n  theme_bw() \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n18개의 절편과 기울기는 큰 상관관계는 없는것으로 보이지만 약한 음의 상관계수가 나타났다. 절편과 기울기에 대한 분포를 보기 위하여 상자그림을 그려보면 평균을 중심으로 대칭인 분포를 보이고 있다.\n\ncor(coef(lmf1))\n\n            (Intercept)       Days\n(Intercept)   1.0000000 -0.1375534\nDays         -0.1375534  1.0000000\n\nplot(coef(lmf1),main=\"intercepts and slopes on drivers: sleep study \")\n\n\n\n\n\n\n\n\nboxplot(coef(lmf1)[1])\nboxplot(coef(lmf1)[2])\n\n\n\n그림 7.1: 개별 선형회귀모형에서 절볓과 기울기의 분포\n\n\n\n\n\n\n\n(a) 절편\n\n\n\n\n\n\n\n\n\n\n\n(b) 기울기\n\n\n\n\n\n\n\n\n\n\n\n\nboxplot(coef(lmf1)[1])\n\n\n\n\n\n\n\n\n이제 각 운전사에 대하여 회귀식을 따로 적합하지 않고 전체 운전사들의 자료를 모두 합쳐서 하나의 회귀식을 고려할 수 있다. 개체의 특성을 반영하는 모형이 아닌 전체 모집단에 대한 모집단 평균 모형(population mean model) 을 고려하는 것이다.\n\\[\ny_{ij} = \\beta_0 + \\beta_1 t_j + e_{ij} ,\\quad i=1,2\\dots,18,  j=1,2, \\dots, 10\n\\tag{7.11}\\]\n여기서 오차항은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n위와 같은 전체 운전사 집단의 관측값을 운전자의 특성을 고려하지 않고 세운 모형으로서 시간에 따른 반응시간에 대한 모집단의 전체적인 평균적 함수 관계를 파악하는 모형이라고 할 수 있다.\n\nlmpop &lt;- lm(Reaction ~ Days, sleepstudy)\nsummary(lmpop)\n\n\nCall:\nlm(formula = Reaction ~ Days, data = sleepstudy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-110.848  -27.483    1.546   26.142  139.953 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.610  38.033  &lt; 2e-16 ***\nDays          10.467      1.238   8.454 9.89e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47.71 on 178 degrees of freedom\nMultiple R-squared:  0.2865,    Adjusted R-squared:  0.2825 \nF-statistic: 71.46 on 1 and 178 DF,  p-value: 9.894e-15\n\nwith(sleepstudy, plot(Days, Reaction,main=\"Population and individual regression lines\"))\nabline(a=coef(lmpop)[1], b=coef(lmpop)[2],lwd=3)\nfor ( i in 1:18 ) {\n  xx &lt;- as.numeric(coef(lmf1)[i,])\nabline(a=xx[1],b=xx[2], lty=2)\n}\n\n\n\n\n\n\n\n\n식 7.10 의 개체별 선형회귀 모형에서 얻은 모든 절편들과 기울기들의 평균을 구하면 다음과 같다.\n\napply(coef(lmf1),2,mean)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n다음으로 식 7.11 의 선형회귀 모형에서 얻은 절편과 기울기의 평균을 구하면 다음과 같다.\n\ncoef(lmpop)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n각 운전사에 대하여 식 7.10 의 개체별로 적합한 회귀식에서 구한 계수들\\((\\hat \\beta_{0i}, \\hat \\beta_{1i})\\) 와 식 7.11 의 모집단 평균 회귀모형에서 구한서 계수 \\((\\hat \\beta_{0}, \\hat \\beta_{1})\\)의 관계를 보면 개체별로 적합한 회귀 계수들의 평균이 모집단 평균 회귀모형의 계수와 매우 가까운 사실을 알 수 있다.\n\n\n7.5.2 임의계수 모형\n앞 절의 모형과 분석에서 알 수 있듯이 한 개체에 대하여 여러 개의 관측값을 측정한 자료에 회귀방정식을 각각 적합시켜보고 또한 개체의 특성을 고려하지않은 전체 모형을 적합해보면 다음과 같은 두 가지 결과를 볼 수 있다.\n\n각 개체별 회귀식은 개인의 특성을 반영한다. 즉, 개체에 따라 시간에 따른 반응시간의 변화가 다르게 나타난다.\n하지만 개인별로 볼 때도 전체적으로는 시간에 따라서 반응시간이 증가하는 경향이 있음을 알 수 있다.\n전체 자료에 적합한 모형을 보면 개인별로 적합한 모형의 공통적인 성격, 즉 시간에 따른 반응시간의 증가를 알 수 있다.\n이러한 결과를 보고 각 개인의 변화는 전체적인 변화를 따르면서 각 개인의 특성이 반영되었다고 가정할 수 있다.\n\n위에서 논의하였듯이 전체적인 경향과 개인의 특성을 동시에 고려할 수 있는 모형이 생각할 수 있고 이러한 모형이 다음과 같은 모형이다.\n\\[\ny_{ij} = (\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i}) t_j + e_{ij}\n\\tag{7.12}\\]\n식 7.12 는 절편과 기울기가 두 개의 구성 요소로 더해져서 표현된다. 기울기는 \\(\\beta_1+b_{1i}\\)로서 나타내어지며 \\(\\beta_1\\)은 모집단이 가지는 공통적인 경향을 반영하는 모수이고 \\(b_{1i}\\)는 \\(i\\) 번째 개체의 특성을 반영한 확률변수이다. 절편도 유사한 형식으로 구성된다.\n각 개인에 대한 특성을 나타내는 변수 \\((b_{0i}, b_{1i})\\) 을 확률변수로 설정하고 이를 모수(\\(\\beta_0, \\beta_1)\\) (parameter or fixed effect)와 구별하여 임의효과(random effect)라고 한다. 임의효과는 모집단을 구성하는 개인이 표본에 추출되었다고 생각하며 확률분포를 따른다고 가정한다. 반복측정자료에서 인의효과를 공통으로 가지고 있는 관측치는 독립이 아니게 돼며 따라서 같은 개체에서 나온 관측값은 독립이 아니다.\n18명에 대한 회귀직선의 절편과 기울기를 보면 개인의 차이에 따른 변동을 볼 수 있으며 이러한 각 개인간의 변동을 임의효과를 이용하여 다음과 같은 모형을 생각해보자.\n\\[\n\\pmb \\beta_i=\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\end{bmatrix}\n+\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix}\n=\n\\pmb \\beta + {\\pmb b}_i\n\\]\n\\[\n{\\pmb b}_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b1} & \\rho \\sigma_{b1} \\sigma_{b2}\\\\\n\\rho \\sigma_{b1} \\sigma_{b2} & \\sigma^2_{b2} \\\\\n\\end{bmatrix}\n\\right )\n\\]\n위의 모형은 각 개인의 회귀직선에서 각 절편과 기울기가 전체평균 \\(\\beta_0\\)와 \\(\\beta_1\\)를 따르며 각 개인의 차이는 전체평균에 임의효과인 \\(b_{0i}\\)와 \\(b_{1i}\\)가 더해져서 나타난다는 것을 의미한다.\n이변량 임의효과 \\(b_{0i}\\)와 \\(b_{1i}\\)는 이변량 정규분포를 따르며 각각의 분산과 상관계수가 \\(\\sigma^2_{b1}\\), \\(\\sigma^2_{b2}\\), \\(\\rho\\)이다.\n다른 개체에 대한 임의효과는 서로 독립이며 임의 효과와 오차항은 독립이다. 여기서 오차항은 서로 독립이며 \\(N(0, \\sigma^2_e)\\)를 따른다고 가정한다.\n\\[  Cov(\\pmb b_{i}, \\pmb b_{j}) =\\pmb 0 \\text{ when } i \\ne j,\\quad\nCov(\\pmb b_{i}, e_{jk}) =\\pmb 0 \\text{ for all } i,j,k \\]\n\n\n7.5.3 혼합효과 모형\n임의계수모형을 각 개인 \\(i\\)에 대하여 행렬식으로 표시하면 다음과 같은 혼합효과모형(mixed effects model)으로 나타낼 수 있다. 혼합효과모형은 반응변수에 영향을 미치는 효과를 고정효과와 임의효과로 나누어 설명하는 모형이다.\n\\[  \n\\pmb y_i = \\pmb X_i \\pmb \\beta + \\pmb Z_i \\pmb b_i + \\pmb e_i\n\\]\n여기서\n\\[  \n\\pmb y_i=\\begin{bmatrix}\ny_{i1} \\\\\ny_{i2} \\\\\n\\vdots \\\\\ny_{i,10}\n\\end{bmatrix},~\\pmb X_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix}, \\pmb  \\beta=\n\\begin{bmatrix}\n\\beta_{0} \\\\\n\\beta_{1} \\\\\n\\end{bmatrix}, ~\\pmb Z_i =\n\\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n\\vdots & \\vdots  \\\\\n1 & 9\n\\end{bmatrix},~ \\pmb b_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix},~\n\\pmb  e_i=\n\\begin{bmatrix}\ne_{i1} \\\\\ne_{i2} \\\\\n\\vdots \\\\\ne_{i,10}\n\\end{bmatrix}\n\\]\n위의 각 개인에 대한 모형을 모두 합쳐서 하나의 혼합효과모형으로 나타내면 다음과 같이 표현할 수 있다.\n\\[\n\\pmb  y = \\pmb  X \\pmb \\beta + \\pmb Z \\pmb b + \\pmb e\n\\tag{7.13}\\] \\end{equation}\n여기서 반응변수 벡터 \\(\\pmb y\\)와 고정효과 \\(\\pmb \\beta\\)에 대한 계획행렬 \\(X\\)는 각 개인의 반응변수 벡터 \\(\\pmb y_i\\)와 \\(\\pmb X_i\\)를 행으로 쌓아놓은 것으로 표현된다. 오차항에 대한 벡터 \\(\\pmb e\\)도 동일한 형식의 벡터이다.\n\\[  \n\\pmb y_i=\\begin{bmatrix}\n\\pmb y_{1} \\\\\n\\pmb y_{2} \\\\\n\\vdots \\\\\n\\pmb y_{18}\n\\end{bmatrix},~\\pmb X =\n\\begin{bmatrix}\n\\pmb X_1 \\\\\n\\pmb X_2 \\\\\n\\vdots \\\\\n\\pmb  X_{18}\n\\end{bmatrix}\n~ \\pmb e =\n\\begin{bmatrix}\n\\pmb e_1 \\\\\n\\pmb e_2 \\\\\n\\vdots  \\\\\n\\pmb e_{18}\n\\end{bmatrix}\n\\]\n임의효과 벡터 \\({\\pmb b}\\) 는 각 개인에 대한 임의효과벡터 \\(\\pmb b_i\\)를 행으로 쌓아놓은것과 같고 임의효과에 대한 계획행렬 \\(\\pmb Z\\)는 각 개인의 계획행렬 \\(\\pmb Z_i\\)를 대각원소로 같은 행렬이다.\n\\[\n\\pmb b=\\begin{bmatrix}\n\\pmb b_{1} \\\\\n\\pmb b_{2} \\\\\n\\vdots \\\\\n\\pmb b_{18}\n\\end{bmatrix},~\\pmb Z =\n\\begin{bmatrix}\n\\pmb Z_1 & 0 & \\dots & 0 \\\\\n0   & \\pmb Z_2 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots  \\\\\n0 & 0 & \\dots & \\pmb Z_{18}\n\\end{bmatrix}\n\\]\n임의효과는 개인의 특성을 설명하는 효과로서 모집단을 구성하는 개인이 표본에 추출되었다고 생각하며 확률분포를 따른다고 가정한다. 반복측정자료에서 임의효과를 공통으로 가지고 있는 관측치는 독립이 아니게 돼며 따라서 같은 개체에서 나온 관측값은 독립이 아니다.\n\n\n7.5.4 선형혼합모형의 적합\n혼합모형 식 7.13 은 lmer() 함수를 이용하여 적합시켜보자. 모형식에서 (1 + Days|Subject) 는 각 개체 Subject 에 대하여 절편 1 과 기울기 Days에 임의효과를 포함한다고 지정한다.\n\nfm1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy)\nsummary(fm1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  &lt; 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n\n\n위의 혼합모형 적합결과를 살펴보자. 첫째로 고정효과에 대한 추정식은 다음과 같다\n\nfixef(fm1)\n\n(Intercept)        Days \n  251.40510    10.46729 \n\n\n\\[\n\\begin{bmatrix}\n\\hat {\\beta}_{0} \\\\\n\\hat {\\beta}_{1} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n251.4051048 \\\\\n10.467286\n\\end{bmatrix}\n\\]\n또한 오차항에 대한 분산 및 임의효과의 분산성분과 상관계수는 다음과 같이 나타난다.\n\nVarCorr(fm1)\n\n Groups   Name        Std.Dev. Corr \n Subject  (Intercept) 24.7407       \n          Days         5.9221  0.066\n Residual             25.5918       \n\n\n\\[\n\\begin{aligned}\n\\hat \\sigma_{b1} & =  24.740658 \\\\\n\\hat \\sigma_{b2} & =  5.9221377 \\\\\n\\hat \\rho & = 0.0655512 \\\\\n\\hat \\sigma_e & = 25.5917957\n\\end{aligned}\n\\]\n\n\n7.5.5 임의효과에 대한 예측\n이제 임의효과 \\(\\pmb b_i =(b_{0i}, b_{1i})^t\\)에 대한 예측(prediction)을 생각해보자. 우리는 오직 관측벡터 \\(\\pmb y_i\\)만을 관측하고 임의효과 \\(\\pmb b_i\\)는 관측을 할 수 없는 확률변수이다. 하지만 주어진 관측벡터와 추정된 분산으로 임의효과의 값을 예측할 수있으며 그 결과는 다음과 같다.\n\nre &lt;- ranef(fm1)$Subject\nre\n\n    (Intercept)        Days\n308   2.2585509   9.1989758\n309 -40.3987381  -8.6196806\n310 -38.9604090  -5.4488565\n330  23.6906196  -4.8143503\n331  22.2603126  -3.0699116\n332   9.0395679  -0.2721770\n333  16.8405086  -0.2236361\n334  -7.2326151   1.0745816\n335  -0.3336684 -10.7521652\n337  34.8904868   8.6282652\n349 -25.2102286   1.1734322\n350 -13.0700342   6.6142178\n351   4.5778642  -3.0152621\n352  20.8636782   3.5360011\n369   3.2754656   0.8722149\n370 -25.6129993   4.8224850\n371   0.8070461  -0.9881562\n372  12.3145921   1.2840221\n\n\n예를 들어 첫 번째 운전자에 대한 절편과 기울기의 임의효과에 대한 예측값은 다음과 같다.\n\\[ {\\hat b}_{0i} = 2.2585509, \\quad  {\\hat b}_{1i} =   9.1989758 \\] 위에서 구한 절편과 기울기에 대한 임의효과들의 산포도를 보면 다음과 같다.\n\nplot(re, main =\"prediction of random effects \")\n\n\n\n\n\n\n\n\n예측된 각 개인의 절편과 기울기에 대한 임의효과의 예측값 \\({\\hat b}_{0i}\\)과 \\({\\hat b}_{1i}\\)에 고정효과의 추정량 \\(\\hat \\beta_0\\)와 \\(\\hat \\beta_1\\)에 각각 더해주면 각 개인의 절편과 기울기에 대한 예측값을 구할 수 있다.\n\\[\n{\\hat \\beta}_{0i} = \\hat \\beta_0 + {\\hat b}_{0i} , \\quad\n{\\hat \\beta}_{1i} = \\hat \\beta_1 + {\\hat b}_{1i}\n\\]\n\nbeta &lt;- matrix(as.numeric(fixef(fm1)),18,2,byrow=T)\nbeta + re \n\n    (Intercept)       Days\n308    253.6637 19.6662617\n309    211.0064  1.8476053\n310    212.4447  5.0184295\n330    275.0957  5.6529356\n331    273.6654  7.3973743\n332    260.4447 10.1951090\n333    268.2456 10.2436499\n334    244.1725 11.5418676\n335    251.0714 -0.2848792\n337    286.2956 19.0955511\n349    226.1949 11.6407181\n350    238.3351 17.0815038\n351    255.9830  7.4520239\n352    272.2688 14.0032871\n369    254.6806 11.3395008\n370    225.7921 15.2897709\n371    252.2122  9.4791297\n372    263.7197 11.7513080\n\n\n예를 들어 선형혼합모형에서 첫 번째 운전자에 대한 절편과 기울기에 대한 추정값은 다음과 같다.\n\\[\n{\\hat \\beta}_{0i} =  253.6637,  \\quad {\\hat \\beta}_{1i} = 19.6662617\n\\]\n\n\n7.5.6 수축 현상\n각 운전자에 대해 개체별 회귀직선 식 7.10 과 임의계수 모형 식 7.10 적합시켜서 얻은 18개의 절편과 기울기를 비교해보자.\n먼저 개체별 회귀직선에서 적합한 절편과 기울기는 다음과 같다.\n\nab_lines_ind &lt;- coef(lmf1) %&gt;% \n  tibble::rownames_to_column(\"Subject\") %&gt;% \n  rename(intercept = `(Intercept)`) %&gt;%\n  tibble::add_column(Model = \"개체별 모형\")\nab_lines_ind\n\n   Subject intercept      Days       Model\n1      308  244.1927 21.764702 개체별 모형\n2      309  205.0549  2.261785 개체별 모형\n3      310  203.4842  6.114899 개체별 모형\n4      330  289.6851  3.008073 개체별 모형\n5      331  285.7390  5.266019 개체별 모형\n6      332  264.2516  9.566768 개체별 모형\n7      333  275.0191  9.142045 개체별 모형\n8      334  240.1629 12.253141 개체별 모형\n9      335  263.0347 -2.881034 개체별 모형\n10     337  290.1041 19.025974 개체별 모형\n11     349  215.1118 13.493933 개체별 모형\n12     350  225.8346 19.504017 개체별 모형\n13     351  261.1470  6.433498 개체별 모형\n14     352  276.3721 13.566549 개체별 모형\n15     369  254.9681 11.348109 개체별 모형\n16     370  210.4491 18.056151 개체별 모형\n17     371  253.6360  9.188445 개체별 모형\n18     372  267.0448 11.298073 개체별 모형\n\n\n이제 식 7.12 의 임의계수 모형에서 적합한 기울기와 절편은 다음과 같다.\n\nab_lines_random &lt;- coef(fm1)[[\"Subject\"]] %&gt;% \n  tibble::rownames_to_column(\"Subject\") %&gt;% \n  rename(intercept = `(Intercept)`) %&gt;%\n  tibble::add_column(Model = \"임의계수 모형\")\nab_lines_random \n\n   Subject intercept       Days         Model\n1      308  253.6637 19.6662617 임의계수 모형\n2      309  211.0064  1.8476053 임의계수 모형\n3      310  212.4447  5.0184295 임의계수 모형\n4      330  275.0957  5.6529356 임의계수 모형\n5      331  273.6654  7.3973743 임의계수 모형\n6      332  260.4447 10.1951090 임의계수 모형\n7      333  268.2456 10.2436499 임의계수 모형\n8      334  244.1725 11.5418676 임의계수 모형\n9      335  251.0714 -0.2848792 임의계수 모형\n10     337  286.2956 19.0955511 임의계수 모형\n11     349  226.1949 11.6407181 임의계수 모형\n12     350  238.3351 17.0815038 임의계수 모형\n13     351  255.9830  7.4520239 임의계수 모형\n14     352  272.2688 14.0032871 임의계수 모형\n15     369  254.6806 11.3395008 임의계수 모형\n16     370  225.7921 15.2897709 임의계수 모형\n17     371  252.2122  9.4791297 임의계수 모형\n18     372  263.7197 11.7513080 임의계수 모형\n\n\n이제 개체별 회귀직선 식 7.10 과 임의계수 모형 식 7.10 적합시켜서 얻은 18명의 개체에 대한 선형회귀 모형을 그림으로 그려보자.\n\nab_lines_pop &lt;- data_frame(\n  Subject = unique(sleepstudy$Subject),\n  intercept = coef(lm(Reaction ~ Days, sleepstudy))[1],\n  Days = coef(lm(Reaction ~ Days, sleepstudy))[2],\n  Model = \"모집단 평균모형\"\n)\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\nall_lines &lt;- bind_rows(ab_lines_pop, ab_lines_ind, ab_lines_random)\n\nhead(all_lines,5) \n\n# A tibble: 5 × 4\n  Subject intercept  Days Model          \n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n1 308          251.  10.5 모집단 평균모형\n2 309          251.  10.5 모집단 평균모형\n3 310          251.  10.5 모집단 평균모형\n4 330          251.  10.5 모집단 평균모형\n5 331          251.  10.5 모집단 평균모형\n\n\n\nggplot(sleepstudy, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.7) + \n  geom_abline(aes(intercept = intercept, slope = Days, color=Model), data = all_lines) +\n  facet_wrap(\"Subject\") + \n  theme_bw() + \n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n이렇게 혼합모형을 통해서 얻은 각 개인의 절편과 기울기에 대한 예측값과 각각의 개체별 선형회귀 직선을 따로 적합하여 얻은 절편과 기울기의 관계를 그림으로 그려보면 다음과 같다.\n혼합모형을 통해서 얻은 각 개인의 절편과 기울기는 절편과 기울기의 전체평균값 방향으로 수축되는 경향(shrinkage)을 볼수있다.\n\nggplot(bind_rows(ab_lines_ind, ab_lines_random)) + \n  aes(x = intercept, y = Days, color = Model) + \n  geom_point() + \n  geom_point(data = ab_lines_pop) + \n  geom_path(aes(group = Subject), \n            arrow = arrow(length = unit(.02, \"npc\"))) + \n  theme_bw() + \n  theme(legend.position = \"bottom\") + \n  ggtitle(\"회귀계수의 수축\")\n\n\n\n\n\n\n\n\n\n\n7.5.7 모형의 비교\n위에서 고려한 임의계수모형 식 7.12 에서는 절편과 기울기에 대한 2개의 임의효과 \\(b_{0i}\\) 와 \\(b_{1i}\\) 를 고려하고 더 나아가 두 개의 임의효과가 독립이 아니며 상관계수가 \\(\\rho\\)라고 가정하였다.\n앞에서 추정결과에 의하면 두 개의 임의효과의 상관계수의 추정값은 \\(\\hat \\rho = 0.066\\) 으로 거의 0에 가깝다. 이러한 결과에 근거하여 두 임의효과가 독립인 축소모형을 고려해 보자. 즉 임의계수모형 식 7.12 에서 임의효과의 상관계수가 \\(\\rho=0\\)인 임의효과의 분포를 다음과 같이 가정한다.\n\\[\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b1} & 0\\\\\n0 & \\sigma^2_{b2} \\\\\n\\end{bmatrix}\n\\right )\n\\]\n이러한 모형을 아래와 같이 적합시키면 추정결과는 다음과 같다. 아래 모형식에서 (1 + Days||Subject) 는 각 개체 Subject 에 대하여 절편 1 과 기울기 Days에 임의효과를 포함한다고 지정하며 한개의 바 | 대신 두 개의 바 || 를 사용하면 임의효과가 독립이라는 것을 지정한다.\n\nfm2 &lt;- lmer(Reaction ~ 1 + Days + (1+Days || Subject) , sleepstudy)\nsummary(fm2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days || Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9626 -0.4625  0.0204  0.4653  5.1860 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n Subject   (Intercept) 627.57   25.051  \n Subject.1 Days         35.86    5.988  \n Residual              653.58   25.565  \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.885  18.156  36.513  &lt; 2e-16 ***\nDays          10.467      1.560  18.156   6.712 2.59e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.184\n\n\n상관계수가 0인 모형에 대한 추정 결과는 상관계수가 있는 모형과 크게 다르지 않다.\n두 모형, 즉 절편과 기울기에 대한 두 임의효과가 종속인지 또는 독립인지에 대한 두 모형을 AIC(Akaike Information Criteris)와 BIC(Bayesian Information Criteria)로 비교한 결과이다. 두 모형 간의 차이는 거의 없는 것으로 판단된다.\n\nc(AIC(fm1) , BIC(fm1))\n\n[1] 1755.628 1774.786\n\nc(AIC(fm2), BIC(fm2))\n\n[1] 1753.669 1769.634\n\n\n더나아가 anova 함수를 이용하여 두 모형의 차이를 검정한 결과는 두 모형 간의 차이가 없다는 것이다. 참고할 점은 혼합모형에서의 모형을 비교하는 분산분석에 의한 검정은 효율이 떨어질 수 있기 때문에 주의해야 한다.\n\nanova(fm1,fm2)\n\nrefitting model(s) with ML (instead of REML)\n\n\nData: sleepstudy\nModels:\nfm2: Reaction ~ 1 + Days + (1 + Days || Subject)\nfm1: Reaction ~ 1 + Days + (1 + Days | Subject)\n    npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)\nfm2    5 1762.0 1778.0 -876.00   1752.0                     \nfm1    6 1763.9 1783.1 -875.97   1751.9 0.0639  1     0.8004",
    "crumbs": [
      "혼합모형",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>반복측정자료</span>"
    ]
  },
  {
    "objectID": "notes/spline-01.html#regressogram",
    "href": "notes/spline-01.html#regressogram",
    "title": "8  국소 회귀모형",
    "section": "8.1 Regressogram",
    "text": "8.1 Regressogram\nRegressogram은 histogrm을 회귀모형에 적용한 방법이다. 아래의 함수 regressogram은 설명변수 벡터 x와 반응변수 벡터 y 를 인자로 받으며 구간 (left, right) 를 k개의 구간으로 나누어 각 구간마다 반응값들의 평균을 구해주는 함수이다. 이렇게 주어진 구간에서 평균값을 이용하여 회귀식을 추정하는 모형을 국소회귀(local regression)이라고 한다.\n\nregressogram = function(x,y,left,right,k,plotit,xlab=\"\",ylab=\"\",sub=\"\"){\n  ### assumes the data are on the interval [left,right]\n  n = length(x)\n  B = seq(left,right,length=k+1)\n  WhichBin = findInterval(x,B)\n  N = tabulate(WhichBin)\n  m.hat = rep(0,k)\n  for(j in 1:k){\n    if(N[j]&gt;0)m.hat[j] = mean(y[WhichBin == j])\n  }\n  if(plotit==TRUE){\n    a = min(c(y,m.hat))\n    b = max(c(y,m.hat))\n    plot(B,c(m.hat,m.hat[k]),lwd=3,type=\"s\",\n         xlab=xlab,ylab=ylab,ylim=c(a,b),col=\"blue\",sub=sub)\n    points(x,y,cex=.6)\n  }\n  return(list(bins=B,m.hat=m.hat))\n}\n\n위의 프로그램에서 findInterval(x,B)은 전체 구간 B의 각 구간에 벡터 x 의 값들이 속해있는 정보를 계산해준다. 예를 들어서 \\((0,10)\\) 구간을 4개로 나누고 \\((1,2,2,4,6,7,8)\\)의 값이 어떤 구간에 속해있는지 다음과 같이 알 수 있다.\n\nB = seq(0,10,length=5)\nB\n\n[1]  0.0  2.5  5.0  7.5 10.0\n\nx = c(1,2,2,4,6,7,8)\nfindInterval(x,B)\n\n[1] 1 1 1 2 3 3 4\n\n\n이제 다음과 같은 \\(m(x)\\)를 고려하고 오차항 \\(e\\)가 정규분포 \\(N(0, 3^2)\\)을 따른다고 가정하고 임의로 100개의 독립표본을 만든다. \\(x\\)의 값들은 구간 \\((0,1)\\)에서 균등분포를 따른다.\n\\[ m(x) = 3 \\sin(8x) \\] 이제 구간의 수를 \\(k=5,10,20\\) 으로 바꾸면서 regressogram이 어떤 형태로 \\(m(x)\\)를 추정하는지 알아보자.\n\npar(mfrow=c(2,2))\nn = 100\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nplot(x,y,pch=20)\nout = regressogram(x,y,left=0,right=1,k=5,plotit=TRUE)\nout = regressogram(x,y,left=0,right=1,k=10,plotit=TRUE)\nout = regressogram(x,y,left=0,right=1,k=20,plotit=TRUE)\n\n\n\n\n\n\n\n\n이제 라이브러리 ElemStatLearn에 있는 실제 자료 bone를 이용하여 regressogram 을 그려보자. 자료 bone의 반응변수는 density (Measurements in the bone mineral density) 이며 설명변수는 나이(age)이다. 남자와 여자를 따로 그렸으며 구간의 크기는 각각 \\(k=10\\)과 \\(k=20\\)을 사용해 보았다.\n\npar(mfrow=c(2,2))\n#install.packages(\"ElemStatLearn\") \n\nattach(bone)\nage.male = age[gender == \"male\"]\ndensity.male = spnbmd[gender == \"male\"]\nout = regressogram(age.male,density.male,left=9,right=26,k=10,plotit=TRUE,\n                   xlab=\"Age\",ylab=\"Density\",sub=\"Male\")\nout = regressogram(age.male,density.male,left=9,right=26,k=20,plotit=TRUE,\n                   xlab=\"Age\",ylab=\"Density\",sub=\"Male\")\nage.female = age[gender == \"female\"]\ndensity.female = spnbmd[gender == \"female\"]\nout = regressogram(age.female,density.female,left=9,right=26,k=10,plotit=TRUE,xlab=\"Age\",ylab=\"Density\",sub=\"Female\")\nout = regressogram(age.female,density.female,left=9,right=26,k=20,plotit=TRUE,xlab=\"Age\",ylab=\"Density\",sub=\"Female\")",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>국소 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/spline-01.html#커널추정",
    "href": "notes/spline-01.html#커널추정",
    "title": "8  국소 회귀모형",
    "section": "8.2 커널추정",
    "text": "8.2 커널추정\n\n8.2.1 커널추정법\n국소회귀에서 가장 많이 사용되는 방법이 커널추정(kernel estimation) 방법이다.\n커널은 다음과 같은 성질을 만족하는 함수 \\(K(x)\\)이다.\n\\[\n\\int K(x) d x=1, \\quad \\int x K(x) d x=0, \\quad 0&lt;\\int x^2 K(x) d x&lt;\\infty\n\\] 커널추정법은 함수 \\(m(x)\\) 를 다음과 같은 방법으로 추정한다.\n\\[ \\hat m(x) = \\frac{ \\sum_{i=1}^n K \\left ( \\frac{x -X_i}{h} \\right ) Y_i }\n{ \\sum_{i=1}^n K \\left ( \\frac{x -X_i}{h} \\right ) }  \\]\n여기서 \\(h\\)는 구간길이(bandwidth)라고 부르며 커널의 폭을 결정하는 양이다. \\(h\\) 가 커지면 추정치 \\(\\hat m(x)\\)는 부드러워지고 \\(h\\)가 작아지면 추정치 \\(\\hat m(x)\\)는 뾰족해진다.\n주로 사용하는 커널함수는 정규분포 커널과\n\\[\nK(x)=\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-x^2 / 2\\right),\n\\] 에페네크니코프 커널(Epanechnikov kernel)이 있다.\n\\[\nK(x)= \\begin{cases}3 / 4\\left(1-x^2\\right) & \\text { if }|x| \\leq 1 \\\\ 0 & \\text { else }\\end{cases}\n\\]\n다음의 함수 kernel(x,y,grid,h)은 표준편차의 크기가 구간길이 \\(h\\)인 정규분포 확률밀도함수를 커널로 이용하여 주어진 값 \\(x\\)에서 반응변수 \\(y\\)들의 가중평균을 구해주는 함수이다.\n\\[\nK \\left ( \\frac{x -y}{h} \\right )  = (2\\pi h^2)^{-1/2} \\exp  \\left (  - \\frac{(x -y)^2 }{2h^2} \\right )\n\\]\n다음의 함수 kernel.fitted(x,y,h)는 주어진 자료벡터 x,y와 구간의 크기 h에 대하여 반응변수의 예측값 \\(\\hat Y_i =\\hat m_h(X_i)\\) 을 커널추정으로 구해준다.\n\nkernel.fitted = function(x,y,h){\n  ### fitted values and diaginal of smoothing matrix\n  n = length(x)\n  m.hat = rep(0,n)\n  S = rep(0,n)\n  for(i in 1:n){\n    w = dnorm(x[i],x,h)\n    w = w/sum(w)\n    m.hat[i] = sum(y*w)\n    S[i] = w[i]\n  }\n  return(list(fitted=m.hat,S=S))\n}\n\n\\[\n\\hat Y_i = \\hat m(X_i) = \\frac{ \\sum_{j=1}^n K \\left ( \\frac{X_i -X_j}{h} \\right ) Y_j }\n{ \\sum_{j=1}^n K \\left ( \\frac{X_i -X_j}{h} \\right ) }  = \\sum_{j=1}^{n} l_j(X_i) Y_j = \\sum_{j=1}^{n} L_{ij} Y_j\n\\] 또한 위의 식에서 \\(L_{ij} = l_j(X_i)\\)라고 하면 다음과 같은 선형예측식에서 \\(n \\times n\\) 행렬 \\(L = \\{ L_{ij} \\}\\)의 대각원소 \\(L_{ii}\\)도 계산해준다.\n\\[ \\hat Y  = L Y \\]\n다음 그림을 보면 \\(h\\) 의 크기가 커지면서 추정치 \\(\\hat m_h(X_i)\\)가 부드러워지는 것을 볼 수 있다.\n다음은 \\(h\\) 가 0.1 인경우 커널추정로 추정한 \\(\\hat m_h(X_i)\\) 의 그림이다. \\(\\hat m_h(X_i)\\)는 빨간색 점으로 표시하였다.\n\nhaty &lt;- kernel.fitted(age.female,density.female, 0.1)\nplot(age.female,density.female, type=\"n\", ylab = \"density\", xlab=\"age\")\npoints(age.female,density.female,cex=.2)\npoints(age.female,haty$fitted, cex=.8, pch=16, col=\"red\")\n\n\n\n\n\n\n\n\n다음은 \\(h\\) 가 0.2 인경우 커널추정로 추정한 \\(\\hat m_h(X_i)\\) 의 그림이다. \\(\\hat m_h(X_i)\\)는 빨간색 점으로 표시하였다.\n\nhaty &lt;- kernel.fitted(age.female,density.female, 0.2)\nplot(age.female,density.female, type=\"n\", ylab = \"density\", xlab=\"age\")\npoints(age.female,density.female,cex=.2)\npoints(age.female,haty$fitted, cex=.8, pch=16, col=\"red\")\n\n\n\n\n\n\n\n\n다음은 \\(h\\) 가 0.4 인경우 커널추정로 추정한 \\(\\hat m_h(X_i)\\) 의 그림이다. \\(\\hat m_h(X_i)\\)는 빨간색 점으로 표시하였다.\n\nhaty &lt;- kernel.fitted(age.female,density.female, 0.4)\nplot(age.female,density.female, type=\"n\", ylab = \"density\", xlab=\"age\")\npoints(age.female,density.female,cex=.2)\npoints(age.female,haty$fitted, cex=.8, pch=16, col=\"red\")\n\n\n\n\n\n\n\n\n다음은 \\(h\\) 가 0.6 인경우 커널추정로 추정한 \\(\\hat m_h(X_i)\\) 의 그림이다. \\(\\hat m_h(X_i)\\)는 빨간색 점으로 표시하였다.\n\nhaty &lt;- kernel.fitted(age.female,density.female, 0.6)\nplot(age.female,density.female, type=\"n\", ylab = \"density\", xlab=\"age\")\npoints(age.female,density.female,cex=.2)\npoints(age.female,haty$fitted, cex=.8, pch=16, col=\"red\")\n\n\n\n\n\n\n\n\n다음은 \\(h\\) 가 3.0 인경우 커널추정로 추정한 \\(\\hat m_h(X_i)\\) 의 그림이다. \\(\\hat m_h(X_i)\\)는 빨간색 점으로 표시하였다.\n\nhaty &lt;- kernel.fitted(age.female,density.female, 3.0)\nplot(age.female,density.female, type=\"n\", ylab = \"density\", xlab=\"age\")\npoints(age.female,density.female,cex=.2)\npoints(age.female,haty$fitted, cex=.8, pch=16, col=\"red\")\n\n\n\n\n\n\n\n\n이제 구간길이 \\(h=0.6\\)값에 대하여 설명변수 \\(X\\) 의 구간을 잘게 그리드(grid)로 나누어 각 설명변수의 값에서 커널추정량을 구해보자.\n\\[\n\\hat Y(x) = \\hat m(x) = \\frac{ \\sum_{i=1}^n K \\left ( \\frac{x -X_i}{h} \\right ) Y_i }\n{ \\sum_{i=1}^n K \\left ( \\frac{x -X_i}{h} \\right ) }  \n\\]\n다음 함수 kernel 에서 인자 grid는 x축에서 커널을 계산할 떄 사용되는 점들 모아놓은 벡터이다.\n\nkernel = function(x,y,grid,h){\n  ### kernel regression estimator at a grid of values\n  n = length(x)\n  k = length(grid)\n  m.hat = rep(0,k)\n  for(i in 1:k){\n    w = dnorm(grid[i],x,h)\n    m.hat[i] = sum(y*w)/sum(w)\n  }\n  return(m.hat)\n}\n\n\ngrid = seq(min(age.female),max(age.female),length=100)\nm.hat = kernel(age.female,density.female,grid,h=0.6)\nplot(age.female,density.female,xlab=\"Age\",ylab=\"Density\")\nlines(grid,m.hat,lwd=3,col=\"blue\")\n\n\n\n\n\n\n\n\n\n\n8.2.2 편이-분산의 관계\n만약 \\(\\hat m(x)\\)가 \\(m(x)\\)의 추정량이라면 예측위험함수(prediction risk, prediction error) \\(R(m, \\hat m)\\)는 다음과 같이 정의되고분해할 수 있다. 아래의 식을 유도할 때 편의상 \\(X\\)는 확률변수가 아닌 고정된 값이라고 할 것이며 확률변수인 경우에도 유사한 결과를 얻는다.\n\\[\n\\begin{aligned}\nR(m, \\hat m) & = E[Y - \\hat m(X)) ]^2 \\\\\n  &=  E[ (Y - m(X) + m(X) -E(\\hat m(X))  + E(\\hat m(X)) -\\hat m(X) ]^2 \\\\\n  &= E[ (Y - m(X) ]^2 + E[m(X) -E(\\hat m(X)) ]^2 + E[\\hat m(X) -E(\\hat m(X))]^2 + \\text{cross product terms}\n\\end{aligned}\n\\]\n위의 식에서 다음과 같은 결과를 이용하면 교차항들(cross-product terms)은 0이 됨을 보일 수 있으며\n\\[ E [Y - m(X) ] =E(e) = 0, \\quad E[\\hat m(X) -E(\\hat m(X))] =0 \\] 또한 다음과 같은 관계를 이용하면\n\\[ E [Y - m(X) ]^2 =E(e^2) = \\tau^2, \\quad m(X) -E(\\hat m(X)) = bias(\\hat m(X)), \\quad E[\\hat m(X) -E(\\hat m(X))]^2 = Var(\\hat m(X)) \\]\n다음과 같이 예측위험함수의 분해가 가능하다.\n\\[ R(m, \\hat m)  = E[Y - \\hat m(X) ]^2= \\tau^2 + [bias(\\hat m(X))]^2 + Var(\\hat m(X)) \\]\n위의 식에서 \\(X\\)가 확률변수이면 먼저 \\(X\\)가 주어진 조건부 기대값을 생각하고 위와 같이 유도하면 다음과 같이 나타낼 수 있다.\n\\[\n\\begin{aligned}\nR(m, \\hat m) & = E[Y - \\hat m(X))^2 ]^2 \\\\\n  & = E \\left \\{ E[ (Y - \\hat m(X))^2 |X=x ] \\right \\} \\\\\n   & =  \\tau^2 + \\int [bias(\\hat m(x))]^2 dP(x) + \\int Var(\\hat m(x))  dP(x)\n\\end{aligned}\n\\]\n\n\n8.2.3 최적 구간길이 선택\n다음의 함수 CV(x,y,H)는 자료벡터 x,y와 서로 다른 \\(h\\)의 값들을 모아 놓은 벡터 H를 받아서 다음과 같은 cross-validation의 값 \\(CV\\), \\(GCV\\), \\(\\nu\\)를 계산해 주는 함수이다.\n\\[\n\\begin{aligned}\nCV & = \\frac{1}{n} \\sum_i^n [ Y_i - \\hat m_h^{(-i)} (X_i) ] ^2\n= \\frac{1}{n} \\sum_i^n \\left ( \\frac {Y_i - \\hat m_h (X_i) }{1-L_{ii}} \\right )^2 \\\\\nGCV & = \\frac{1}{ \\left ( 1-\\frac{\\nu}{n} \\right )^2 } \\frac{1}{n} \\sum_i^n ( Y_i - \\hat m_h (X_i))^2 \\\\\n\\nu &= trace(L)\n\\end{aligned}\n\\]\n\nCV = function(x,y,H){\n  ### H is a vector of bandwidths\n  n = length(x)\n  k = length(H)\n  cv = rep(0,k)\n  nu = rep(0,k)\n  gcv = rep(0,k)\n  for(i in 1:k){\n    tmp = kernel.fitted(x,y,H[i])\n    cv[i] = mean(((y - tmp$fitted)/(1-tmp$S))^2)\n    nu[i] = sum(tmp$S)\n    gcv[i] = mean((y - tmp$fitted)^2)/(1-nu[i]/n)^2\n  }\n  return(list(cv=cv,gcv=gcv,nu=nu))\n}\n\n이제 위에서 보았던 bone 자료에 대한 회귀식을 커널로 추정하려고 한다. 이때 CV 또는 GCV를 최소화하는 구간의 크기(bandwidth) \\(h\\)를 찾기위하여 구간 \\((0.1,5)\\)안에서 20개의 \\(h\\)값에 대한 CV 또는 GCV 값을 계산한다. 아래는 CV 또는 GCV 값을 최소로 하는 \\(h\\)값을 찾는 프로그램이다.\n\npar(mfrow=c(1,2))\nH = seq(.1,5,length=20)\nH\n\n [1] 0.1000000 0.3578947 0.6157895 0.8736842 1.1315789 1.3894737 1.6473684\n [8] 1.9052632 2.1631579 2.4210526 2.6789474 2.9368421 3.1947368 3.4526316\n[15] 3.7105263 3.9684211 4.2263158 4.4842105 4.7421053 5.0000000\n\nout = CV(age.female,density.female,H)\nplot(H,out$cv,type=\"l\",lwd=3,xlab=\"Bandwidth\",ylab=\"Cross-validation Score\")\nlines(H,out$gcv,lty=2,col=\"red\",lwd=3)\nplot(out$nu,out$cv,type=\"l\",lwd=3,xlab=\"Effective Degrees of Freedom\",ylab=\"Cross-validation score\")\nlines(out$nu,out$gcv,lty=2,col=\"red\",lwd=3)\n\n\n\n\n\n\n\nj = which.min(out$cv)\nh = H[j]\nh\n\n[1] 0.6157895\n\n\n위의 그래프에서 왼쪽은 \\(h\\)값에 대한 CV(검정 점선)과 GCV(빨간 점선)의 값에 대한 그래프이며 CV를 최소로 하는 \\(h\\)의 값은 \\(0.6157895\\)이다. 오른쪽 그래프는 유효 자유도 (Effective Degrees of Freedom) \\(\\nu\\)에 대한 CV(검정 점선)과 GCV(빨간 점선)의 그래프이다.\n\npar(mfrow=c(1,1))\ngrid = seq(min(age.female),max(age.female),length=100)\nm.hat = kernel(age.female,density.female,grid,h)\nplot(age.female,density.female,xlab=\"Age\",ylab=\"Density\")\nlines(grid,m.hat,lwd=3,col=\"blue\")\n\n\n\n\n\n\n\n\n위의 그래프는 선택된 \\(h=0.6157895\\)을 이용하여 추정한 반응변수 density 의 커널회귀 함수 \\(\\hat m(x)\\) 이다.\n\n\n8.2.4 붓스트랩 신뢰 구간\n다음 프로그램은 붓스트랩(Bootstrap)을 이용하여 주어진 \\(x\\)값에서 추정량 \\(\\hat m(x)\\)의 표준오차 \\(SE(x)\\)를 구하는 프로그램이다.\n\nboot = function(x,y,grid,h,B){\n  ### pointwise standard error for kernel regression using the bootstrap\n  k = length(grid)\n  n = length(x)\n  M = matrix(0,k,B)\n  for(j in 1:B){\n    I = sample(1:n,size=n,replace=TRUE)\n    xx = x[I]\n    yy = y[I]\n    M[,j] = kernel(xx,yy,grid,h)\n  }\n  s = sqrt(apply(M,1,var))\n  return(s)\n}\n\n아래는 추정량 \\(\\hat m(x)\\)의 95% 신뢰구간을 구하는 프로그램이다. 붓스트랩의 반복수는 \\(B=1000\\)이다.\n\\[ CI(x) = [\\hat m(x) - 2 SE(x) ,  \\hat m(x) + 2 SE(x) ] \\]\n\npar(mfrow=c(1,1))\nh = .7\ngrid = seq(min(age.female),max(age.female),length=100)\nplot(age.female,density.female)\nmhat = kernel(age.female,density.female,grid,h)\nlines(grid,mhat,lwd=3)\nB = 1000\nse = boot(age.female,density.female,grid,h,B)\nlines(grid,mhat+2*se,lwd=3,lty=2,col=\"red\")\nlines(grid,mhat-2*se,lwd=3,lty=2,col=\"red\")",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>국소 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/spline-02.html#함수의-기저",
    "href": "notes/spline-02.html#함수의-기저",
    "title": "9  스플라인 회귀모형",
    "section": "9.1 함수의 기저",
    "text": "9.1 함수의 기저\n반응변수 \\(Y\\)와 설명변수 \\(X\\)가 다음과 같은 관계를 가진다고 하자.\n\\[ E(Y|X=x) = m(x)  \\]\n이러한 관계를 회귀모형(regression model)이라고 하며 \\(Y\\)의 평균이 \\(X\\)에 따라서 변하는 괸계를 설정하는 모형이다. 만약 \\(m(x)\\)의 형태를 회귀계수의 선형식으로 나타낼 수 있다면 우리는 이를 선형회귀모형(linear regression model)이라고 한다.\n\\[ m(x) = a+b_1 x_1 + b_2 x_2 + \\dots + b_p x_p \\]\n설명변수는 고정된 값이거나 또는 확률변수일 수도 있다.\n비모수 회귀모형(nonparametric regression model)에서는 \\(m(x)\\)의 형태에 특별한 제한을 두지 않는다. 따라서 함수 \\(m(x)\\)는 무수히 많고 다양한 형태를 가질 수 있다.\n이제 설명변수의 수가 1개라고 가정하면 함수 \\(m(x)\\)를 가장 단순하게 표현할 수 있는 모형이 1차 회귀모형이다.\n\\[ y = a + b x + e \\]\n만약 반응변수와 설명변수의 관계가 선형이 아니라 비선형이라면 \\(m(x)\\)를 \\(p\\)-차 다항식으로 사용할 수 있다.\n\\[\nm(x)  = a + b_1 x + b_2 x^2 + \\dots + b_p x^p\n\\tag{9.1}\\]\n이렇게 \\(m(x)\\)를 다항식으로 표현하는 것은 우리가 알 수 없는 함수를 \\(p+1\\)개의 기저들(basis), 즉 \\(1\\), \\(x\\), \\(x^2\\), ..,\\(x^p\\)의 선형조합으로 근사하는 것이며 다항식의 경우는 각 기저 \\(N_k(x)\\) 는 설명변수의 \\(k\\)-차 항 \\(x^k\\)이다.\n\\[\n\\beta_0 N_0(x) + \\beta_1 N_1(x) + \\beta_2 N_2(x) + \\dots + \\beta_p N_p(x)\n\\tag{9.2}\\]\n일반적으로 임의의 함수는 다양한 형태의 기저들로 표현할 수 있으며 기저들의 형태에 따라 다음과 같은 것들이 있다.\n\n다항식(polynimials)\n퓨리에 함수(Fourier series)\n웨이블릿 함수(Wavelet series )",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>스플라인 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/spline-02.html#직선-스플라인linear-spline",
    "href": "notes/spline-02.html#직선-스플라인linear-spline",
    "title": "9  스플라인 회귀모형",
    "section": "9.2 직선 스플라인(Linear Spline)",
    "text": "9.2 직선 스플라인(Linear Spline)\n이제 \\(n\\)개의 자료 \\((y_1,x_1),(y_2,x_2),\\dots,(y_n,x_n)\\)이 주어졌다고 하자. 편의상 설명변수 \\(x\\)가 구간 \\((0,1)\\)의 값이라고 가정한다. 설명변수들이 포함되는 구간 \\((0, 1)\\)를 \\(K+1\\)개의 구간 \\(\\{B_j =(\\xi_{k-1}, \\xi_k) | k=1,2,..,K+1 \\}\\) 으로 나누어 보자. 즉\n\\[ \\xi_0 = 0 &lt; \\xi_1 &lt; \\xi_2 &lt; \\dots &lt;  \\xi_{K-1} &lt; \\xi_K &lt; 1 = \\xi_{K+1} \\]\n위의 구간에서 \\(K\\)개의 내부점들 \\(\\xi_1 &lt; \\xi_2 &lt; \\dots &lt; \\xi_{K-1} &lt; \\xi_K\\)은 일반적으로 knots(연결점)이라고 부른다,\n이제 반응변수들의 평균 \\(E(Y|x)\\) 을 단순하게 각 구간에서 상수라고 가정하면\n\\[ E(Y|x) = a_k \\quad \\text{ if } x \\in B_k \\]\n각 구간에 속하는 반응변수들의 평균으로 추정할 수 있다. 이러한 추정법을 우리는 전 강의에서 Regressogram이라고 하였다.\n\\[\n\\hat E(Y|x) =\n\\frac{1}{n_k} \\sum_{i=1}^n y_i I_{B_k}(x_i) \\quad \\text{ if } x \\in B_k\n\\tag{9.3}\\]\n\n\n연결점에서의 연속과 절단다항함수\n\n\n\n이제 Regeressogram의 개념을 확장시켜서 각 구간의 회귀모형을 직선식으로 확장하여 보자. 즉\n\\[\nE(Y|x) = a_k + b_k x \\quad \\text{ if } x \\in B_k\n\\tag{9.4}\\]\n모형 식 9.4 는 각 구간마다 회귀직선을 적합하는 것과 같은 모형이다. 이러한 모형에서 추정된 각 회귀식들은 각 구간의 연결점 \\(\\xi_1, \\xi_2, \\dots, \\xi_{K}\\) 에서 불연속이다. 각 연결점 \\(\\xi_k\\)에서 연속인 회귀식들을 구할 수 있을까?\n이제 구간 \\((0,1)\\)을 다음과 같이 \\(K+1=3\\)개의 구간으로 나누어 보자. 이 경우 연결점은 \\(\\xi_1\\)과 \\(\\xi_2\\), 두 개가 있다.\n\\[  B_1 =(0, \\xi_1) \\quad B_2 = (\\xi_1, \\xi_2) \\quad B_3 = (\\xi_2,1) \\]\n모형 식 9.4 에서 주어진 회귀계수는 모두 \\(2(K+1)=6\\) 개이며 추정값을 구하는 방법은 다음과 같은 오차제곱합을 구하는 최소제곱법을 사용할 수 있다.\n\\[\nSSE = \\sum_{x_i \\in B_1} (y_i - a_1 -b_1 x_i)^2 + \\sum_{x_i \\in B_2} (y_i - a_2 -b_2 x_i)^2 + \\sum_{x_i \\in B_3} (y_i - a_3 -b_3 x_i)^2\n\\tag{9.5}\\]\n이제 모형 식 9.4 에서 구한 직선회귀식이 연결점 \\(\\xi_1\\)과 \\(\\xi_2\\)에서 연속이 되려면 다음과 같은 두 조건을 만족해야 한다. \\[\na_1 + b_1 \\xi_1 = a_2 + b_2 \\xi_1, \\quad a_2 + b_2 \\xi_2 = a_3 + b_3 \\xi_2\n\\tag{9.6}\\]\n각 연결점의 연속을 만족하려면 위의 두 식을 만족해야 하므로 이제 추정해야 하는 모수의 개수는 4개이다. 왜냐하면 원래의 회귀계수의 개수 6 에서 제약식 2개의 개수를 제외해야 하기 떄문이다.\n제약 식 9.6 을 다시 쓰면 다음과 같이 쓸수 있으며 \\[\n\\begin{aligned}\na_2 & = a_1  + (b_1 - b_2) \\xi_1 \\\\\na_3 & = a_2 + (b_2 - b_3 ) \\xi_2 \\\\\n  & = a_1  + (b_1 - b_2) \\xi_1  + (b_2 - b_3 ) \\xi_2\n\\end{aligned}\n\\]\n이 제약식을 이용하여 오차제곱합 식 9.5 에서 두 번째 항과 세 번째 항을 다음과 같이 전개할 수 있다\n\\[\n\\begin{aligned}\n\\sum_{x_i \\in B_2} (y_i - a_2 -b_2 x_i)^2  & = \\sum_{x_i \\in B_2} (y_i - a_1  - (b_1 - b_2) \\xi_1 -b_2 x_i)^2 \\\\\n& =  \\sum_{x_i \\in B_2} [y_i - a_1  - b_1 \\xi_1 -b_2 (x_i - \\xi_1)]^2 \\\\\n& =\\sum_{x_i \\in B_2} [y_i - a_1  - b_1 x_i  -(b_2-b_1) (x_i - \\xi_1)]^2 \\\\\n\\sum_{x_i \\in B_3} (y_i - a_3 -b_3 x_i)^2\n& = \\sum_{x_i \\in B_3} (y_i - a_1  - (b_1 - b_2) \\xi_1 - (b_2 - b_3 ) \\xi_2  -b_3 x_i)^2 \\\\\n& =\\sum_{x_i \\in B_3} [y_i - a_1  - b_1 \\xi_1  +b_2 \\xi_1  -  b_2  \\xi_2  -b_3( x_i - \\xi_2) ]^2 \\\\\n& =\\sum_{x_i \\in B_3} [y_i - a_1  - b_1 x_i + b_1 x_i   - b_1 \\xi_1  +b_2 \\xi_1  -  b_2  \\xi_2 -b_3( x_i - \\xi_2) ]^2  \\\\\n& =\\sum_{x_i \\in B_3} [y_i - a_1  - b_1 x_i + b_1 (x_i - \\xi_1)  +b_2 (\\xi_1 -x_i + x_i)  -  b_2  \\xi_2 -b_3( x_i - \\xi_2) ]^2  \\\\\n&= \\sum_{x_i \\in B_3} [y_i - a_1  - b_1 x_i - (b_2 -b_1) (x_i - \\xi_1)  -(b_3-b_2)( x_i - \\xi_2) ]^2\n\\end{aligned}\n\\]\n위의 전개식에서 모수를 다음과 같이 다시 정의하면\n\\[  \\beta_0 = a_1, \\quad \\beta_1 = b_1, \\quad \\beta_2 =b_2-b_2 , \\quad \\beta_3 = b_3 - b_2 \\]\n오차제곱합 SSE는 다음과 같이 전개할 수 있다.\n\\[\n\\begin{aligned}\nSSE &  = \\sum_{x_i \\in B_1} (y_i -\\beta_0 -\\beta_1 x_i)^2 + \\sum_{x_i \\in B_2} [y_i - \\beta_0  - \\beta_1 x_i  -\\beta_3 (x_i - \\xi_1)]^2  \\\\ \\notag\n& \\quad + \\sum_{x_i \\in B_3} [y_i - \\beta_0  - \\beta_1 x_i - \\beta_2 (x_i - \\xi_1)  -\\beta_3 ( x_i - \\xi_2) ]^2  \n\\end{aligned}\n\\tag{9.7}\\]\n식 9.7 에서 얻은 오차제곱합은 다음과 같은 회귀모형을 적합한 경우에 얻을 수 있는 오차제곱합이다.\n\\[\nE(y|x)  = \\beta_0 + \\beta_1 x + \\beta_2 (x-\\xi_1)_{+} + \\beta_3 (x-\\xi_2)_{+}\n\\tag{9.8}\\]\n위의 식에서 함수 \\((x)_{+}\\) 는 다음과 같이 정의된 함수이다. \\[\n(x)_{+} =\n\\begin{cases}\nx & \\text{ if } x \\ge 0 \\\\\n0 & \\text{ if } x &lt; 0\n\\end{cases}\n\\]\n이제 연결점(knots)에서 연속인 조건을 만족하는 직선들을 추정하는 문제는 식 9.8 에 주어진 회귀식을 추정하는 문제와 같음을 보였다. 즉, 주어진 구간에서 서로 연결되는 최적의 직선식을 구하는 문제는 함수를 다음과 같은 기저로 조합된 것으로 보고 최적의 계수를 구하는 것과 동일한 문제이다.\n\\[ N_0(x) = 1, \\quad N_1(x) =x, \\quad N_2(x) = (x-\\xi_1)_{+}, \\quad N_3(x) =(x-\\xi_2)_{+}  \\]\n위의 기저의 특징은 일부 기저함수의 값이 주어진 구간의 전 \\(\\xi_1\\)과 \\(\\xi_2\\)에 의존한다는 것이다. 아래 그림은 연결점이 2개인 경우 4개의 기저를 나타내는 그림이다.\n\n\n직선스플라인 회귀에서 4개의 기저\n\n\n\n이제 위의 문제에서 만약 \\(K+1\\)개의 구간이 있다면 원래 회귀계수의 개수 \\(2(K+1)\\)에서 제약식의 수 \\(K\\)를 제외한 총 \\(K+2\\) 개의 기저가 필요하며 다음과 같다.\n\\[ N_0(x) = 1, \\quad N_1(x) =x, \\quad N_k(x) = (x-\\xi_k)_{+}, k=1,2,\\dots,K  \\]\n\n\n3차 스플라인의 조건\n\n\n\n\n\n3차 스플라인 기저 함수",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>스플라인 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/spline-02.html#스플라인-회귀",
    "href": "notes/spline-02.html#스플라인-회귀",
    "title": "9  스플라인 회귀모형",
    "section": "9.3 스플라인 회귀",
    "text": "9.3 스플라인 회귀\n이제 주어진 구간에서 직선식이 아닌 \\(p\\)-차 다항식 식 9.1 을 고려하자. \\(K+1\\)개의 구간에서 \\(p\\)-차 다항식이 매유 부드럽게 연결되기 위한 조건은 연결점들에서 연속이며 더 나아가 \\(1,2,..,p-1\\)차의 미분값이 동일한 것이다. 이러한 조건을 만족하는 최적의 \\(p\\)-차 다항식을 구하는 문제는 다음과 같은 \\(K+p+1\\)개의 기저로 표현된 함수식에서 최적의 함수를 구하는 문제와 같다. 아래의 기저들을 절단된 다항함수(truncated power) 기저라고 부른다.\n\\[\n\\begin{aligned}\nN_j (x)  & =   x^j, \\quad j=0,1,2,\\dots, p \\\\ \\notag\nN_{p+k} (x) & =  (x-\\xi_k)^p_{+}, \\quad  k=1,2,\\dots, K\n\\end{aligned}\n\\tag{9.9}\\]\n위와 같은 스플라인 회귀에서 가장 자주 사용되는 것은 3차 스플라인 회귀(Cubic spline, \\(p=3\\))이다. 각 연결점에서 연속이고 1차와 2차 마분값이 같은 조건을 주고 각 구간에서 다항식을 구하는 것이다. 이때 구간의 하한과 상한, 즉 경계점(boundary)에서 직선의 성질을 가지는 조건, 즉 \\[\nm''(0)=m'''(0) =0, \\quad m''(1) = m'''(1) =0\n\\tag{9.10}\\]\n을 만족하는 스플라인을 자연 스플라인(natural spline)이리고 부르며 가장 자주 사용된다.\n예제로서 다음과 같은 모형에서 생성된 자료를 가지고 자연 스플라인을 적합해 보자.\n\\[ y_i = 3 \\sin(8x_i)  + e_i,\\quad e_i \\sim N(0,(0.3)^2) \\]\n다음은 100개의 자료를 가지고 2개의 연결점 \\(\\xi_1=0.2\\)와 \\(\\xi_2 = 0.6\\)을 이용한 3차 스플라인 함수를 적합하고 그리는 프로그램이다.\n\nn = 100\nx = runif(n)\nx.grid = seq(0,1,length.out = 100)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfit = lm(y ~ ns(x,knots = c(0.2,0.6)) )\nplot(x,y,pch=20)\npred  = predict(fit,newdata=list(x=x.grid))\nlines(x.grid, pred,col=\"red\")\nabline(v=c(0.2,0.6), col = 'blue')\n\n\n\n\n\n\n\n\n다음 프로그램에서는 연결점을 자동으로 선택하고 차수를 3차(자유도=3)로 사용하는 방법이다.\n\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfit = lm(y ~ ns(x,df=3) )\nsummary(fit)\n\n\nCall:\nlm(formula = y ~ ns(x, df = 3))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6346 -0.7204  0.1997  0.8190  1.7707 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.8921     0.4312   6.707 1.37e-09 ***\nns(x, df = 3)1  -7.3537     0.4592 -16.013  &lt; 2e-16 ***\nns(x, df = 3)2  -1.7793     1.1068  -1.608    0.111    \nns(x, df = 3)3   3.4791     0.3969   8.766 6.63e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.083 on 96 degrees of freedom\nMultiple R-squared:  0.7604,    Adjusted R-squared:  0.7529 \nF-statistic: 101.5 on 3 and 96 DF,  p-value: &lt; 2.2e-16\n\nplot(x,y,pch=20)\npred  = predict(fit,newdata=list(x=x.grid))\nlines(x.grid, pred,col=\"red\")\n\n\n\n\n\n\n\n\n다음 프로그램에서는 25개의 연결점을 선택하고 차수를 3차(자유도=3)로 사용하는 방법이다. 과적합(overfitting)이 발생하였다.\n\nkknots=seq(0+0.1,1-0.1,len=25)\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfit = lm(y ~ ns(x,df=3,knots = kknots ))\nplot(x,y,pch=20)\npred  = predict(fit,newdata=list(x=x.grid))\nlines(x.grid, pred,col=\"red\")",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>스플라인 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/spline-02.html#평활-스플라인",
    "href": "notes/spline-02.html#평활-스플라인",
    "title": "9  스플라인 회귀모형",
    "section": "9.4 평활 스플라인",
    "text": "9.4 평활 스플라인\n스플라인 회귀에서 추정된 평균 함수 \\(\\hat m(x)\\)의 부드러움(smoothness)는 연결점의 수 \\(K\\)와 기저함수의 차수 \\(p\\)로 결정된다. 일반적으로 기저함수의 차수는 3차를 사용하는 자연 3차 스플라인 회귀식을 사용하며 고차식을 사용해도 큰 차이가 나지 않는다. 따라서 추정된 평균함수의 부드러움을 결정하는 중요한 요소는 연결점의 수이다.\n연결점의 수가 너무 적으면 너무 부드러워서 전체경향을 파악하기 힘들고(large bias, small variance) 반면에 너무 많으면 과적합(over fitting, small bias, large variance)이 된다.\n평활 스플라인(smoothing sapline)은 자료의 모든 점을 연결점으로 하면서 동시에 부드러움을 조절하는 방법이다. 이제 \\(E(y|x)\\)를 추정하는 함수 \\(f(x)\\)에 대한 벌칙항을 포함한 오차제곱합(residual sum of squares with penalty term)을 고려하자.\n\\[\nSSE(f, \\lambda) = \\sum_{i=1}^n (y_i - f(x_i))^2 + \\lambda \\int [f''(x)]^2 dx\n\\tag{9.11}\\]\n위의 식에서 \\(f''(x)\\)는 함수 \\(f(x)\\)의 이차 미분이다. 따라서 고려하는 함수 \\(f(x)\\)는 두 번 미분이 가능한 함수이다. 벌칙항을 포함한 오차제곱합에서 첫번째 항은 자료에 얼마나 가까운지를 측정하는 양이며 두 번째 항은 함수의 부드어운 정도를 측정하는 양이다.\n식 9.11 에서 \\(\\lambda \\in (0,\\infty)\\)는 평활 모수(smoothing parameter)라고 부르며 스플라인 추정 함수의 부드러움을 조절해 주는 모수이다.\n\n\\(\\lambda=0\\): 이 경우는 식 9.11 가 일반적인 오차제곱함과 같다. 따라서 함수 \\(f(x)\\)는 제약이 없다면 각 자료의 점들을 이어주는 아주 매우 거칠은 모양의 함수를 추정치로 얻게 된다.\n\\(\\lambda =\\infty\\): 이 경우는 \\(f(x)\\)가 가장 단순한(부드러운) 직선식으로 주어진다. 왜냐하면 직선식의 이차미분은 0이기 때문이다.\n\n벌칙항을 포함한 오차제곱합 식 9.11 를 최소로 하는 함수는 자료의 점 \\((x_i, y_i)\\)를 지나는, 즉 \\(n\\)개의 연결점을 자기는 자연 3차 스플라인이다. 따라서 모수는 모두 \\(n\\)개이며 평활 모수의 값에 따라 계수들이 변한다.\n이제 식 9.11 를 최소로 하는 함수를 다음과 같이 자연 3차 스플라인의 기저 \\(N_i(x), i=0,1,2,\\dots,n-1\\)와 대응하는 계수 \\(\\beta_i\\)로 다음과 같이 나타내어 보자.\n\\[\ny_i = \\sum_{i=0}^{n-1} \\beta_i N_i(x)\n\\]\n그러면 벌칙항을 포함한 오차제곱합 식 9.11 를 다음과 같이 벡터식으로 나타낼 수 있다.\n\\[\nSSE(f, \\lambda) = ( \\pmb y -\\pmb N \\pmb \\beta)^t (\\pmb y -\\pmb N \\pmb \\beta)) + \\lambda \\pmb \\beta^t \\pmb \\Omega_n \\pmb \\beta\n\\tag{9.12}\\]\n위의 식 에서 \\(\\pmb y\\), \\(\\pmb N\\), \\(\\pmb \\beta\\), \\(\\pmb \\Omega\\)는 다음과 같이 정의된다.\n\\[\n\\pmb y =\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n\\quad\n\\pmb N =\n\\begin{bmatrix}\nN_0(x_1) & N_1(x_1) & \\cdots & N_{n-1}(x_1) \\\\\nN_0(x_2) & N_1(x_2) & \\cdots & N_{n-1}(x_2) \\\\\n\\vdots & \\vdots & \\cdots & \\vdots \\\\\nN_0(x_n) & N_1(x_n) & \\cdots & N_{n-1}(x_n) \\\\\n\\end{bmatrix}\n\\quad\n\\pmb \\beta =\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_{n-1}\n\\end{bmatrix}\n\\]\n\\[\n\\pmb \\Omega = \\{\\omega_{ij} \\} \\text{ where }\n\\omega_{ij} = \\int N_{i}^{''} (t) N_{j}^{''} (t) dt\n\\]\n벌칙항이 있는 오차제곱합 식 9.12 를 최소화하는 추정량 \\(\\hat {\\pmb \\beta}\\)는 다음과 같이 주어진다.\n\\[\n\\hat {\\pmb \\beta} =  (\\pmb N^t \\pmb N + \\lambda \\pmb \\Omega)^{-1} {\\pmb N}^t {\\pmb y}\n\\]\n그리고 반응변수들에 대한 예측치 \\(\\hat {\\pmb y}\\)는 다음과 같이 반응변수 벡터 \\(\\pmb y\\)의 선형식으로 나타난다.\n\\[\n\\hat {\\pmb y} =  \\pmb N (\\pmb N^t \\pmb N + \\lambda \\pmb \\Omega)^{-1} \\pmb N^t \\pmb y =\\pmb S_\\lambda {\\pmb y}\n\\]\n위의 식에서 \\(\\pmb S_\\lambda\\)는 \\(n \\times n\\) 의 행렬이며 평활행렬(smoothing matrix)라고 부른다.\n또한 평활행렬 \\(\\pmb S_\\lambda\\)의 대각원소의 합을 유효 자유도(effective degrees of freedom)이라고 부른다.\n\\[ df_\\lambda = trace ({\\pmb S}_\\lambda) \\]\n유효 자유도는 일반 선형모형에서 나타나는 독립변수의 개수를 확장한 개념이다. 다음과 같은 일반선형모형에서\n\\[ \\pmb y = \\pmb X \\pmb \\beta + \\pmb e \\]\n계획행렬 \\(\\pmb X\\)의 열의 개수는 상수항을 포함한 독립변수의 개수 \\(p+1\\)이다. 이 때 반응변수에 대한 예측은 반응변수 벡터 \\(\\pmb y\\)의 선형변환으로 나타나며\n\\[ \\hat {\\pmb y} = \\pmb X (\\pmb X^t \\pmb X)^{-1} \\pmb X^t \\pmb y =\\pmb H {\\pmb y} \\]\n이때 사영행렬(projection matrix) \\(\\pmb H\\)의 대각합은 \\(p+1\\)이고 이는 반응변수의 평균을 추정할 때 필요한 자료의 크기이며 이를 자유도라고 한다.\n\\[ trace(\\pmb H) = trace[\\pmb X (\\pmb X^t \\pmb X)^{-1} \\pmb X^t] =\ntrace[ (\\pmb X^t \\pmb X)^{-1} \\pmb X^t \\pmb X] = trace(\\pmb I_{p+1})=p+1 \\]\n참고로 일반 선형모형에서 오차의 분산 \\(\\sigma^2\\)를 추정할 때 필요한 자유도는 전체 자료의 개수 \\(n\\)에서 반응변수의 평균을 추정할 때 필요한 자료의 개수 \\(p+1\\)를 뺀 \\(n-p-1\\)이다.\n스플라인 회귀에서 정의된 유효 자유도는 일반 선형모형에서 사용된 사영행렬 \\(\\pmb H\\) 의 대각합을 일반화한 개념이다. 일반 선형모형에서는 자유도, 즉 사영행렬의 대각합은 상수항을 포함한 독립변수의 개수 \\(p+1\\)이 된다. 스플라인 회귀와 같은 비모수회귀에서는 평활행렬 \\(\\pmb S_\\lambda\\) 의 대각합을 유효 자유도라고 일반화한 것이다. 따라서 유효 자유도는 정확하게 독립변수의 개수를 나타내는 것이 아니지만 반응변수의 평균을 추정할 떄 사용되는 모수(계수)의 개수로 해석할 수 있다.\n예를 들어 3차 스플라인(cubic spline)을 고려하고 연결점을 \\(K\\)개를 사용하면 총 \\(K+3+1=K+4\\)개의 기저가 필요하다. 더 나아가 자연 3차 스플라인은 식 9.10 에서 주어진 4개의 제약조건때문에 전체적으로 \\(K\\)개의 모르는 모수가 필요하다고 할 수 있다. 따라서 자연 3차 스플라인의 유효 자유도는 \\(K\\)개이다.\n다음 프로그램은 R 에서 평활 스플라인을 적합하는 방법이다. 유효 자유도를 5로 사용한 예이다.\n\nn = 100\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfitsm5 = smooth.spline(y ~ x, all.knots=T, cv=T, df=5)\nfitsm5\n\nCall:\nsmooth.spline(x = y ~ x, df = 5, cv = T, all.knots = T)\n\nSmoothing Parameter  spar= 1.071293  lambda= 0.006166073 (13 iterations)\nEquivalent Degrees of Freedom (Df): 4.999474\nPenalized Criterion (RSS): 28.35393\nPRESS(l.o.o. CV): 0.3245808\n\nplot(x,y,pch=20)\nlines(fitsm5,col=\"red\")\n\n\n\n\n\n\n\n\n유효 자유도를 증가시키면 추정된 평활곡선은 다음과 같이 나타난다.\n\npar(mfrow = c(2,2))\nn = 100\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfitsm15= smooth.spline(y ~ x, all.knots=T, cv=T, df=15)\nfitsm50= smooth.spline(y ~ x, all.knots=T, cv=T, df=50)\nfitsm70= smooth.spline(y ~ x, all.knots=T, cv=T, df=70)\nplot(x,y,pch=20, cex=0.6)\ntitle(\"effective degress of freedom = 5\")\nlines(fitsm5,col=\"red\")\nplot(x,y,pch=20, cex=0.6)\ntitle(\"effective degress of freedom = 15\")\nlines(fitsm15,col=\"red\")\nplot(x,y,pch=20, cex=0.6)\ntitle(\"effective degress of freedom = 50\")\nlines(fitsm50,col=\"red\")\nplot(x,y,pch=20, cex=0.6)\ntitle(\"effective degress of freedom = 70\")\nlines(fitsm70,col=\"red\")\n\n\n\n\n\n\n\n\n만약 유효 자유도를 지정해주지 않으며 CV를 최소화해주는 자유도를 구하여 자동으로 스플라인함수를 추정해준다. 아래에서 구해진 평활모수는 \\(\\lambda = 0.000208\\) 이고 자유도는 \\(df = 10.15446\\)이다.\n\npar(mfrow = c(1,1))\nn = 100\nx = runif(n)\ny = 3*sin(8*x) + rnorm(n,0,.3)\nfitsmauto= smooth.spline(y ~ x, all.knots=T, cv=T)\nfitsmauto\n\nCall:\nsmooth.spline(x = y ~ x, cv = T, all.knots = T)\n\nSmoothing Parameter  spar= 0.867106  lambda= 0.0001764013 (14 iterations)\nEquivalent Degrees of Freedom (Df): 10.572\nPenalized Criterion (RSS): 8.976152\nPRESS(l.o.o. CV): 0.1138647\n\nplot(x,y,pch=20, cex=0.6)\nlines(fitsmauto,col=\"red\")",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>스플라인 회귀모형</span>"
    ]
  },
  {
    "objectID": "notes/survival-01.html#생존함수와-위험함수",
    "href": "notes/survival-01.html#생존함수와-위험함수",
    "title": "10  생존함수와 위험함수",
    "section": "10.1 생존함수와 위험함수",
    "text": "10.1 생존함수와 위험함수\n확률변수 \\(T\\)를 생존시간이라고 하고 \\(f(t)\\)를 확률밀도함수라고 하자. \\(T\\)의 누적분포함수(cumulative distribution function; CDF)는 다음과 같이 정의된다.\n\\[ F(t) = P(T \\le t) = \\int_0^t f(t) dt \\]\n또한 생존함수(Survival function)은 다음과 같이 정의된다.\n\\[ S(t) = P (T &gt; t) = 1-F(t) \\]\n위험함수(hazrd function)의 정의는 다음과 같으며 만약 생존시간이 \\(t\\) 보다 클때 바로 사망할 확률을 의미하며 순간위험율(instantaneous failure rate)이다.\n\\[\n\\begin{aligned}\nh(t) & = \\lim_{dt \\rightarrow 0} \\frac{ P(t &lt; T \\le t+ dt | T &gt; t) }{dt} \\\\ \\notag\n      & = \\lim_{dt \\rightarrow 0} \\frac{1}{dt} \\frac{P(P(t &lt; T \\le t+ dt )}{P(T &gt;t)} \\\\ \\notag\n     & = \\frac{f(t)}{S(t)}\n\\end{aligned}\n\\tag{10.1}\\]\n위험함수의 의미를 좀더 자세히 알아보자.\n\n위험함수는 아주 짧은 시간에 일아날 사건의 확률로서 순간적인(instantaneous)인 의미를 가진다. 정의에서 보듯이 아주 짧은 시간에 일어나는 극한(\\(lim_{dt \\rightarrow 0}\\))의 의미이다.\n위험함수는 확률로서 정의되지만 발생율(rate)로 이해할 수 있다. 위험함수를 정의에서 분모는 확률이고 분자는 시간으로 표시되기 때문에 마차 단위 시간당 일어나는 발생율로 이해할 수 있다. 또한 위험함수의 값은 [0,1] 사이에 있는 것이 아니기 때문에 단위 시간당 발생율로 이해하는 것이 편리하다 (\\(h(t) \\ge 0\\)).\n위험함수는 조건부 확률로 정의되어 있다. 즉, 모든 개체에 대한 사건이 아니라 시간 \\(t\\)까지 살아있는 개체들에 대한 위험율이다.\n생존분석에서는 생존함수보다 위험함수가 더 큰 의미를 가진다. 위험함수가 시간에 따라서 변하는 추세는 시간에 따른 위험의 변화를 나타내기 때문에 생존함수보다 위험의 변화에 대한 정보를 잘 파악할 수 있다.\n\n\n\n위험함수와 생존함수의 관계\n\n\n\n생존함수와 위험함수는 다음과 같은 관계를 가지고 있다.\n\\[\n\\begin{aligned}\nh(t) & = \\frac{f(t)}{S(t)} \\\\\n  & = \\frac{f(t)}{1-F(t)} \\\\\n  & = - \\frac {\\partial}{\\partial t} \\log [1-F(t)] \\\\\n  & = - \\frac {\\partial}{\\partial t} \\log S(t)\n\\end{aligned}\n\\]\n따라서 다음의 관계가 성립힌다.\n\\[ S(t) = exp[-H(t)] \\] 여기서\n\\[ H(t) = \\int_0^t h(t) dt \\] 이며 \\(H(t)\\)를 누적 위험함수(cumulative hazard function)라고 한다.\n위의 식에서 볼 수 있듯이 위험함수를 알면 생존함수를 쉽게 구할 수 있고 또한 반대로 생존함수를 알면 위험함수를 자동적으로 알게된다.",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>생존함수와 위험함수</span>"
    ]
  },
  {
    "objectID": "notes/survival-01.html#위험함수의-형태",
    "href": "notes/survival-01.html#위험함수의-형태",
    "title": "10  생존함수와 위험함수",
    "section": "10.2 위험함수의 형태",
    "text": "10.2 위험함수의 형태\n앞에서 언급했듯이 위험함수는 시간에 따른 위험의 변화를 말해준다. 생존분석에서 중요한 분포들과 예제를 가지고 다양한 위험함수의 형태를 알아보자.\n만약 생존시간 \\(T\\)가 지수분포(Exponential distribution)을 따른다고 하자.\n\\[ f(t; \\lambda) = \\lambda e^{-\\lambda t} \\]\n위에서 \\(\\lambda\\) 는 흔히 단위시간 당 사망률, 실패율(failure rate)라고 부르며 \\(E(T) = 1/\\lambda\\)이다.\n생존함수(survaival function)와 위험함수(hazard function)은 다음과 같이 주어진다.\n\\[\n\\begin{aligned}\nS(t) & = P(T&gt;t)  = 1 - P(T \\le t) \\\\\n    & = 1 - \\int_0^t \\lambda e^{-\\lambda t} \\\\\n    & = 1 - (1-e^{-\\lambda t} ) \\\\\n    & = e^{-\\lambda t} \\\\\nh(t) & = \\frac{f(t)}{S(t)} \\\\\n    & = \\lambda e^{-\\lambda t}  / e^{-\\lambda t} \\\\\n    & = \\lambda\n\\end{aligned}\n\\]\n누적위험함수는 아래와 같다.\n\\[ H(t) = \\int_0^t h(t) dt = \\lambda t \\]\n생존시간이 지수분포를 따른다면 위험함수는 시간에 관계없이 상수 \\(\\lambda\\)이다. 이렇게 시간에 따라서 위험함수가 상수인 경우는 현실에서는 거의 나타나지 않는다. 위험함수가 상수라는 것은 시간이 지나도 (1) 제품이 고정날 또는 (2) 사람이 사망할 위험성이 변허지 않는다는 의미이다.\n지수분포는 생존분석에서 중요한 의미를 가진다. 즉, 생존시간이 지수분포를 따르면 개체는 얼마나 시간이 경과했는지 정보가 없다는 것이며 주어진 시각에 사건이 일어나지 않았다면 바로 다음 시간에 사건이 일어날 확률은 언제나 동일하다. \\(\\blacksquare\\)\n만약 생존시간이 와이블 분포(Weibull distribution)를 따른다면 확률밀도함수는 다음과 같다.\n\\[ f(t) = \\frac{\\lambda t^{\\lambda-1}}{\\theta^\\lambda}\n\\exp \\left[ - \\left(\\frac{t}{\\theta} \\right)^\\lambda \\right],\n\\quad \\theta,\\lambda&gt;0,  t \\geq 0.\n\\]\n평균은 \\(E(T)=\\theta \\Gamma(1+1/\\lambda)\\) 이다. 여기서 \\(\\lambda=1\\)이면 지수분포가 된다.\n이때 생존 함수는 다음과 같다.\n\\[\n\\begin{aligned}\n  S(t) &= 1-\\int_0^t \\frac{\\lambda t^{\\lambda-1}}{\\theta^\\lambda} \\exp \\left[\n- \\left( \\frac{t}{\\theta} \\right)^\\lambda  \\right] dt \\\\\n&= \\exp \\left[\n- \\left( \\frac{t}{\\theta} \\right)^\\lambda  \\right].\n\\end{aligned}\n\\]\n또한 위험함수는 다음과 같다.\n\\[\n\\begin{aligned}\nh(t) &= \\frac{f(t)}{S(t)} \\\\\n   &= \\frac{\\frac{\\lambda t^{\\lambda-1}}{\\theta^\\lambda} \\exp \\left[\n- \\left( \\frac{t}{\\theta} \\right)^\\lambda  \\right]}{\\exp \\left[\n- \\left( \\frac{t}{\\theta} \\right)^\\lambda  \\right]}  \\\\\n   &= \\left( \\frac{\\lambda }{\\theta^\\lambda} \\right) t^{\\lambda-1}.\n\\end{aligned}\n\\]\n위에서 볼 수 있듯이 \\(\\lambda=1\\)이면 지수분포가 되고 위험함수는 상수이다. 만약에 \\(\\lambda&gt;1\\)이면 위험함수는 시간에 따라 증가하며 \\(\\lambda&lt;1\\)이면 위험함수는 감소한다.\n누적위험함수는 아래와 같다. \\[ H(t) = \\int_0^t h(t) dt = (t/\\theta)^\\lambda \\]\n다음은 모수의 변화에 따른 와이블 분포의 위험함수이다.\n\nweibHaz &lt;- {function(x, shape, scale) dweibull(x, shape=shape,\n     scale=scale)/pweibull(x, shape=shape, scale=scale, lower.tail=F)}\ncurve(weibHaz(x, shape=1.5, scale=1/0.03), from=0, to=80, \n     ylab='Hazard', xlab='Time', col=\"blue\")\ncurve(weibHaz(x, shape=1.0, scale=1/0.03), from=0, to=80, \n     ylab='Hazard', xlab='Time', add=T, col=\"black\")\ncurve(weibHaz(x, shape=0.75, scale=1/0.03), from=0, to=80, \n     ylab='Hazard', xlab='Time', add=T, col=\"red\")\ntext(45, 0.065, expression(lambda == 1.50), col=\"red\", cex=1.3)\ntext(58, 0.065, expression(theta==1/0.03), col=\"red\", cex=1.3)\ntext(45, 0.015, expression(lambda == 0.75), col=\"blue\", cex=1.3)\ntext(58, 0.015, expression(theta==1/0.03), col=\"blue\", cex=1.3)\ntext(45, 0.034, expression(lambda== 1.00), col=\"black\", cex=1.3)\ntext(58, 0.034, expression(theta==1/0.03), col=\"black\", cex=1.3)\n\n\n\n\n\n\n\n\n다음 그림은 미국 여자와 남자의 연령에 따른 사망위험율을 나타내는 위험함수를 보여주는 그림이다. Y 축은 로그 스케일로 그린 그림이며 2004년의 자료를 이용하여 그린 그림이다. 태어난 날과 그 후 몇 주동안은 매우 사망위험이 높다가 급격하게 떨어진다. 그리고 10대에서 약간의 증가 현상을 보이며 조금 감쏘하다가 시간이 지날수록 위험율이 완만하게 증가한다. 주목할 점은 남자가 여자보다 사망의 위험이 언제나 크다는 것이며 이는 잘 알려진 사실이다.\n\ntm &lt;- c(0, # birth\n   1/365, # first day of life\n   7/365, # seventh day of life\n   28/365, # fourth week of life\n   1:107) # subsequent years\nhazMale &lt;- as.numeric(survexp.us[,\"male\",\"2004\"]) # 2004 males\nhazFemale &lt;- as.numeric(survexp.us[,\"female\",\"2004\"]) # 2004 females\ntm.diff &lt;- diff(tm)\nsurvMale &lt;- exp(-cumsum(hazMale*tm.diff)*365.24)\nsurvFemale &lt;- exp(-cumsum(hazFemale*tm.diff)*365.24)\n\n# Figure 2.1.2 log hazard and survival for US males and females in 2004\npar(mfrow=c(2,1),    # two rows and one column of plots\n    mar=c(4.2,5,2,2))  # set margins for the lower, left, top, and righ of each plot\n\nlogHazMale &lt;- log(hazMale)\nlogHazFemale &lt;- log(hazFemale)    \n\nplot(logHazMale ~ tm[-1], type=\"l\",\n     xlab=\"Age in years\",           # x axis label\n     ylab=\"Hazard\",col=\"blue\",      # y azis label\n     lwd=2,                         # double line width\n     las=1,                         # make y axis labels perpendicular to axis\n     axes=F, cex.lab=1.3, cex.axis=1.3)     # make blue line solid\nlines(logHazFemale ~ tm[-1],type=\"l\", \n      col=\"red\",lwd=2, lty=2)   # add a red dashed line to the plot\n\nyyLabs &lt;- c(1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02)\nyyLabsLog &lt;- log(yyLabs)\naxis(2, at=yyLabsLog, labels=c(expression(10^-7), expression(10^-6), \n  expression(10^-5), expression(10^-4), expression(10^-3), expression(10^-2)), las=1)  \naxis(1, cex.axis=1.3)   \nlegend(\"bottomright\", legend=c(\"males\",\"females\"),\n       lty=c(1,2), col=c(\"blue\",\"red\"), lwd=2, cex=1.3)\ntitle(\"Hazards for US males and females in 2004\")\n\ntm.diff &lt;- diff(tm)         # same length as \"tm\"\nsurvMale &lt;- exp(-cumsum(hazMale*tm.diff)*365.24)         # survival probs for males\nsurvFemale &lt;- exp(-cumsum(hazFemale*tm.diff)*365.24)     # survival probs for females\n#windows(width=7,height=5)\nplot(survMale ~ tm[-1],type=\"l\",          # lower case \"L\" indicates line plot\n     xlab=\"Age in years\",             # x axis label\n     ylab=\"Survival probability\",     # y azis label\n     col=\"blue\",                      # line color\n     lwd=2,                           # double line width\n     las=1,                           # make y axis labels perpendicular to axis\n     ylim=c(0,1), cex.lab=1.3, cex.axis=1.3)       # y axis limit ranges from 0 to 1\n\nlines(survFemale ~ tm[-1], col=\"red\", lwd=2, lty=2)    # add a red dashed line to the plot\nlegend(\"bottomleft\", legend=c(\"males\",\"females\"),\n       lty=c(1,2), col=c(\"blue\",\"red\"), lwd=2, cex=1.3)\ntitle(\"Survival of US males and females in 2004\")",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>생존함수와 위험함수</span>"
    ]
  },
  {
    "objectID": "notes/survival-01.html#평균-생존시간과-중위-생존시간",
    "href": "notes/survival-01.html#평균-생존시간과-중위-생존시간",
    "title": "10  생존함수와 위험함수",
    "section": "10.3 평균 생존시간과 중위 생존시간",
    "text": "10.3 평균 생존시간과 중위 생존시간\n평균 생존시간 \\(\\mu\\) 다은과 같이 정의된다.\n\\[ \\mu = \\int_{0}^\\infty t f(t) dt \\]\n잘 알려진 생존함수의 공식 \\(f(t) = dS(t)/dt\\)와 부분 적분 공식(integration by part)를 이용하면\n평균 생존시간 \\(\\mu\\) 다은과 같이 구할 수 있다.\n\\[ \\mu = \\int_0^\\infty S(t)dt \\] 중위 생존시간은 \\(t_{med}\\) 다음 방정식을 만족하는 \\(t\\)의 값이다.\n\\[ t_{med} = \\inf ~ \\{t~|~ S(t) \\le 1/2 \\} \\]",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>생존함수와 위험함수</span>"
    ]
  },
  {
    "objectID": "notes/survival-01.html#임의중도절단",
    "href": "notes/survival-01.html#임의중도절단",
    "title": "10  생존함수와 위험함수",
    "section": "10.4 임의중도절단",
    "text": "10.4 임의중도절단\n\n\n중도 절단 자료\n\n\n\n생존시간 \\(T_1, T_2, \\dots, T_n\\)을 독립적으로 분포 \\(f_\\theta(t)\\)에서 추출하였다고 가정하고 중도절단시간 \\(C_1, C_2, \\dots, C_n\\)도 독립적으로 분포 \\(g(c)\\)에서 추출하였다고 가정하자.\n생존시간 \\(T\\)와 중도절단시간 \\(C\\)가 서로 독립이라고 가정하며 이러한 가정을 임의 중도절단(random censoring)이라고 한다.\n이제 관측한 생존시간 \\(X_i\\)는 다음과 같이 정의한다.\n\\[ X_i = \\min (T_i, C_i) \\quad i=1,2,\\dots, n \\]\n또한 절단 표시변수 \\(\\delta_i\\)는 다음과 같이 정의한다. 표시변수 \\(\\delta_i\\) 가 1의 값을 가지면 실제 생존시간을 관측한 것이고 0이면 절단된 자료이다.\n\\[\n\\delta_i = \\begin{cases}\n1 & T_i &lt; C_i \\\\\n0 & T_i &gt; C_i\n\\end{cases}\n\\]\n따라서 중도절단이 있는 자료는 다음과 같은 각 개체에 대한여 쌍으로 구성된 관측값이 얻어진다.\n\\[ (X_1, \\delta_1), (X_2, \\delta_2), \\dots, (X_n, \\delta_n) \\]",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>생존함수와 위험함수</span>"
    ]
  },
  {
    "objectID": "notes/survival-01.html#모수의-최대가능도-추정",
    "href": "notes/survival-01.html#모수의-최대가능도-추정",
    "title": "10  생존함수와 위험함수",
    "section": "10.5 모수의 최대가능도 추정",
    "text": "10.5 모수의 최대가능도 추정\n이제 생존시간 \\(T\\)의 분포 \\(F_\\theta(t)\\) 가 주어졌을 때 표본 \\((x_i, \\delta_i)\\)의 가능도 함수 \\(L\\) 는 다음과 같이 나타낼 수 있다.\n\\[\nL(\\theta; x, \\delta) = \\prod_{i \\in UC} P_\\theta(T_i= x_i ) \\prod_{i \\in C} P_\\theta(T_i &gt; x_i ) = \\prod_{i \\in UC} f_\\theta( x_i ) \\prod_{i \\in C} [1-F_\\theta( x_i )]\n\\]\n여기서 집합 \\(UC\\)는 실제 생존시간이 관측된 자료들, 집합 \\(C\\)는 중도절단된 자료을 의미한다.\n모수의 최대가능도 추정은 \\(L(\\theta; X, \\delta)\\)를 최대로 하는 \\(\\theta\\)를 찾는 방법이다.\n이제 예제로서 생존시간의 분포가 지수분포를 따른다고 가정하고 가능도함수를 구해보자.\n\\[\n\\begin{aligned}\nL(\\lambda; x, \\delta) & = \\prod_{i \\in UC} P_\\lambda(T_i= x_i ) \\prod_{i \\in C} P_\\lambda(T_i &gt; x_i ) \\\\\n  & = \\prod_{i \\in UC} f_\\lambda( x_i ) \\prod_{i \\in C} [1-F_\\lambda( x_i )] \\\\\n  & = \\prod_{i=1}^n \\left [ \\lambda e^{-\\lambda x_i} \\right ]^{\\delta_i} \\left [e^{-\\lambda x_i} \\right ]^{1-\\delta_i} \\\\\n  & = \\prod_{i=1}^n \\lambda^{\\delta_i} e^{-\\lambda x_i} \\\\\n  & = \\lambda^{ \\sum_{i=1}^n \\delta_i} e^{-\\lambda \\sum_{i=1}^n x_i}\n\\end{aligned}\n\\]\n이제 위의 가능도함수를 최대화하는 모수를 찾기위하여 로그가능도함수를 고려하고\n\\[\n\\ell (\\lambda; x, \\delta) = \\log L(\\lambda; x, \\delta) =\n    \\log \\lambda \\sum_{i=1}^n \\delta_i - \\lambda \\sum_{i=1}^n x_i\n\\]\n로그가능도함수를 모수 \\(\\lambda\\)에 대하여 미분하고 0으로 놓고 풀면 최대가능도 추정량을 구할 수 있다.\n\\[\n\\frac{\\partial}{\\partial \\lambda} \\ell (\\lambda; x, \\delta) =\n     \\frac{\\sum_{i=1}^n \\delta_i}{\\lambda} - \\sum_{i=1}^n x_i = 0\n\\] 따라서 최대가능도 추정량은 다음과 같이 주어진다. \\[ \\hat \\lambda_{ML} = \\frac{\\sum_{i=1}^n \\delta_i}{\\sum_{i=1}^n x_i} \\]\n만약 중도절단자료가 없다면 최대가능도 추정량은 일반적인 경우와 같이 다음과 같다.\n\\[ \\hat \\lambda_{ML} = \\frac{n}{\\sum_{i=1}^n x_i} \\]",
    "crumbs": [
      "비모수 회귀모형",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>생존함수와 위험함수</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#필요한-패키지와-함수",
    "href": "notes/logistic_practice.html#필요한-패키지와-함수",
    "title": "11  로지스틱 회귀모형 실습 1",
    "section": "11.1 필요한 패키지와 함수",
    "text": "11.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nsource(\"../R/functions.R\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#분석-자료",
    "href": "notes/logistic_practice.html#분석-자료",
    "title": "11  로지스틱 회귀모형 실습 1",
    "section": "11.2 분석 자료",
    "text": "11.2 분석 자료\n로지스틱 회귀모형에 대한 분석은 교과서 Faraway (2016) 에서 사용된 wcgs 데이터프레임을 사용한다.\n데이터프레임 wcgs 은 Western Collaborative Group Study 에 참가한 3154명의 39-59 세 남성에 대한 신체 자료와 관상동맥질환(coronary heat disease)의 발병 여부에 대한 자료이다.\n\nhelp(wcgs)\n\n\nhead(wcgs)\n\n  age height weight sdp dbp chol behave cigs dibep chd  typechd timechd   arcus\n1  49     73    150 110  76  225     A2   25     A  no     none    1664  absent\n2  42     70    160 154  84  177     A2   20     A  no     none    3071 present\n3  42     69    160 110  78  181     B3    0     B  no     none    3071  absent\n4  41     68    152 124  78  132     B4   20     B  no     none    3064  absent\n5  59     70    150 144  86  255     B3   20     B yes infdeath    1885 present\n6  44     72    204 150  90  182     B4    0     B  no     none    3102  absent\n\n\n반응 변수는 chd 로서 만약 coronary heat disease 가 발생한 여부를 yes 와 no 로 표시한다.\n\nstr(wcgs)\n\n'data.frame':   3154 obs. of  13 variables:\n $ age    : int  49 42 42 41 59 44 44 40 43 42 ...\n $ height : int  73 70 69 68 70 72 72 71 72 70 ...\n $ weight : int  150 160 160 152 150 204 164 150 190 175 ...\n $ sdp    : int  110 154 110 124 144 150 130 138 146 132 ...\n $ dbp    : int  76 84 78 78 86 90 84 60 76 90 ...\n $ chol   : int  225 177 181 132 255 182 155 140 149 325 ...\n $ behave : Factor w/ 4 levels \"A1\",\"A2\",\"B3\",..: 2 2 3 4 3 4 4 2 3 2 ...\n $ cigs   : int  25 20 0 20 20 0 0 0 25 0 ...\n $ dibep  : Factor w/ 2 levels \"A\",\"B\": 1 1 2 2 2 2 2 1 2 1 ...\n $ chd    : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 2 1 1 1 1 1 ...\n $ typechd: Factor w/ 4 levels \"angina\",\"infdeath\",..: 3 3 3 3 2 3 3 3 3 3 ...\n $ timechd: int  1664 3071 3071 3064 1885 3102 3074 3071 3064 1032 ...\n $ arcus  : Factor w/ 2 levels \"absent\",\"present\": 1 2 1 1 2 1 1 1 1 2 ...\n\n\n이번 분석에서는 wcgs 자료에서 dibep 와 마지막 3개 변수를 제외하고 사용하겠다.\n\nwcgs_1 &lt;- wcgs %&gt;%\n  dplyr::select(!(typechd:arcus) ) %&gt;% dplyr::select(!dibep )\nhead(wcgs_1)\n\n  age height weight sdp dbp chol behave cigs chd\n1  49     73    150 110  76  225     A2   25  no\n2  42     70    160 154  84  177     A2   20  no\n3  42     69    160 110  78  181     B3    0  no\n4  41     68    152 124  78  132     B4   20  no\n5  59     70    150 144  86  255     B3   20 yes\n6  44     72    204 150  90  182     B4    0  no",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#로지스틱-회귀모형",
    "href": "notes/logistic_practice.html#로지스틱-회귀모형",
    "title": "11  로지스틱 회귀모형 실습 1",
    "section": "11.3 로지스틱 회귀모형",
    "text": "11.3 로지스틱 회귀모형\n이제 다음과 같이 개의 설명 변수가 포함된 로지스틱 회귀모형을 적합해 보자.\n\nfit_all &lt;- glm(chd ~ age +  height +  weight + sdp + dbp +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_all)\n\n\nCall:\nglm(formula = chd ~ age + height + weight + sdp + dbp + chol + \n    behave + cigs, family = binomial, data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -12.989034   2.336470  -5.559 2.71e-08 ***\nage           0.065068   0.012125   5.367 8.03e-08 ***\nheight        0.015824   0.033141   0.477  0.63302    \nweight        0.007874   0.003881   2.029  0.04248 *  \nsdp           0.017536   0.006395   2.742  0.00611 ** \ndbp           0.000121   0.010833   0.011  0.99109    \nchol          0.011076   0.001522   7.278 3.38e-13 ***\nbehaveA2      0.088266   0.222589   0.397  0.69171    \nbehaveB3     -0.602705   0.244216  -2.468  0.01359 *  \nbehaveB4     -0.499214   0.320978  -1.555  0.11988    \ncigs          0.020998   0.004280   4.906 9.32e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1580.4  on 3131  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1602.4\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n11.3.1 회귀계수의 의미\n위의 결과에서 회귀계수의 의미에 대하여 살펴보자. 먼저 하루에 평균 피우는 담배의 개수 cigs 의 의미는 다음과 같다.\n\nfit_all$coefficients['cigs']\n\n      cigs \n0.02099804 \n\n\n설명변수 cigs 의 계수가 0.020998 이므로 담배의 개수가 1개 증가하면 심장병 관련 질환의발생 확률이 다음과 같이 오즈비 단위로 증가 한다.\n아래 식에서 유의할 점은 다른 설명변수들은 모두 같다는 가정하에서 성립한다는 것이다.\n\\[ \\frac{\\text{odd(cigs = a+1)}}{\\text{odd(cigs = a)}} =\n\\frac{\\tfrac{P(\\text{chd =  y} | \\text{cigs = a+1})}{1- P(\\text{chd = y} | \\text{cigs = a+1} )}}\n{\\tfrac{P(\\text{chd = y} | \\text{cigs = a})}{1- P(\\text{chd = y} | \\text{cigs = a})}}= \\exp(0.020998) = 1.02122\n\\tag{11.1}\\]\n이제 좀 더 이해하기 쉬운 상대위험으로 회귀계수의 영향에 대하여 알아보자.\n먼저 연속형 변수들의 평균을 구하고 데이터프레임으로 만들자. 또한 범주형 변수인 behave 도 하나의 레벨을 추가하자.\n\nmean_vars &lt;- get_means(wcgs_1) %&gt;% t() %&gt;% as.data.frame()\nmean_vars$behave &lt;- 'A2'\nmean_vars\n\n       age   height   weight      sdp      dbp     chol     cigs behave\n1 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 11.60051     A2\n\n\n이제 데이터프레임 mean_vars 에서 주어진 설명변수의 값에서 성공의 확률을 예측해 보자\n\\[ \\hat P(y=1| \\pmb x) = \\frac{1}{1+\\exp(-[\\hat \\beta_0 + \\hat \\beta_1 x_1 + \\dots + \\hat \\beta_p x_p])} \\tag{11.2}\\]\n\npredict(fit_all, newdata=mean_vars, type = \"response\")\n\n         1 \n0.08085642 \n\n\n참고로 함수 prediction 은 선형예측식의 값만을 구할 수 있다.\n\\[ \\hat \\eta = \\hat \\beta_0 + \\hat \\beta_1 x_1 + \\dots + \\hat \\beta_p x_p \\]\n\npredict(fit_all, newdata=mean_vars, type = \"link\")\n\n        1 \n-2.430767 \n\n\n위에서 type = \"link\" 는 default 선택문이다.\n\npredict(fit_all, newdata=mean_vars)\n\n        1 \n-2.430767 \n\n\n확률로 바꿀려면 다음과 같이 식 11.2 을 이용하면 된다.\n\n1/(1+exp(-predict(fit_all, newdata=mean_vars, type = \"link\")))\n\n         1 \n0.08085642 \n\n\n위와 같이 계산은 logit 함수의 역함수인 ilogit 함수를 이용하여 구할 수 있다\n\nfaraway::ilogit(predict(fit_all, newdata=mean_vars, type = \"link\"))\n\n         1 \n0.08085642 \n\n\n이제 데이터프레임 mean_vars 의 두 번째 행에 cigs 가 1 증가한 관측값을 추가하자.\n\nsel_var &lt;- 'cigs'\nmean_vars_df &lt;- rbind(mean_vars,mean_vars)\nmean_vars_df[2,c(sel_var)] &lt;- mean_vars_df[2,c(sel_var)] + 1\nmean_vars_df\n\n       age   height   weight      sdp      dbp     chol     cigs behave\n1 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 11.60051     A2\n2 46.27869 69.77774 169.9537 128.6328 82.01554 226.3724 12.60051     A2\n\n\n다시 예측값을 구해보면 다음과 같다.\n\npre_p &lt;- predict(fit_all, newdata=mean_vars_df, type = \"response\")\npre_p\n\n         1          2 \n0.08085642 0.08243076 \n\n\n위의 결과로 오즈비를 구해보면 식 11.1 에 나타난 값과 같다.\n\n(pre_p[2]/(1-pre_p[2]))/(pre_p[1]/(1-pre_p[1]))\n\n      2 \n1.02122 \n\n\n이제 우리는 확률의 예측값을 계산할 수 있으므로 상대위험을 구해보면 다음과 같다.\n\npre_p[2]/pre_p[1]\n\n       2 \n1.019471 \n\n\n이제 age 도 비슷한 분석을 해보자. 나이는 30세와 60세의 상대위험을 계산해 보자.\n\nsel_var &lt;- 'age'\nmean_vars_df &lt;- rbind(mean_vars,mean_vars)\nmean_vars_df[1,c(sel_var)] &lt;- 30\nmean_vars_df[2,c(sel_var)] &lt;- 60\npre_p &lt;- predict(fit_all, newdata=mean_vars_df, type = \"response\")\npre_p[2]/pre_p[1]\n\n       2 \n5.974438 \n\n\n이제 범주형 변수에 대한 회귀계수의 의미를 살펴보자. 먼저 범주형변수 behave 가 가질 수 있는 범주를 보자.\n\nlevels(wcgs_1$behave)\n\n[1] \"A1\" \"A2\" \"B3\" \"B4\"\n\n\n또한 범주형변수 behave 에 관련된 회귀계수의 추정값을 보자.\n\ncoef1 &lt;- fit_all$coefficients \ncoef1\n\n  (Intercept)           age        height        weight           sdp \n-1.298903e+01  6.506806e-02  1.582390e-02  7.873538e-03  1.753588e-02 \n          dbp          chol      behaveA2      behaveB3      behaveB4 \n 1.209992e-04  1.107574e-02  8.826567e-02 -6.027047e-01 -4.992142e-01 \n         cigs \n 2.099804e-02 \n\n\n위의 결과에서 behave 의 A0 에 대한 게수의 값은 0이다. 즉 다음과 같은 식이 성립한다.\n\\[\n\\begin{aligned}\n\\text{logit} [ P(y=1 | \\text{behave = A0}) ] = \\cdots & + 0 + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = A2}) ] = \\cdots & + (0.0882657) + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = B3}) ]= \\cdots & + (-0.6027047) + \\cdots \\\\\n\\text{logit} [ P(y=1 | \\text{behave = B4}) ]= \\cdots & + (-0.4992142) + \\cdots\n\\end{aligned}\n\\]\n따라서 다른 설명 변수들의 값이 고정되어 있다면, 예를 들어 behave 의 두 범주 A0 와 A2 에 대한 오즈비는 다음과 같다.\n\\[\n\\frac{\\text{odd(behave = A2)}}{\\text{odd(behave = A0)}} =\n\\frac{\\tfrac{P(\\text{chd =  y} | \\text{ehave = A2})}{1- P(\\text{chd = y} | \\text{behave = A2)} )}}\n{\\tfrac{P(\\text{chd = y} | \\text{ehave = A0})}{1- P(\\text{chd = y} | \\text{ehave = A0})}}= \\exp(0.0882657 - 0) = 1.0922783\n\\tag{11.3}\\]\n\n\n11.3.2 모형의 비교: 내포된 모형\n이제 몇 개의 변수를 제외한 모형을 더적합해 보자. 모형에서 height 와 dbp 를 제외하고 적합해 보자.\n\nfit_1 &lt;- glm(chd ~ age +  weight + sdp  +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_1)\n\n\nCall:\nglm(formula = chd ~ age + weight + sdp + chol + behave + cigs, \n    family = binomial, data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -11.989331   0.995324 -12.046  &lt; 2e-16 ***\nage           0.064732   0.012103   5.348 8.87e-08 ***\nweight        0.008874   0.003173   2.797  0.00516 ** \nsdp           0.017326   0.004095   4.231 2.33e-05 ***\nchol          0.011005   0.001513   7.274 3.49e-13 ***\nbehaveA2      0.090232   0.222140   0.406  0.68460    \nbehaveB3     -0.602010   0.243734  -2.470  0.01351 *  \nbehaveB4     -0.498449   0.320571  -1.555  0.11997    \ncigs          0.021198   0.004226   5.017 5.26e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1580.7  on 3133  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1598.7\n\nNumber of Fisher Scoring iterations: 6\n\n\n이제 두 개의 모형 fit_all 과 fit_1 을 비교해 보자. 두 모형의 편차(deviance)는 다음과 같다.\n\ndeviance(fit_all)\n\n[1] 1580.446\n\ndeviance(fit_1)\n\n[1] 1580.676\n\n\n두 개의 모형 fit_all 과 fit_1 의 편차가 거의 차이가 없으므로 모형에서 height 와 dbp 를 제외하더라도 모형의 설명력이 거의 차이가 없다고 볼 수 있다.\n이제 3개의 설명변수 height , dbp, weight 를 제외한 모형을 적합해 보자.\n\nfit_2 &lt;- glm(chd ~ age  + sdp  +  chol + behave +  cigs , family = binomial, wcgs_1)\nsummary(fit_2)\n\n\nCall:\nglm(formula = chd ~ age + sdp + chol + behave + cigs, family = binomial, \n    data = wcgs_1)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -10.582582   0.843068 -12.552  &lt; 2e-16 ***\nage           0.061049   0.012003   5.086 3.66e-07 ***\nsdp           0.019909   0.003946   5.046 4.51e-07 ***\nchol          0.010950   0.001502   7.290 3.10e-13 ***\nbehaveA2      0.073842   0.221516   0.333  0.73887    \nbehaveB3     -0.630270   0.243056  -2.593  0.00951 ** \nbehaveB4     -0.539369   0.319753  -1.687  0.09164 .  \ncigs          0.020246   0.004222   4.796 1.62e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1779.2  on 3141  degrees of freedom\nResidual deviance: 1588.4  on 3134  degrees of freedom\n  (12 observations deleted due to missingness)\nAIC: 1604.4\n\nNumber of Fisher Scoring iterations: 6\n\n\n\ndeviance(fit_all)\n\n[1] 1580.446\n\ndeviance(fit_1)\n\n[1] 1580.676\n\ndeviance(fit_2)\n\n[1] 1588.378\n\n\n이제 두 모형 fit_1 과 fit_2 의 편처의 차이를 보면 다음과 같다.\n\ndeviance(fit_2) - deviance(fit_1)\n\n[1] 7.702675\n\n\n이제 질문은 모형에서 weight 를 제외하면 모형의 설명력에 유의한 영향이 있는지에 대한 것이다. 이는 다음과 같은 가설로 표현할 수 있다.\n\\[ H_0 : \\beta_{\\text{weight}} = 0 \\quad \\text{vs.} \\quad \\beta_{\\text{weight}} \\ne 0 \\]\n이제 함수 anova 를 통해서 가설검정을 해보자.\n\nanova(fit_2, fit_1, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: chd ~ age + sdp + chol + behave + cigs\nModel 2: chd ~ age + weight + sdp + chol + behave + cigs\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   \n1      3134     1588.4                        \n2      3133     1580.7  1   7.7027 0.005514 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n위의 결과에서 weight 를 제외하면 모형의 설명력에 유의한 영향이 있다고 할 수 있다. 즉 weight 는 모형에서 유의한 변수이다.\n참고로 두 개의 설명 변수 height, dbp 를 제외한 경우는 큰 차이가 유의한 차이가 있는지 알아보자.\n\nanova(fit_1, fit_all, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: chd ~ age + weight + sdp + chol + behave + cigs\nModel 2: chd ~ age + height + weight + sdp + dbp + chol + behave + cigs\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1      3133     1580.7                     \n2      3131     1580.5  2  0.22978   0.8915\n\n\n위의 결과를 보면 \\(H_0 : \\beta_{\\text{height}} =\\beta_{\\text{dbp}} = 0\\)를 기각할 수 없다는 것을 알 수 있다.\n주어진 모형에서 1개의 변수를 제거할 수 있는지는 다음과 같은 함수 drop1 으로 알아볼 수 있다. 아래 결과를 보면 각 독립변수를 제거한 경우에 얻어진 편차를 보여주고 그 편차의 차이가 유의한 지를 알려준다.\n아래 결과를 보면 설명 변수 height 와 dbp 는 모형에서 제외해도 유의한 차이가 없음을 알려준다.\n\ndrop1(fit_all, test = \"Chisq\")\n\nSingle term deletions\n\nModel:\nchd ~ age + height + weight + sdp + dbp + chol + behave + cigs\n       Df Deviance    AIC    LRT  Pr(&gt;Chi)    \n&lt;none&gt;      1580.5 1602.5                     \nage     1   1609.1 1629.1 28.662 8.617e-08 ***\nheight  1   1580.7 1600.7  0.228  0.632710    \nweight  1   1584.5 1604.5  4.072  0.043612 *  \nsdp     1   1587.8 1607.8  7.299  0.006898 ** \ndbp     1   1580.5 1600.5  0.000  0.991089    \nchol    1   1635.2 1655.2 54.739 1.376e-13 ***\nbehave  3   1602.0 1618.0 21.518 8.218e-05 ***\ncigs    1   1603.6 1623.6 23.159 1.492e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n적합한 모형에서 각 회귀계수의 신뢰구간은 다음과 같이 구할 수 있다.\n\nconfint(fit_all)\n\nWaiting for profiling to be done...\n\n\n                    2.5 %      97.5 %\n(Intercept) -1.761371e+01 -8.45120837\nage          4.131448e-02  0.08887927\nheight      -4.890449e-02  0.08105677\nweight       2.268784e-04  0.01544556\nsdp          4.869834e-03  0.02996578\ndbp         -2.114627e-02  0.02134188\nchol         8.112039e-03  0.01407651\nbehaveA2    -3.351460e-01  0.53997138\nbehaveB3    -1.073224e+00 -0.11295633\nbehaveB4    -1.143870e+00  0.12153181\ncigs         1.255611e-02  0.02935499\n\n\n\n\n11.3.3 모형의 비교: 일반적인 모형\n일반적으로 두 개 이상의 모형을 비교하는 경우 가장 자주 사용되는 측도는 정보기준 측도인 AIC(Akaike Information Criteris) 와 BIC(Bayesian Information Criteria) 가 이 있다. AIC와 BIC 모두 값이 작은 것이 좋으 모형이다.\n이제 앞에서 살펴본 3개의 모형의 AIC 와 BIC 를 구해보자.\n\nAIC(fit_all, fit_1, fit_2)\n\n        df      AIC\nfit_all 11 1602.446\nfit_1    9 1598.676\nfit_2    8 1604.378\n\n\n\nBIC(fit_all, fit_1, fit_2)\n\n        df      BIC\nfit_all 11 1669.024\nfit_1    9 1653.149\nfit_2    8 1652.799\n\n\nAIC 기준으로는 모형 fit_1 이 제일 좋으며 BIC 기준으로는 fit_2 가 가장 좋다. BIC 가 AIC 보다 설명변수의 수가 적은 성김 모형을 선호하는 일반적인 결과이다.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#회귀모형의-진단",
    "href": "notes/logistic_practice.html#회귀모형의-진단",
    "title": "11  로지스틱 회귀모형 실습 1",
    "section": "11.4 회귀모형의 진단",
    "text": "11.4 회귀모형의 진단\n\n11.4.1 잔차\n선형회귀 모형처럼 관측값(로지스틱 회귀에서는 0 또는 1)에서 예측값을 뺀 잔차 \\(r_i\\) (residual, raw residual)을 구할 수 있다.\n\\[ r_i = y_i - \\hat P(y_i=1| \\pmb x_i)  \\tag{11.4}\\]\n다음과 같이 residuals 함수에 type=\"response\"를 이용하면 식 11.4 의 잔차 를 구할 수 있다.\n\nhead(residuals(fit_all, type=\"response\")) # 너무 많아서 일부만 출력\n\n          1           2           3           4           5           6 \n-0.08157607 -0.06242009 -0.01031108 -0.01118637  0.84345627 -0.03832130 \n\n\n이제 잔차를 표준화한 피어슨 잔차(pearson residual)은 다음과 같이 구할 수 있다.\n\\[ r^*_i = \\frac{y_i - \\hat p_i}{\\sqrt{\\hat p_i (1-\\hat p_i)}}  \\tag{11.5}\\]\n\nhead(residuals(fit_all, type=\"pearson\")) \n\n         1          2          3          4          5          6 \n-0.2980299 -0.2580228 -0.1020711 -0.1063622  2.3212047 -0.1996205 \n\n\n참고로 피어슨 잔차를 제곱한 합은 적합도 분석에 사용하는 카이제곱 통계량이다.\n\\[ \\chi^2 = \\sum_{i=1}^n \\left [ r^*_i \\right ]^2 \\]\n그리고 잔차를 분석하는 그림도 다음과 같이 출력할 수 있다.\n\nplot(fit_all)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n다른 잔차로서 편차 잔차(deviance residual) 이 있으며 이는 편차의 합으로 표시될 수 있도록 잔차를 로그가능도 함수의 값으로 정의한 것이다.\n\\[ d_i = sign(y-\\hat p_i) \\sqrt{-2\\{  y_i \\log \\hat p_i + (1-y_i) \\log (1- \\hat p_i)\\}}  \\tag{11.6}\\]\n여기서 정의된 편차 잔차는 다음의 식을 만족하도록 구한 잔차이다.\n\\[ \\text{deviance} = D(\\hat {\\pmb y} ; \\hat {\\pmb \\mu } ) = \\sum_{i=1}^n d^2_i \\]\n로지스틱 회귀모형에서의 정의된 모든 잔차는 선형모형과의 잔차와는 많이 다르다. 로지스틱 회귀모형에서 반응값은 0 또는 1 의 값만 가지기 때문에 잔차의 범위가 제약되어 있고 두 개의 패턴으로 몰려서 나오기 때문에 이상점을 찾거나 등분산성을 판단하는 진단으로 이용하기는 힘들다.\n\n\n11.4.2 다중공선성\n로지스틱 회귀모형에서도 다중공선성(colliearity)는 쉽게 진단할 수 있다.\n함수vif 를 이용하면 분산팽창계수(variance inflation factor; vif)의 값을 구하고 상대적으로 큰 값을 보이는 설명변수들이 다중공선성의 위험이 높다.\n다음의 결과에서 두 개의 혈압 sdp 와 dbp 의 vif 값이 높다는 것을 알 수 있다.\n\nvif(fit_all)\n\n           GVIF Df GVIF^(1/(2*Df))\nage    1.052733  1        1.026028\nheight 1.474285  1        1.214201\nweight 1.599757  1        1.264815\nsdp    2.656508  1        1.629880\ndbp    2.792595  1        1.671106\nchol   1.019601  1        1.009753\nbehave 1.029248  3        1.004816\ncigs   1.051759  1        1.025553\n\n\n다음과 같이 설명변수들의 상관계수를 보면 두 개의 혈압 sdp 와 dbp 이 상관계수가 0.77로 다른 조합보다 높게 나타난다.\n\ncor(model.matrix(fit_all)[,-1])\n\n                  age       height       weight         sdp          dbp\nage       1.000000000 -0.091924057 -0.033078516  0.17005253  0.143979992\nheight   -0.091924057  1.000000000  0.533288106  0.01556533  0.006985365\nweight   -0.033078516  0.533288106  1.000000000  0.25127827  0.293968705\nsdp       0.170052531  0.015565329  0.251278272  1.00000000  0.770044438\ndbp       0.143979992  0.006985365  0.293968705  0.77004444  1.000000000\nchol      0.089188510 -0.088937779  0.008537442  0.12306130  0.129597108\nbehaveA2  0.052019677  0.035509861  0.032336093  0.07146950  0.038463827\nbehaveB3 -0.065710685 -0.018273763 -0.022060732 -0.05832314 -0.040950551\nbehaveB4 -0.040543591 -0.025710608 -0.033791371 -0.03375835 -0.031730174\ncigs     -0.006111181  0.017304324 -0.082673038  0.02928485 -0.062670918\n                 chol    behaveA2    behaveB3    behaveB4         cigs\nage       0.089188510  0.05201968 -0.06571069 -0.04054359 -0.006111181\nheight   -0.088937779  0.03550986 -0.01827376 -0.02571061  0.017304324\nweight    0.008537442  0.03233609 -0.02206073 -0.03379137 -0.082673038\nsdp       0.123061297  0.07146950 -0.05832314 -0.03375835  0.029284852\ndbp       0.129597108  0.03846383 -0.04095055 -0.03173017 -0.062670918\nchol      1.000000000  0.03365476 -0.03791301 -0.03204021  0.096031834\nbehaveA2  0.033654760  1.00000000 -0.67403983 -0.30058884  0.069761255\nbehaveB3 -0.037913013 -0.67403983  1.00000000 -0.27929653 -0.060013668\nbehaveB4 -0.032040209 -0.30058884 -0.27929653  1.00000000 -0.053546698\ncigs      0.096031834  0.06976125 -0.06001367 -0.05354670  1.000000000",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice.html#예측",
    "href": "notes/logistic_practice.html#예측",
    "title": "11  로지스틱 회귀모형 실습 1",
    "section": "11.5 예측",
    "text": "11.5 예측\n이제 적합된 성공 확률을 이용하여 반응변수의 값과 예측값을이 얼마나 일치하는지 알아보자.\n\\[\n\\hat y_i =\n\\begin{cases}\n\\text{yes} & \\text{ if } \\hat p_i \\ge \\text{threshold} \\\\\n\\text{no} & \\text{ if } \\hat p_i &lt; \\text{threshold}\n\\end{cases}\n\\]\n먼저 자주 사용되는 분류기준 \\(\\text{threshold}=0.5\\) 이용하여 반응값을 예측해보자.\n\nTH &lt;- 0.5\npred_y &lt;- ifelse(predict(fit_2, type=\"response\") &lt; TH , 0, 1)\npred_df &lt;- data.frame(response=fit_1$y , predicted=pred_y)\nhead(pred_df)\n\n  response predicted\n1        0         0\n2        0         0\n3        0         0\n4        0         0\n5        1         0\n6        0         0\n\n\n\nclass_table &lt;- xtabs(~response+predicted, data=pred_df)\nclass_table\n\n        predicted\nresponse    0    1\n       0 2884    1\n       1  254    3\n\n\n이제 분류기준을 정하면 위의 분류표와 민감도와 특이도를 계산하는 함수를 만들어 보자\n\nclassify_func &lt;- function(fit_glm, th){\n  pred_y &lt;- ifelse(predict(fit_glm, type=\"response\") &lt; th , 0, 1)\n  pred_df &lt;- data.frame(response=fit_glm$y , predicted=pred_y)\n  class_table &lt;- xtabs(~response+predicted, data=pred_df)\n  sensitivity &lt;- class_table[2,2]/(class_table[2,1] + class_table[2,2])\n  specificity &lt;- class_table[1,1]/(class_table[1,1] + class_table[1,2])\n  \n  list(class_table, sensitivity, specificity)\n}\n\n분류기준을 0.5 로 하면 다음과 같은 결과가 얻어진다.\n\nclassify_func(fit_1, 0.5)\n\n[[1]]\n        predicted\nresponse    0    1\n       0 2882    3\n       1  255    2\n\n[[2]]\n[1] 0.007782101\n\n[[3]]\n[1] 0.9989601\n\n\n분류기준을 0.3으로 낮추면 민감도가 조금 증가하는 것을 알 수 있다.\n\nclassify_func(fit_1, 0.3)\n\n[[1]]\n        predicted\nresponse    0    1\n       0 2824   61\n       1  234   23\n\n[[2]]\n[1] 0.08949416\n\n[[3]]\n[1] 0.9788562\n\n\n양성예측도와 음성예측도를 구하는 함수를 다음과 같이 만들 수 있다.\n\nclassify_func(fit_1, 0.3)[[2]][1]\n\n[1] 0.08949416\n\n\n\n# prev : 유병률\ncalpred &lt;- function(prev, sen, spe){\n    pred.pos &lt;- sen*prev/(sen*prev + (1-spe)*(1-prev))\n  pred.neg &lt;- spe*(1-prev)/(spe*(1-prev) + (1-sen)*(prev))\n  res &lt;- data.frame(sen, spe, prev, pred.pos, pred.neg)\n  colnames(res) &lt;- c(\"Sensitivity\", \"SPecificity\",\"Prevalnce\", \"Pred. Post.\", \"Pred. Nega.\")\n  res\n}\n\n분류기준을 0.3, 관상동맥질환의 한국 유병율을 \\(3.0\\%\\) 로 놓고 양성예측도와 음성예측도를 구해보자.\n\ncalpred(0.03, classify_func(fit_1, 0.3)[[2]][1], classify_func(fit_1, 0.3)[[3]][1])\n\n  Sensitivity SPecificity Prevalnce Pred. Post. Pred. Nega.\n1  0.08949416   0.9788562      0.03   0.1157534   0.9720362\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#필요한-패키지와-함수",
    "href": "notes/logistic_practice_2.html#필요한-패키지와-함수",
    "title": "12  로지스틱 회귀모형 실습 2",
    "section": "12.1 필요한 패키지와 함수",
    "text": "12.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(epiR)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(sm)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nsource(\"../R/functions.R\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#예제-백혈병의-재발",
    "href": "notes/logistic_practice_2.html#예제-백혈병의-재발",
    "title": "12  로지스틱 회귀모형 실습 2",
    "section": "12.2 예제: 백혈병의 재발",
    "text": "12.2 예제: 백혈병의 재발\n다음은 Jaewon Lee (2005) 의 4장에 나오는 예제이다.\n102명의 백혈병(Lukeumia) 환자들을 랜덤하게 두 개의 그룹으로 나누어서 한 그룹에는 처리 A를 하고, 다른 그룹에는 처리 B를 적용하여 재발 여부를 조사하였다. 이때 재발 여부에 영향을 미치는 또 다른 요인으로 호전기간(remission time)을 예측변수로 고려하였다.\n변수 remission 는 호전기간(단위는 월)이며 재발여부를 나타내는 y 는 1이면 재발을 나타내며 이 예제에서는 재발할 확률이 관심 사건이다. 이제 처리 그룹 trt 과 호전 기간이 재발 여부에 미치는 영향을 알아보자.\n참고로 백혈병(Lukeumia) 환에 대한 자료는 확률변수 \\(y_i\\) 가 베르누이 분포 \\(Berr(p_i)\\)를 따른다.\n먼저 자료를 데이터프레임으로 읽어 오자.\n\nluk &lt;- read.csv(\"../data/leukemia.csv\", header=T, sep=\"\")\nhead(luk,5)\n\n  trt remission y\n1   A         3 0\n2   A         3 1\n3   A        15 0\n4   A         6 1\n5   A        15 0\n\n\n먼저 재발여부를 나타내는 y 는 1 이 성공 사건이므로 level=c(0,1) 로 지정한다.\n\nluk$y &lt;- factor(luk$y, levels=c(0, 1))\n\n먼저 처리와 재발에 대한 분할표를 만들어 보자. 또한 호전 기간의 요약통계도 살펴보자.\n\ntable(luk$trt, luk$y)\n\n   \n     0  1\n  A 29 22\n  B 20 31\n\n\n\nsummary(luk$remission)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  3.000   6.000   9.000   9.735  12.000  18.000 \n\n\n이제 다음과 같이 함수 glm 을 이용하여 로지스틱 회귀모형을 적합해보자.\n\nluk_res &lt;- glm(y~ trt + remission, family = \"binomial\", data=luk)\nsummary(luk_res)\n\n\nCall:\nglm(formula = y ~ trt + remission, family = \"binomial\", data = luk)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.45595    0.55839   2.607 0.009123 ** \ntrtB         1.17754    0.46669   2.523 0.011631 *  \nremission   -0.19985    0.05589  -3.576 0.000349 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 141.25  on 101  degrees of freedom\nResidual deviance: 122.68  on  99  degrees of freedom\nAIC: 128.68\n\nNumber of Fisher Scoring iterations: 3\n\n\n위의 결과를 해석하면 다음과 같이 설명할 수 있다. 일단 두 환자가 같은 호전 시간 remission 을 보여주었다면 처리 A 와 B 에 대한 재발 확률의 오즈비는 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|B)}{1-P(y=1|B)} \\right ] \\\\\n& \\quad = [1.4559 + 0 + (-0.1998)(x)] - [1.4559 + 1.1775\n  + (-0.1998)(x)] \\\\\n& \\quad  = - 1.1775\n\\end{aligned}\n\\]\n따라서\n\\[\n\\log   \\left [  \\frac {\\tfrac{P(y=1|A)}{1-P(y=1|A)}}{\\tfrac{P(y=1|B)}{1-P(y=1|B)}} \\right ]  = - 1.1775\n\\]\n다시 쓰면\n\\[\n\\frac {\\tfrac{P(y=1|A)}{1-P(y=1|A)}}{\\tfrac{P(y=1|B)}{1-P(y=1|B)}}   = \\exp(-1.1775) = 0.308\n\\]\n따라서 처리 A 를 받은 환자들의 오드가 처리 B 를 받은 환자들의 오드의 약 0.3 배(30%)가 된다는 것을 의미한다. 처리 A의 한자들이 재발할 가능성이 처리 B 를 받은 환자들 보다 작다는 것을 의미하며 처리 trt 의 회귀계수에 대한 p-값이 \\(0.0116\\) 이므로 처리 간의 차이가 유의한 것을 알 수 있다.\n호전기간 remisson 에 대한 효과도 알아보자. 일단 두 환자가 같은 처리를 받았다고 가정하고(예를 들어 처리 A) 호전 시간이 1개월 차이가 는 경우의 배발 확률을 비교해보자.\n한 명의 한자는 호전기간이 \\(r+1\\) 개월이고 다른 환자는 \\(r\\) 개월 이라면 재발 확률의 오즈비는 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|x=r+1)}{1-P(y=1|x=r+1)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|x=r)}{1-P(y=1|x=r)} \\right ] \\\\\n& \\quad = [1.4559 + 0 + (-0.1998)(r+1)] - [1.4559 + 0\n  + (-0.1998)(r)] \\\\\n& \\quad  = -0.1998\n\\end{aligned}\n\\]\n따라서\n\\[\n\\frac {\\tfrac{P(y=1|x=r+1)}{1-P(y=1|x=r+1)}}{\\tfrac{P(y=1|x=r)}{1-P(y=1|x=r)}}   = \\exp(-0.1998) = 0.819\n\\]\n즉, 호전기간이 1개월 증가하면 오즈가 이전의 약 81.9% 가 된다. 따라서 호전 기간이 늘어날수록 재발할 확률이 낮아지는 것을 알 수 있다. 가설 검정에 의하여 호전 기간은 매우 유의한 예측변수이다(p-값 = 0.000349).\n이제 함수 predict() 를 이용하여 각 환자에 대한 재발 확률의 예측값을 구해보자. 선택문 type = \"response\"을 이용해야 확률의 예측값이 구해진다.\n\nluk_pred_p &lt;- predict(luk_res, type = \"response\")\nluk_pred_p[1:14]\n\n        1         2         3         4         5         6         7         8 \n0.7019096 0.7019096 0.1762813 0.5638664 0.1762813 0.2804544 0.5638664 0.5638664 \n        9        10        11        12        13        14 \n0.2804544 0.5638664 0.5638664 0.7019096 0.4151610 0.5638664 \n\n\n각 처리에 따라서 호전기간이 변하면 재발확률이 어떻게 변하는지 에측확률에 대한 그림을 다음과 같이 그려보자.\n먼저 두 처리 그룹에 대하여 호전기간에 대한 값을 1개월부터 24개월까지 새로운 자료를 만들자.\n\nt_num = 24\ntrt_new = c(rep(\"A\", t_num), rep(\"B\", t_num))\nremission_new = rep(1:t_num, 2)\nluk_new = data.frame(trt = trt_new, remission=remission_new)\nhead(luk_new,10)\n\n   trt remission\n1    A         1\n2    A         2\n3    A         3\n4    A         4\n5    A         5\n6    A         6\n7    A         7\n8    A         8\n9    A         9\n10   A        10\n\n\n새롭개 만든 데이터프레임 luk_new 에 예측함수 predict() 를 이용하여 예측한 재발확률의 벡터를 만들고 데이터프레임 luk_new 에 포함시킨다.\n\npred_new = predict(luk_res, newdata = luk_new, type = \"response\")\nluk_new$hatp = pred_new \nhead(luk_new)\n\n  trt remission      hatp\n1   A         1 0.7783541\n2   A         2 0.7419740\n3   A         3 0.7019096\n4   A         4 0.6584875\n5   A         5 0.6122346\n6   A         6 0.5638664\n\n\n이제 패키지 ggplot2 를 이용하여 처리에 따라서 호전기간에 따른 예측된 재발확률의 변화를 그림으로 그려보자.\n\nggplot(luk_new, aes(x=remission, y=hatp, color=trt)) + \n  geom_line() + \n  labs(x=\"remission(month)\", y=\"Probability\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/logistic_practice_2.html#예제-종양-치료",
    "href": "notes/logistic_practice_2.html#예제-종양-치료",
    "title": "12  로지스틱 회귀모형 실습 2",
    "section": "12.3 예제: 종양 치료",
    "text": "12.3 예제: 종양 치료\n다음은 Jaewon Lee (2005) 의 4장에 나오는 예제이다.\n두 종류의 종양(T,M)이 있는 환자들을 대상으로 3가지 치료 방법(A, B, C)를 적용하여 종양이 치료되었는지 여부를 조사한 자료이다. 변수 cured 와 uncured 는 각각 치료된 환자와 그렇지 못한 환자의 수를 나타낸다.\n연구자의 관심은 치료율이 종양과 치료법에 따라서 다른지 알아보는데 있다.\n\ntumor &lt;- read.csv(text = \"\ntype trt  cured uncured\nT A  65   18\nM B  100  13\nT C  56   38\nM A  80   15\nT B  29   9\nM C  78   22\n\", sep=\"\", header=TRUE )\n\ntumor\n\n  type trt cured uncured\n1    T   A    65      18\n2    M   B   100      13\n3    T   C    56      38\n4    M   A    80      15\n5    T   B    29       9\n6    M   C    78      22\n\n\n먼저 자료에서 종양의 종류(type) 과 치료법(trt)를 범주형 변수로 정하고 수준(level)과 순서를 정하자.\n\ntumor$type &lt;- factor(tumor$type, levels = c(\"M\", \"T\"))\ntumor$trt &lt;-  factor(tumor$trt, levels=c(\"A\", \"B\", \"C\"))\nstr(tumor)\n\n'data.frame':   6 obs. of  4 variables:\n $ type   : Factor w/ 2 levels \"M\",\"T\": 2 1 2 1 2 1\n $ trt    : Factor w/ 3 levels \"A\",\"B\",\"C\": 1 2 3 1 2 3\n $ cured  : int  65 100 56 80 29 78\n $ uncured: int  18 13 38 15 9 22\n\n\n이제 다음과 같인 종양의 종류와 치료법을 예측변수로 하는 로지스틱 회귀식을 적합해 보자.\n모형식에서 반응값으로 함수 cbind() 에 성공의 횟수(cured)와 실패의 횟수(uncured)를 지정한다.\n\ntumor_res &lt;- glm( cbind(cured, uncured) ~ type + trt, family = \"binomial\", data=tumor)\n\nsummary(tumor_res)\n\n\nCall:\nglm(formula = cbind(cured, uncured) ~ type + trt, family = \"binomial\", \n    data = tumor)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.8575     0.2328   7.978 1.48e-15 ***\ntypeT        -0.7216     0.2202  -3.276  0.00105 ** \ntrtB          0.1288     0.3073   0.419  0.67515    \ntrtC         -0.6795     0.2505  -2.712  0.00668 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 26.8238  on 5  degrees of freedom\nResidual deviance:  1.0604  on 2  degrees of freedom\nAIC: 35.669\n\nNumber of Fisher Scoring iterations: 4\n\n\n앞에서 종양의 종류와 치료 방법에 대한 수준(level)을 만들 때 종양 M 과 치료법 A 를 첫 수준으로 놓있기 떄문에 효과에 대한 추정치는 0이 된다. 즉, 나머지 종양과 치료법의 효과는 종양 M 과 치료법 A 에 대한 상대적인 효과이다.\n추정의 결과를 해석하면 다음과 같다. 비교하고자 하는 효과를 제외한 다른 효과들은 모두 같은 효과를 가정하므로 0으로 놓고 계산해도 무방하다.\n\n종양의 종류가 M 인 경우의 치료에 대한 오드가 T 인 경우의 2.06 배 이다 [\\(\\exp(0.7216)\\)]. 따라서 종양의 종류가 M 인 경우가 T 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|M)}{1-P(y=1|M)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|T)}{1-P(y=1|T)} \\right ] \\\\\n& \\quad = [1.8575 + 0 + 0 ] - [1.8575 -0.7216 + 0] \\\\\n& \\quad  =0.7216\n\\end{aligned}\n\\]\n\n치료 방법이 A 인 경우의 치료에 대한 오드가 B 인 경우의 87.91 % 이다 [\\(\\exp(-0.1288)\\)]. 따라서 치료 방법이 B 인 경우가 A 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|B)}{1-P(y=1|B)} \\right ] \\\\\n& \\quad = [1.8575 + 0 + 0 ] - [1.8575 + 0 + 0.1288 ] \\\\\n& \\quad  = - 0.1228\n\\end{aligned}\n\\]\n\n치료 방법이 A 인 경우의 치료에 대한 오드가 C 인 경우의 1.97 배 이다 [\\(\\exp( 0.6795)\\)]. 따라서 치료 방법이 A 인 경우가 C 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|C)}{1-P(y=1|C)} \\right ] \\\\\n& \\quad = [1.8575 0 + 0 ] - [1.8575  + 0 - 0.6795] \\\\\n& \\quad  = 0.6795\n\\end{aligned}\n\\]\n\n치료 방법이 B 인 경우의 치료에 대한 오드가 C 인 경우의 2.23 배 이다 [\\(\\exp(0.8023)\\)]. 따라서 치료 방법이 B 인 경우가 C 인 경우보다 치료 효과가 더 좋다.\n\n\\[\n\\begin{aligned}\n& \\log   \\left [   {\\tfrac{P(y=1|A)}{1-P(y=1|A)}} \\right ]\n-\\log \\left [ \\tfrac{P(y=1|C)}{1-P(y=1|C)} \\right ] \\\\\n& \\quad = [1.8575 +  0 + 0.1288 ] - [1.8575  + 0 - 0.6795] \\\\\n& \\quad  = 0.1228 +  0.6795 = 0.8023\n\\end{aligned}\n\\]\n이제 종양별, 치료 방법별로 치료의 확률에 대한 예측값을 구해보자.\n종양의 종류에 관계없이 치료법 B 가 가장 치료 효과가 높다는 것을 알 수 있다.\n\ntumor_new &lt;- tumor[,1:2]\npred_new = predict(tumor_res, newdata = tumor_new, type = \"response\")\ntumor_new$hatp = pred_new \ntumor_new %&gt;% arrange(type, trt)\n\n  type trt      hatp\n1    M   A 0.8650044\n2    M   B 0.8793494\n3    M   C 0.7645810\n4    T   A 0.7569227\n5    T   B 0.7798294\n6    T   C 0.6121479\n\n\n여기서 주의할 점은 각 종양과 치료법의 조합에서 구할 수 있는 치료된 환자들의 표본 비율과 로지스틱 회귀에서 나타나는 추정 확률은 약간 차이가 난다. 그 이유는 로지스틱회귀에서는 최대가능도함수 추정법을 사용하여 각 조합의 효과를 추정하기 때문에 단순한 표본 비율과 차이가 날 수 있다.\n\n\n\n\nJaewon Lee, Hanna Yu, Mira Park. 2005. 생명과학연구를 위한 통계적 방법. 1st ed. 자유아카데미.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>로지스틱 회귀모형 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice.html#필요한-패키지와-함수",
    "href": "notes/lme_practice.html#필요한-패키지와-함수",
    "title": "13  반복측정자료 실습 1",
    "section": "13.1 필요한 패키지와 함수",
    "text": "13.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(brms)\nlibrary(pbkrtest)\n# ggplot2 에서 한글의 사용\nlibrary(showtext)\nfont_add_google(\"Nanum Pen Script\", \"nanum\")\nshowtext_auto()\n\n\nsource(\"../R/functions.R\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>반복측정자료 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice.html#반복측정자료의-분석",
    "href": "notes/lme_practice.html#반복측정자료의-분석",
    "title": "13  반복측정자료 실습 1",
    "section": "13.2 반복측정자료의 분석",
    "text": "13.2 반복측정자료의 분석\n반복측정자료에 대한 분석은 교과서 Faraway (2016) 에서 사용된 psid 데이터프레임을 사용한다.\n1968년에 시작된 소득 역학 패널 연구(PSID)는 Hill(1992)에 설명된 미국 개인을 대표하는 표본을 대상으로 한 종단 연구(longitudinal study)이다. 이 연구는 미시간 대학교 사회 연구소의 서베이 리서치 센터에서 수행되며 현재도 계속되고 있다.\n현재 8700가구가 연구에 참여하고 있으며 많은 변수가 측정되고 있다. 본 분석에서는 1968년에 25~39세였고 1968년과 1990년 중 최소 11년 동안의 완전한 데이터를 보유한 85명의 가구주로 구성된 이 데이터의 무작위 하위 집합을 분석하기로 선택하였다. 분석에 포함된 변수는 연소득, 성별, 교육 기간, 1968년 나이였습니다:\n\nage :age in 1968\neduc : years of education\nsex : sex of individual, F or M\nincome : annual income in dollars\nyear : year of observation\nperson : ID number for individual\n\n\ndata(psid, package=\"faraway\")\nhead(psid)\n\n  age educ sex income year person\n1  31   12   M   6000   68      1\n2  31   12   M   5300   69      1\n3  31   12   M   5200   70      1\n4  31   12   M   6900   71      1\n5  31   12   M   7500   72      1\n6  31   12   M   8000   73      1\n\n\n다음 그림은 처음 20명의 소득의 변화를 나타낸 것이다. 같은 직장에 안정적으로 고용되어 있는 사람처럼 소득이 서서히 증가하는 사람이 있음을 알 수 있지만 반대로 어떤 사람들은 소득이 더 불규칙으로 변하는 것도 볼 수 있다.\n\nlibrary(dplyr)\npsid20 &lt;- filter(psid, person &lt;= 20)\nlibrary(ggplot2)\nggplot(psid20, aes(x=year, y=income))+geom_line()+facet_wrap(~ person)\n\n\n\n\n\n\n\n\n다음은 성별에 따라 소득이 어떻게 다른지 보여줄 수도 있다. 소득은 로그 척도(log scale)로 표현하는 것이 비교를 위하여 적절하다. 이 경우 y=income+100 은 반응변수가 0일 때를 대비하여 100을 더한 것이다.\n다음\n\nggplot(psid20, aes(x=year, y=income+100, group=person)) +\n  geom_line() + \n  facet_wrap(~ sex) + \n  scale_y_log10()\n\n\n\n\n\n\n\n\n일반적으로 남성의 소득이 더 높고 변동성이 적은 반면, 여성의 소득은 변동성이 더 크지만 더 빠르게 증가하고 있음을 알 수 있다. 첫 번째 주제부터 각 주제에 한 줄을 그을 수 있습니다",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>반복측정자료 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice.html#개체별-모형",
    "href": "notes/lme_practice.html#개체별-모형",
    "title": "13  반복측정자료 실습 1",
    "section": "13.3 개체별 모형",
    "text": "13.3 개체별 모형\n이제 소득의 로그값을 반응변수로 하여 연도별 소득의 변화를 각 개인에 대하여 선형회귀 직선을 적합해 보자.\n\n ggplot(psid20, aes(x=year, y=income))+\n  geom_line()+\n  stat_smooth(method = \"lm\",se=F,linewidth=0.5)+ \n  facet_wrap(~ person)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n이 경우 개인별로 회귀직선의 기울기와 절편이 다르므로 개체별 모형이라고 한다. 함수 lmlist 를 이용하여 소득의 로그값을 반응변수로, 연도를 설명변수로 하여 개체별 모형을 적합해 보자. 연도는 실제 연도값(68,…,90) 에서 중간값 78을 뺀 값을 사용한다. 이렇게 하면 회귀직선의 절편은 78년의 소득을 나타내고 회귀직선의 기울기는 1년 당 소득의 증가를 나타낸다.\n\nml &lt;- lmList(log(income) ~ I(year-78) | person, psid)\nintercepts &lt;- sapply(ml,coef)[1,]\nslopes &lt;- sapply(ml,coef)[2,]\n\n절편과 기울기는 큰 상관관계는 없는 것으로 보이지만 약한 음의 상관계수가 나타났다.\n절편과 기울기에 대한 분포를 보기 위하여 상자그림을 그려보면 평균을 중심으로 대칭인 분포를 보이고 있다.\n\ncor(coef(ml))\n\n             (Intercept) I(year - 78)\n(Intercept)   1.00000000  -0.04850099\nI(year - 78) -0.04850099   1.00000000\n\nplot(coef(ml),main=\"intercepts and slopes on drivers: sleep study \")\n\n\n\n\n\n\n\n\nboxplot(intercepts)\nboxplot(slopes)\n\n\n\n그림 13.1: 개별 선형회귀모형에서 절편과 기울기의 분포\n\n\n\n\n\n\n\n(a) 절편\n\n\n\n\n\n\n\n\n\n\n\n(b) 기울기\n\n\n\n\n\n\n\n\n\n\n\n다음 그림은 남여별로 78년의 소득(intercept)을 비교한 그림이다. 여성에 비해 남성의 소득이 더 높다는 사실을 알 수 있다.\n\npsex &lt;- psid$sex[match(1:85,psid$person)]\nboxplot(split(intercepts,psex))\n\n\n\n\n\n\n\n\n다음 그림은 남여별로 소득 증가율(slope)을 비교한 그림이다. 남성에 비해 여성의 소득 증가율이 더 높고 가변적이라는 것을 알 수 있다.\n\nboxplot(split(slopes,psex))\n\n\n\n\n\n\n\n\n남여 두 그룹간에 절편과 기울기의 차이가 있는지 다음과 같이 t-검정을 수행할 수 있다.\n78년의 소득과 증가율 모두 남여간에 유의한 차이다 있다는 것을 알 수 있다.\n\nt.test(slopes[psex==\"M\"],slopes[psex==\"F\"])\n\n\n    Welch Two Sample t-test\n\ndata:  slopes[psex == \"M\"] and slopes[psex == \"F\"]\nt = -2.3786, df = 56.736, p-value = 0.02077\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.05916871 -0.00507729\nsample estimates:\n mean of x  mean of y \n0.05691046 0.08903346 \n\n\n\nt.test(intercepts[psex==\"M\"],intercepts[psex==\"F\"])\n\n\n    Welch Two Sample t-test\n\ndata:  intercepts[psex == \"M\"] and intercepts[psex == \"F\"]\nt = 8.2199, df = 79.719, p-value = 3.065e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.8738792 1.4322218\nsample estimates:\nmean of x mean of y \n 9.382325  8.229275",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>반복측정자료 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice.html#임의계수-모형",
    "href": "notes/lme_practice.html#임의계수-모형",
    "title": "13  반복측정자료 실습 1",
    "section": "13.4 임의계수 모형",
    "text": "13.4 임의계수 모형\n위와 같이 각 개체에 대한 회귀모형은 다음 설명변수들(성별, 교육기간 등)의 효과를 통합적으로 분석하기 힘들다, 이제 개인의 효과와 인구사회핫적 설명변수들을 동시에 고려할 수 있는 선형혼합모형을 고려해보자. 이 경우 연도의 회귀계수에 임의효과를 포함한 임의계수모형을 고려한다.\n\\[\n\\log~ (\\text{income})_{ij} = (\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i})~ \\text{year}_j + \\beta_2 ~\\text{sex}_j +\n\\beta_3 ~\\text{age}_j +  \\beta_4 ~ \\text{edu}_j + \\beta_{12} (\\text{year} \\times \\text{sex})_j + e_{ij}\n\\tag{13.1}\\]\n\\[\n{\\pmb b}_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b0} & \\rho \\sigma_{b0} \\sigma_{b1}\\\\\n\\rho \\sigma_{b0} \\sigma_{b1} & \\sigma^2_{b1} \\\\\n\\end{bmatrix}\n\\right ), \\quad \\sigma_e \\sim N(0, \\sigma^2_e)\n\\]\n이제 psid 자료에 다음과 같은 임의계수 모형을 적합해 보자.\n\npsid$cyear &lt;- psid$year-78\nmmod &lt;- lmer(log(income) ~ cyear*sex +age+educ+(cyear|person), psid)\nsummary(mmod)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: log(income) ~ cyear * sex + age + educ + (cyear | person)\n   Data: psid\n\nREML criterion at convergence: 3819.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-10.2310  -0.2134   0.0795   0.4147   2.8254 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n person   (Intercept) 0.2817   0.53071      \n          cyear       0.0024   0.04899  0.19\n Residual             0.4673   0.68357      \nNumber of obs: 1661, groups:  person, 85\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)  6.674211   0.543323 81.176969  12.284  &lt; 2e-16 ***\ncyear        0.085312   0.008999 78.915123   9.480 1.14e-14 ***\nsexM         1.150312   0.121292 81.772542   9.484 8.06e-15 ***\nage          0.010932   0.013524 80.837433   0.808   0.4213    \neduc         0.104209   0.021437 80.722317   4.861 5.65e-06 ***\ncyear:sexM  -0.026306   0.012238 77.995359  -2.150   0.0347 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) cyear  sexM   age    educ  \ncyear       0.020                            \nsexM       -0.104 -0.098                     \nage        -0.874  0.002 -0.026              \neduc       -0.597  0.000  0.008  0.167       \ncyear:sexM -0.003 -0.735  0.156 -0.010 -0.011\n\n\n위의 결과에 대하여 고정 효과부터 살펴보자. 교육 기간이 1년 더 늘어날 때마다 소득이 약 10% 증가하는 것을 알 수 있다. 연령은 유의하지 않은 것으로 나타난다.\n소득이 연도별로 변하는 증가율은 여성의 경우 소득은 연간 약 8.5% 증가하는 반면 남성의 경우 연간 약 8.5 - 2.6 = 5.9% 증가한다. 이 데이터의 경우 남성의 소득이 \\(\\exp(1.15) = 3.16\\) 배 더 높다는 것을 알 수 있다.\n이제 임의효과에 대한 추정 결과를 보자.\n\nVarCorr(mmod)\n\n Groups   Name        Std.Dev. Corr \n person   (Intercept) 0.530713      \n          cyear       0.048988 0.187\n Residual             0.683574      \n\n\n절편과 기울기의 개체별 변동은 표준편차 단위로 각각 다음과 같이 나타난다.\n\\[\n\\hat \\sigma_{b0} = 0.5307125, \\quad \\hat \\sigma_{b1} = 0.0489883, \\quad \\hat \\sigma_e = 0.683574\n\\]\n소득 증가(기울기)의 변동은 상대적으로 작은 반면 개인 간 전체 소득(절편)의 변동은 상당히 크다는 것을 알 수 있다. 또한 잔여 변동(오차항)이 크다는 점을 고려하면 소득의 연도별 변동이 크다는 것을 알 수 있다.\n또한 절편과 기울기의 상관계수는 0.1874426 로서 작게 나타나는 것을 알 수 있다.\n연도와 성별 간의 상호작용은 식 13.1 의 임의계수모형에서 가장 복잡한 항이므로 통계적으로 유의한 지 검정을 해보자. 아래 결과에 따라서 연도와 성별 간의 상호작용 항은 약간 유의미하므로 이 항을 제거하여 모델을 단순화하는 것이 타당하지 않다는 것을 알 수 있다. 여성 소득이 남성 소득보다 빠르게 증가하고 있다.\n\\[ H_0 : \\beta_{12} = 0 \\quad \\text{vs.} \\quad H_1 : \\beta_{12} \\ne 0 \\]\n\nmmod &lt;- lmer(log(income) ~ cyear*sex +age+educ+(cyear|person),psid, REML=FALSE)\nmmodr &lt;- lmer(log(income) ~ cyear + sex +age+educ+(cyear|person),psid, REML=FALSE)\nanova(mmod,mmodr)\n\nData: psid\nModels:\nmmodr: log(income) ~ cyear + sex + age + educ + (cyear | person)\nmmod: log(income) ~ cyear * sex + age + educ + (cyear | person)\n      npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)  \nmmodr    9 3808.1 3856.8 -1895.0   3790.1                       \nmmod    10 3805.5 3859.6 -1892.7   3785.5 4.6245  1    0.03152 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n참고로 아래에서 함수 KRmodcomp를 사용한 가설 검정은 Kenward-Roger 수정 F-검정으로 위에서 함수 anova 를 이용한 일반적인 가능도비 검정에 대하여 자유도를 수정하여 검정력을 높인 것이다.\n\nKRmodcomp(mmod,mmodr)\n\nlarge : log(income) ~ cyear + sex + age + educ + (cyear | person) + cyear:sex\nsmall : log(income) ~ cyear + sex + age + educ + (cyear | person)\n         stat     ndf     ddf F.scaling p.value  \nFtest  4.6142  1.0000 81.3279         1 0.03468 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nFaraway, Julian J. 2016. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>반복측정자료 실습 1</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#필요한-패키지와-함수",
    "href": "notes/lme_practice_2.html#필요한-패키지와-함수",
    "title": "14  반복측정자료 실습 2",
    "section": "14.1 필요한 패키지와 함수",
    "text": "14.1 필요한 패키지와 함수\n\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(brms)\nlibrary(stringr)\nlibrary(xfun)\nlibrary(lattice)\nlibrary(cowplot)\nlibrary(sjPlot)\nlibrary(MuMIn)\nlibrary(performance)\n\n# 아래 3 문장은 한글을 포함한 ggplot 그림이 포함된 HTML, PDF로 만드는 경우 사용\nlibrary(showtext)\nfont_add_google(\"Nanum Pen Script\", \"gl\")\nshowtext_auto()",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#계층모형",
    "href": "notes/lme_practice_2.html#계층모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.2 계층모형",
    "text": "14.2 계층모형\n이제 계층모형에 대한 전형적인 예제와 분석을 살펴보고자 한다. 아래에서 사용할 자료와 분석 내용은 Finch, Bolin, 와/과 Kelley (2019) 3장을 따른 것이다.\n성취도 시험 데이터(Achieve)는 160개 학교(school) 내에 위치한 10,903명의 3학년 학생으로부터 수집되었다. 학교 규모는 11개 학급(class)에서 143 개 학급까지 다양하며, 평균 규모는 68.14 학급이다..\n어휘력 점수가 일반적인 읽기 성취도를 예측하는 데 어느 정도까지 사용될 수 있는지 알아보고자 했습니다. 학생들은 학교 내에 중첩되어 있어 표준 선형 회귀 모델이 적합하지 않았습니다. 이 경우 학교는 무작위 효과이고 어휘 점수는 고정되어 있습니다. 먼저 독립 변수가 없고 절편만 있는 공분산 모델을 피팅합니다. 이 모델은 방정식 (2.11)에서와 같이 학교별 군집화만 고려할 때 잔차 및 절편 분산의 추정치를 구하는 데 유용합니다. 널 모델을 추정하는 데 필요한 lmer 구문은 다음과 같습니다.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#학생-성취도-자료",
    "href": "notes/lme_practice_2.html#학생-성취도-자료",
    "title": "14  반복측정자료 실습 2",
    "section": "14.3 학생 성취도 자료",
    "text": "14.3 학생 성취도 자료\n학생 성취도 자료는 Finch, Bolin, 와/과 Kelley (2019) 의 홈페이지에서 다운로드 받을 수 있다.\n\nAchieve &lt;- read.csv(\"../data/Achieve.csv\", header=T)\nhead(Achieve,n=3)\n\n  row id region corp school class gender age race geread gevocab gereadcm\n1   1  1      2  940    767     1      2 104    5    3.5     3.1      3.2\n2   2  2      2  940    767     1      2 106    5    1.2     2.8      2.0\n3   3  3      2  940    767     1      2 112    5    2.1     1.7      1.9\n  gelang gelangmc gelangcm gemath gemathcp gemathcm getotal npanverb npamem\n1    2.3      4.3      3.0    3.1      2.7      2.9     3.0       16     56\n2    1.8      1.7      1.6    3.2      4.3      3.8     2.7       39     79\n3    2.5      2.2      2.4    3.6      3.2      3.4     2.7       37     41\n  npaverb npatotal csi multi clenroll classize ptratio ptia locale chapter1\n1      46       26  90     2       16        1      16    2      7        1\n2      37       47  99     2       16        1      16    2      7        1\n3      34       35  94     2       16        1      16    2      7        1\n   ses context calender senroll sattend white1 black1 hispanc1 asian1 aindian1\n1 80.4     929        1     463    95.6   99.8      0        0      0        0\n2 80.4     929        1     463    95.6   99.8      0        0      0        0\n3 80.4     929        1     463    95.6   99.8      0        0      0        0\n  multi1 total1 noteach avgage1 avgexp1 avgsal1 spert thrdclss thrdstud passla1\n1    0.2    0.2    28.5    46.2    20.6   43517  16.3        4       60      63\n2    0.2    0.2    28.5    46.2    20.6   43517  16.3        4       60      63\n3    0.2    0.2    28.5    46.2    20.6   43517  16.3        4       60      63\n  passmth1 passbth1 tmnnce1 rmdnce1 lamdnce1 mmdnce1 tmdnce1 avgcsi1 geog\n1       74       52    60.5    57.6       55      61    59.7      99    2\n2       74       52    60.5    57.6       55      61    59.7      99    2\n3       74       52    60.5    57.6       55      61    59.7      99    2\n  totepp cenroll cattend freelnch lep speced minority white2 black2 hispanc2\n1   5956    3115    95.9       16 0.2   14.4      1.2   3077      1       12\n2   5956    3115    95.9       16 0.2   14.4      1.2   3077      1       12\n3   5956    3115    95.9       16 0.2   14.4      1.2   3077      1       12\n  asian2 aindian2 multi2 total2 thrdadm thrdtech avgage2 avgexp2 avgsal2\n1      3        1     21     38     208       11    45.2    18.4   41096\n2      3        1     21     38     208       11    45.2    18.4   41096\n3      3        1     21     38     208       11    45.2    18.4   41096\n  thrdaide passla2 passmth2 passbth2 tmnnce2 rmdnce2 lamdnce2 mmdnce2 tmdnce2\n1        3      67       70       52    59.4    57.8     59.8    60.6    60.8\n2        3      67       70       52    59.4    57.8     59.8    60.6    60.8\n3        3      67       70       52    59.4    57.8     59.8    60.6    60.8\n  rmediate\n1       18\n2       18\n3       18\n\n\n성취도 자료 Achieve는 160개 학교를 추출하고 각 학교마다 작게는 11명, 크게는 162명의 학생들을 추출하여 학교의 여러 가지 정보와 학생들의 다양한 성적을 수집한 자료이다.\n\nschool_info &lt;- Achieve %&gt;% group_by(school) %&gt;% summarise(n = n()) \nsummary(school_info$n)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  11.00   45.00   63.00   64.50   81.25  162.00 \n\n\n성취도 자료 Achieve는 계층적 자료이며 다음과 같은 계층구조를 가지고 있다.\n\n계층 1 : 학생\n계층 2 : 학교\n\n분석의 목적은 학교의 특성과 학생들의 다양한 성적들 (예를 들어 어휘 능력, vocabulary scores, gevocab)이 학생들의 읽기 성취도 (general reading achievement, geread)에 어떤 영향을 미치는지 분석하는 것이다.\n이제 \\(i\\) 번째 학교에 속한 \\(j\\) 번쨰 학생의 읽기 성취도 점수를 \\(y_{ij}\\) 라고 하자.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#단순-계층모형",
    "href": "notes/lme_practice_2.html#단순-계층모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.4 단순 계층모형",
    "text": "14.4 단순 계층모형\n가장 단순한 계층 모형으로서 읽기 성취도 점수에 대하여 학교 school 이 임의효과인 모형을 고려해 보자.\n\\[\ny_{ij} = \\beta_0 + b_{0i} + e_{ij}\n\\tag{14.1}\\]\n위의 식에서 \\(\\beta_0\\) 는 전체 평균 점수를 나타내는 모수이며 학교에 대한 임의효과 \\(b_{0i}\\) 와 오차항 \\(e_{ij}\\) 는 서로 독립이며 다음과 같은 분포를 따른다.\n\\[ b_{0i} \\sim N(0, \\sigma_{b0}^2 ) , \\quad e_{ij} \\sim N(0, \\sigma_e^2) \\]\n이제 lmer 함수로 모형 식 14.1 을 적합시켜 보자.\n\nmodel1 &lt;- lmer(geread~1 +(1|school), data=Achieve)\nsummary(model1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ 1 + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 46268.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.3229 -0.6378 -0.2138  0.2850  3.8812 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.3915   0.6257  \n Residual             5.0450   2.2461  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   4.30675    0.05498 158.53888   78.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ntab_model(model1)\n\n\n\n \ngeread\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n4.31\n4.20 – 4.41\n&lt;0.001\n\n\nRandom Effects\n\n\n\nσ2\n5.05\n\n\n\nτ00 school\n0.39\n\n\nICC\n0.07\n\n\nN school\n160\n\nObservations\n10320\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.072\n\n\n\n\n\n\n추정결과를 보면 학생들의 읽기 성취도의 전체 평균의 추정량은 \\(\\hat \\beta_0= 4.3067534\\)이다. 임의효과의 분산성분 \\(\\sigma_{b0}\\) 과 오차항의 븐산 \\(\\sigma_e\\)의 추정량은 다음과 같다.\n\\[ \\hat {\\sigma}^2_{b0} = 0.3915154 , \\quad\n\\hat {\\sigma}^2_{e} = 5.0450083 \\]\n지난 강의에서 언급한 그룹내 상관계수(ICC)의 값을 구해보면 0.072 로서 같은 학교에 속한 학생들의 성적들의 상관계수를 의미한다.\n\\[ \\text{ICC } = \\frac{\\hat {\\sigma}^2_{b0} }{\\hat {\\sigma}^2_{b0} + \\hat {\\sigma}^2_{e}  }\n= 0.072 \\]\n160개의 학교에 대한 임의효과에 대한 예측값 \\(\\hat b_{0i}\\)을 예측구간과 같이 나타내면 다음 그림과 같이 나타난다.\n\nsjPlot::plot_model  (model1, type = \"re\")\n\nWarning in checkMatrixPackageVersion(): Package version inconsistency detected.\nTMB was built with Matrix version 1.6.0\nCurrent Matrix version is 1.5.4.1\nPlease re-install 'TMB' from source using install.packages('TMB', type = 'source') or ask CRAN for a binary version of 'TMB' matching CRAN's 'Matrix' package",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#계층-1-설명변수가-있는-모형",
    "href": "notes/lme_practice_2.html#계층-1-설명변수가-있는-모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.5 계층 1 설명변수가 있는 모형",
    "text": "14.5 계층 1 설명변수가 있는 모형\n이제 학생들의 어휘능력 성적 gevocab를 설명 변수(\\(x_{ij1}\\))로 포함하는 모형을 고려해 보자. 첫 번째 계층의 구성원인 학생들에 대한 성적이므로 계층 1 설명변수(level 1 covariate)라고 부른다. 일단 어휘능력 성적은 고정 효과로서 모집단 전체에 대한 회귀 계수를 나타낸다.\n\\[\ny_{ij} = (\\beta_0 + b_{0i}) + \\beta_1 x_{ij1} + e_{ij}\n\\tag{14.2}\\]\n\nmodel11 &lt;- lmer(geread~gevocab +(1|school), data=Achieve)\nsummary(model11)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43137.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0823 -0.5735 -0.2103  0.3207  4.4334 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.09978  0.3159  \n Residual             3.76647  1.9407  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept) 2.023e+00  4.931e-02 7.582e+02   41.03   &lt;2e-16 ***\ngevocab     5.129e-01  8.373e-03 9.801e+03   61.26   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\ngevocab -0.758\n\n\n앞에서 적합한 평균모형의 추정값과 다음과 같이 비교하여 나타낼 수 있다.\n\ntab_model(model1, model11)\n\n\n\n \ngeread\ngeread\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n4.31\n4.20 – 4.41\n&lt;0.001\n2.02\n1.93 – 2.12\n&lt;0.001\n\n\ngevocab\n\n\n\n0.51\n0.50 – 0.53\n&lt;0.001\n\n\nRandom Effects\n\n\n\nσ2\n5.05\n3.77\n\n\n\nτ00\n0.39 school\n0.10 school\n\n\nICC\n0.07\n0.03\n\n\nN\n160 school\n160 school\n\nObservations\n10320\n10320\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.072\n0.276 / 0.295\n\n\n\n\n\n\n학생들의 어휘능력 성적은 읽기 성취도를 예측하는데 유의한 변수임이 t-검정로 나타난다(t-통계량 = 61.26). 또한 다음의 추정식과 같이 어휘능력 성적이 1점 증가하면 평균적으로 읽기 성취도은 0.5점 증가한다.\n\\[ \\hat {\\sigma}^2_{b0} = 0.0997786 , \\quad\n\\hat {\\sigma}^2_{e} = 3.7664703 \\]\n따라서 위의 모형에 따른 그룹내 상관계수(ICC)의 값을 구해보면 다음과 같다.\n\ns0 &lt;- (as.data.frame(VarCorr(model11))[\"vcov\"][1,1])\nse &lt;- (as.data.frame(VarCorr(model11))[\"vcov\"][2,1])\nicc &lt;- s0/(s0+se)\nicc\n\n[1] 0.02580759\n\n\n\\[ \\text{ICC } = \\frac{\\hat {\\sigma}^2_{b0} }{\\hat {\\sigma}^2_{b0} + \\hat {\\sigma}^2_{e}  }\n= 0.0258076 \\]",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#주변-결정계수와-조건부-결정계수",
    "href": "notes/lme_practice_2.html#주변-결정계수와-조건부-결정계수",
    "title": "14  반복측정자료 실습 2",
    "section": "14.6 주변 결정계수와 조건부 결정계수",
    "text": "14.6 주변 결정계수와 조건부 결정계수\n위의 모형 식 14.2 을 적합한 결과에서 Marginal R2 / Conditional R2 는 혼합모형에서 두 가지 종류의 결정계수 \\(R^2\\), 즉 주변 결정계수(marginal \\(R^2\\))와 조건부 결정계수(conditional \\(R^2\\)) 을 제시하고 있다.\n혼합모형에서 사용할 수 있는 두 개의 서로 다른 결정 계수에 대하여 알아보자.\n자세한 내용은 Nakagawa 와/과 Schielzeth (2013) 와 Nakagawa, Johnson, 와/과 Schielzeth (2017) 에 자세하게 설명되어 있다.\n먼저 다음과 같은 선형혼합모형이 있다고 가정하자.\n\\[\ny_{ij} = \\beta_0 + \\sum_{k=1}^p \\beta_k x_{kij} + b_i + e_{ij}, \\quad b_i \\sim N(0, \\sigma_b^2), ~e_{ij} \\sim N(0, \\sigma^2_e)\n\\tag{14.3}\\]\n일반적인 선형혼합모형 식 14.3 에서 주변 결정계수(marginal \\(R^2\\); \\(R^2_M\\)) 는 임의효과를 제외한 고정효과가 설명하는 변동이 전체 변동에서 차지하는 비율을 말한다. 주변 결정계수는 이반적인 선형모형에서 사용하는 결정계수의 의미를 혼합모형에 그대로 확장한 측도이다.\n\\[\nR^2_M = \\frac{\\sigma^2_f}{\\sigma^2_f + \\sigma^2_b + \\sigma^2_e}\n\\tag{14.4}\\]\n위에서 고정효과의 변동 \\(\\sigma^2_f\\)는 다음과 같이 정의된다. 아래 식에서 \\(Var\\)은 표본 분산을 의미한다.\n\\[ \\sigma^2_f = Var(\\sum_{k=1}^p \\hat \\beta_k x_{kij}) \\]\n반면 조건부 결정계수(conditional \\(R^2\\), \\(R^2_C\\))는 전체 변동을 설명하는 요인으로 고정효과가 설명하는 변동뿐만 아니라 임의효과가 설명하는 변동도 포함한다. 즉 조건부 결정계수는 다음과 같이 정의된다.\n\\[\nR^2_C = \\frac{\\sigma^2_f + \\sigma^2_b}{\\sigma^2_f + \\sigma^2_b + \\sigma^2_e}\n\\tag{14.5}\\]\n이제 선형혼합모형 식 14.2 에서 고정효과의 변동 \\(\\sigma^2_f\\)을 어떻게 계산하는지 알아보자. 고정효과가 gevocab 이고 이 설명변수에 대한 계수에 대한 추정값은 다음과 같다.\n\\[ \\hat \\beta_1 = 0.5128977 \\]\n따라서 \\(\\sigma^2_f\\) 은 다음과 같이 계산할 수 있다.\n\nxx &lt;- fixef(model11)[2] * model.matrix(model11)[,2]\nsf &lt;- var(xx)\nsf\n\n[1] 1.474928\n\n\n이제 위에서 구한 변동으로 선형혼합모형 식 14.2 에 대한 주변 결정계수와 조건부 결정계수를 계산할 수 있다.\n\nR2M &lt;- (sf)/(sf+s0+se)\nR2M\n\n[1] 0.2761428\n\n\n\\[ R^2_M = \\frac{\\sigma^2_f}{\\sigma^2_f + \\sigma^2_b + \\sigma^2_e}\n= \\frac{1.4749277}{1.4749277 + 0.0997786 + 3.7664703} = 0.2761428 \\]\n\nR2C &lt;- (sf + s0)/(sf+s0+se)\nR2C\n\n[1] 0.2948239\n\n\n\\[ R^2_C = \\frac{\\sigma^2_f + \\sigma^2_b}{\\sigma^2_f + \\sigma^2_b + \\sigma^2_e}\n= \\frac{1.4749277 + 0.0997786}{1.4749277 + 0.0997786 + 3.7664703} = 0.2948239 \\]\n주변 결정계수와 조건부 결정계수는 performance 라이브러리의 함수 model_performance를 이용하여 구할 수 있다.\n\nmodel_performance(model11)\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma\n-----------------------------------------------------------------------------------\n43145.200 | 43145.204 | 43174.168 |      0.295 |      0.276 | 0.026 | 1.932 | 1.941",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#층별-결정계수",
    "href": "notes/lme_practice_2.html#층별-결정계수",
    "title": "14  반복측정자료 실습 2",
    "section": "14.7 층별 결정계수",
    "text": "14.7 층별 결정계수\n계층모형의 특성을 고려하면 각 층에 대한 결정계수를 각각 다르게 정의할 수 있다. 교과서 Finch, Bolin, 와/과 Kelley (2019) 의 46 페이지에 설명과 계산이 나타나 있다.\n각 층에 대한 결정계수는 주어진 층에서 가장 단순한 평균모형을 적합하는 경우 나타나는 총 변동에서 설명변수를 포함한 모형을 적합한 후에 줄어든 변동의 비율을 나타낸다.\n먼저 계층 1에 대한 결정계수 \\(R^2_1\\) 은 다음과 같이 정의할 수 있다.\n\\[\n\\begin{aligned}\nR^2_1 & = 1 - \\frac{Var(y_{ij} - \\hat y_{ij})}{Var(y_{ij})} \\\\\n& = 1 -\\frac{\\sigma^2_b + \\sigma^2_e }{\\sigma^2_{b0} + \\sigma^2_{e0}}\n\\end{aligned}\n\\tag{14.6}\\]\n위의 식 식 14.6 에서 \\(\\sigma^2_{b0}\\) 과 \\(\\sigma^2_{e0}\\) 은 고정효과가 없는 평균모형 식 14.1 를 적합한 후에 구한 분산 성분의 추정량이다.\n식 14.6 에서 \\(\\sigma^2_{b}\\) 과 \\(\\sigma^2_{e}\\) 는 고정효과가 주어진 모형식 식 14.3 를 적합하고 얻은 분산 성분의 추정량이다.\n또한 식 식 14.6 에서 \\(\\hat y_{ij}\\)는 추정된 고정효과를 의미한다.\n\\[ \\hat y_{ij} = \\hat \\beta_0 +\\sum_{k=1}^p  \\hat \\beta_k x_{kij} \\]\n이제 계층 2에 대한 결정계수 \\(R^2_2\\) 은 다음과 같이 정의할 수 있다.\n\\[\n\\begin{aligned}\nR^2_2 & = 1 - \\frac{Var( \\bar y_{i} - \\hat {\\bar y_{i}})}{Var(\\bar y_{i})}  \\\\\n& = 1 -\\frac{\\sigma^2_b/ B + \\sigma^2_e }{\\sigma^2_{b0} / B + \\sigma^2_{e0}}\n\\end{aligned}\n\\tag{14.7}\\]\n위의 식 식 14.6 에서 \\(B\\) 는 계층 2의 평균 크기를 나타낸다. 학교 자료의 예제에서는 학교의 평균 학생 수를 의미하므로 다음과 같이 구할 수 있다.\n\\[  B = 10320/160 = 64.5\\]",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#계층-2-설명변수가-있는-모형",
    "href": "notes/lme_practice_2.html#계층-2-설명변수가-있는-모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.8 계층 2 설명변수가 있는 모형",
    "text": "14.8 계층 2 설명변수가 있는 모형\n이제 학교의 규모를 나타내는 등록 학생의 수 senroll를 설명 변수(\\(x_{i2}\\))로 포함하는 모형을 고려해 보자. 두 번째 계층의 구성원인 학교들에 대한 정보이므로 계층 2 설명변수(level 2 covariate)라고 부른다. 일단 등록 학생의 수은 고정 효과로서 모집단 전체에 대한 회귀 계수를 나타낸다.\n\\[\ny_{ij} = (\\beta_0 + b_{0i}) + \\beta_1 x_{ij1} + \\beta_2 x_{i2} + e_{ij}\n\\tag{14.8}\\]\n\nmodel12 &lt;- lmer(geread~gevocab +senroll +(1|school), data=Achieve)\nsummary(model12)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + senroll + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43152.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0834 -0.5729 -0.2103  0.3212  4.4336 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.1003   0.3168  \n Residual             3.7665   1.9408  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)  2.075e+00  1.140e-01  2.373e+02   18.20   &lt;2e-16 ***\ngevocab      5.129e-01  8.373e-03  9.798e+03   61.25   &lt;2e-16 ***\nsenroll     -1.026e-04  2.051e-04  1.652e+02   -0.50    0.618    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr) gevocb\ngevocab -0.327       \nsenroll -0.901 -0.002\n\n\n학교의 규모는 읽기 성취도를 예측하는데 유의하지 않다(t-통계량의 p-값 =0.618). 다른 변수에 대한 추정값은 거의 변하지 않았다.\n앞에서 적합한 평균모형의 추정값과 다음과 같이 비교하여 나타낼 수 있다.\n\ntab_model(model1, model11, model12)\n\n\n\n \ngeread\ngeread\ngeread\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n4.31\n4.20 – 4.41\n&lt;0.001\n2.02\n1.93 – 2.12\n&lt;0.001\n2.07\n1.85 – 2.30\n&lt;0.001\n\n\ngevocab\n\n\n\n0.51\n0.50 – 0.53\n&lt;0.001\n0.51\n0.50 – 0.53\n&lt;0.001\n\n\nsenroll\n\n\n\n\n\n\n-0.00\n-0.00 – 0.00\n0.617\n\n\nRandom Effects\n\n\n\nσ2\n5.05\n3.77\n3.77\n\n\n\nτ00\n0.39 school\n0.10 school\n0.10 school\n\n\nICC\n0.07\n0.03\n0.03\n\n\nN\n160 school\n160 school\n160 school\n\nObservations\n10320\n10320\n10320\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.072\n0.276 / 0.295\n0.276 / 0.295",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#계층-간의-상호작용",
    "href": "notes/lme_practice_2.html#계층-간의-상호작용",
    "title": "14  반복측정자료 실습 2",
    "section": "14.9 계층 간의 상호작용",
    "text": "14.9 계층 간의 상호작용\n계층 모형에서는 서로 다른 계층의 설명 변수이 상호 작용을 가지는 경우가 매우 중요한 이슈이다. 또한 같은 계층 안에 속하는 변수들의 상호 작용도 중요하다.\n이제 다음과 같은 두 모형을 고려한다.\n\n계층 내 상호작용이 있는 모형: 학생의 어휘성적과 연령\n계층 간 상호작용이 있는 모형: 학생의 어휘성적과 학교의 규모\n\n\nsummary(Achieve$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   82.0   104.0   107.0   107.5   111.0   135.0 \n\n\n\n14.9.1 계층 내 상호작용\n\nmodel21 &lt;- lmer(geread~gevocab + age + gevocab*age + (1|school), data=Achieve)\nsummary(model21)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + age + gevocab * age + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43143.5\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.0635 -0.5706 -0.2108  0.3191  4.4467 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.09875  0.3143  \n Residual             3.76247  1.9397  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)  5.187e+00  8.668e-01  1.031e+04   5.984 2.24e-09 ***\ngevocab     -2.808e-02  1.881e-01  1.030e+04  -0.149 0.881373    \nage         -2.937e-02  8.035e-03  1.031e+04  -3.655 0.000258 ***\ngevocab:age  5.027e-03  1.750e-03  1.030e+04   2.873 0.004072 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gevocb age   \ngevocab     -0.879              \nage         -0.998  0.879       \ngevocab:age  0.877 -0.999 -0.879\n\n\n학생의 연령과 어휘 능력과의 상호작용은 읽기 성취도를 예측하는데 유의하다. 다른 변수에 대한 추정값은 거의 변하지 않았다. 반면 어휘 능력의 유의성은 사라졌다. 이러한 결과는 연령에 따라서 어휘 능력의 기여도가 달라진다는 것을 의미하며 연령이 증가하면 어휘능력의 효과가 커진다.\n\nmodel_performance(model21)\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma\n-----------------------------------------------------------------------------------\n43155.494 | 43155.503 | 43198.946 |      0.296 |      0.277 | 0.026 | 1.930 | 1.940\n\n\n학생의 연령과 어휘 능력과의 상호작용은 다은과 같이 그림으로 나타낼 수 있다.\n\nsjPlot::plot_model  (model21, type='int')\n\n\n\n\n\n\n\n\n\n\n14.9.2 계층 간 상호작용\n\nmodel22 &lt;- lmer(geread~gevocab + senroll + gevocab*senroll + (1|school), data=Achieve)\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nsummary(model22)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + senroll + gevocab * senroll + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43163.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1228 -0.5697 -0.2090  0.3188  4.4359 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.1002   0.3165  \n Residual             3.7646   1.9403  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n                  Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)      1.748e+00  1.727e-01  1.058e+03  10.118   &lt;2e-16 ***\ngevocab          5.851e-01  2.986e-02  9.766e+03  19.592   &lt;2e-16 ***\nsenroll          5.121e-04  3.186e-04  8.402e+02   1.607   0.1084    \ngevocab:senroll -1.356e-04  5.379e-05  9.849e+03  -2.520   0.0118 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gevocb senrll\ngevocab     -0.782              \nsenroll     -0.958  0.735       \ngevcb:snrll  0.752 -0.960 -0.766\nfit warnings:\nSome predictor variables are on very different scales: consider rescaling\n\n\n\nmodel_performance(model22)\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma\n-----------------------------------------------------------------------------------\n43175.571 | 43175.579 | 43219.022 |      0.295 |      0.276 | 0.026 | 1.931 | 1.940\n\n\n학교의 규모와 어휘 능력과의 상호작용은 읽기 성취도를 예측하는데 유의하다. 또한 어휘 능력도 유의하다. 이러한 결과는 학교의 규모에 따라서 어휘 능력의 기여도가 달라진다는 것을 의미하며 학교의 규모가 커지면 어휘능력의 효과가 감소한다(buffering or inhibitory effect).\n\nsjPlot::plot_model  (model22, type = \"int\")",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#임의계수-모형",
    "href": "notes/lme_practice_2.html#임의계수-모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.10 임의계수 모형",
    "text": "14.10 임의계수 모형\n이제 어휘능력에도 학교에 대한 임의효과가 들어가는 임의계수 모형을 고려해 보자.\n\\[\ny_{ij} = (\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i})  x_{ij1} + e_{ij}\n\\tag{14.9}\\]\n\nmodel3 &lt;- lmer(geread~gevocab +  (1+gevocab |school), data=Achieve)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0191462 (tol = 0.002, component 1)\n\nsummary(model3)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + (1 + gevocab | school)\n   Data: Achieve\n\nREML criterion at convergence: 42992.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7096 -0.5674 -0.2079  0.3177  4.6765 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n school   (Intercept) 0.28050  0.5296        \n          gevocab     0.01922  0.1386   -0.86\n Residual             3.66613  1.9147        \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   2.00575    0.06097 154.62243   32.90   &lt;2e-16 ***\ngevocab       0.52032    0.01440 145.40535   36.15   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\ngevocab -0.866\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.0191462 (tol = 0.002, component 1)\n\n\n위의 적합된 결과를 보면 어휘능력은 유의한 설명변수이다. 이제 학생들의 읽기 성취도에 대한 총변동의 분해를 보면 다음과 같다.\n\\[ Var(y_{ij}) = \\hat{\\sigma}_{b0}^2 + \\hat{\\sigma}_{b1}^2 + \\hat{\\sigma}_e^2 = 0.28 + 0.02 + 3.67 \\]\n학교의 변동을 설명하는임의효과에 대한 분산성분 \\(\\sigma_{b0}^2\\) 과 \\(\\sigma_{b1}^2\\)의 추정치는 각각 0.28과 0.02 로서 학생 개인들의 변동에 대한 분산 \\(\\sigma_e^2\\)의 추정치 3.67에 비하여 매우 작다. 따라서 학생들의 읽기 성취도는 학교 요인보다 학생들의 개인 요인이 더 크게 기여한다.\n참고로 모형 식 14.9 를 lmer 로 적합할 때 계산에 대한 경고가 나타났다. 이와 같은 계산에 대한 경고는 계층모형에서 매우 흔하게 나타난다. 모형이 너무 복잡하여 계산에 문제가 있거나 계산에서 사용되는 여러 가지 조건이 충분하지 않아서 발생한다. 이러한 경고가 나오면 추정 결과를 면밀하게 검토하고 다른 모형들에 대한 고려도 해야 한다.\n이제 두 임의효과, 즉 절변에 대한 \\(b_{0i}\\) 와 기울기에 대한 \\(b_{1i}\\) 가 독립인 혼합모형을 적합헤 보자. 이렇게 임의효과들이 독립인 경우 아래와 같이 임의효과 모델에 두 개의 바(||) 를 사용한다.\n\nmodel31 &lt;- lmer(geread~gevocab +  (1+gevocab || school), data=Achieve)\nsummary(model31)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + (1 + gevocab || school)\n   Data: Achieve\n\nREML criterion at convergence: 43045.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3662 -0.5719 -0.2095  0.3280  4.4650 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.03646  0.19096 \n school.1 gevocab     0.00571  0.07556 \n Residual             3.70688  1.92533 \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)   2.03042    0.04543 490.48961   44.70   &lt;2e-16 ***\ngevocab       0.50979    0.01069 441.29210   47.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\ngevocab -0.688\n\n\n두 임의효과가 독립이 아닌 경우 나타난 경고는 나오지 않는다. 또한 고정효과에 대한 결과는 변하지 않았으나 분산성분의 추정은 다소 변화가 있다.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#가장-복잡한-모형",
    "href": "notes/lme_practice_2.html#가장-복잡한-모형",
    "title": "14  반복측정자료 실습 2",
    "section": "14.11 가장 복잡한 모형",
    "text": "14.11 가장 복잡한 모형\n이제 위의 결과를 이용하여 연령과 학교규모를 고정효과로 보고 상호작용도 추가함 모형을 살펴보자. 임의효과는 학교에 대한 항만 고려한다.\n\nmodel4 &lt;- lmer(geread~gevocab + age + senroll + gevocab*senroll  + gevocab*age +  (1| school), data=Achieve)\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nsummary(model4)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ gevocab + age + senroll + gevocab * senroll + gevocab *  \n    age + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43169.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1294 -0.5687 -0.2121  0.3174  4.4477 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.0991   0.3148  \n Residual             3.7606   1.9392  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n                  Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)      4.918e+00  8.816e-01  1.024e+04   5.578 2.49e-08 ***\ngevocab          4.164e-02  1.901e-01  1.031e+04   0.219 0.826611    \nage             -2.944e-02  8.033e-03  1.031e+04  -3.665 0.000249 ***\nsenroll          5.150e-04  3.181e-04  8.412e+02   1.619 0.105762    \ngevocab:senroll -1.361e-04  5.376e-05  9.840e+03  -2.532 0.011362 *  \ngevocab:age      5.053e-03  1.749e-03  1.029e+04   2.889 0.003876 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gevocb age    senrll gvcb:s\ngevocab     -0.875                            \nage         -0.981  0.869                     \nsenroll     -0.184  0.110 -0.004              \ngevcb:snrll  0.143 -0.145  0.004 -0.766       \ngevocab:age  0.861 -0.988 -0.879  0.005 -0.006\nfit warnings:\nSome predictor variables are on very different scales: consider rescaling",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/lme_practice_2.html#설명변수의-중심화",
    "href": "notes/lme_practice_2.html#설명변수의-중심화",
    "title": "14  반복측정자료 실습 2",
    "section": "14.12 설명변수의 중심화",
    "text": "14.12 설명변수의 중심화\n계층모형에서는 설명 변수를 중심화하는 것(centering, 변수의 평균이 0)이 모형의 결과를 해석하는데 편리하다. 이유는 변수들의 효과가 전체 평균을 기준으로 높거나 낮은 경향으로 나타나므로 해석이 용이하다.\n이제 계층 1 의 설명변수들인 연령과 어휘능력을 중심화하여 다시 가장 복잡한 모형을 적합해보자.\n\nAchieve$Cgevocab &lt;- Achieve$gevocab - mean(Achieve$gevocab)\nAchieve$Cage &lt;- Achieve$age - mean(Achieve$age)\nmodel5 &lt;- lmer(geread~Cgevocab + Cage + senroll + Cgevocab*senroll  + Cgevocab*Cage +  (1| school), data=Achieve)\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\nsummary(model5)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: geread ~ Cgevocab + Cage + senroll + Cgevocab * senroll + Cgevocab *  \n    Cage + (1 | school)\n   Data: Achieve\n\nREML criterion at convergence: 43169.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1294 -0.5687 -0.2121  0.3174  4.4477 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept) 0.0991   0.3148  \n Residual             3.7606   1.9392  \nNumber of obs: 10320, groups:  school, 160\n\nFixed effects:\n                   Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)       4.381e+00  1.074e-01  1.927e+02  40.807  &lt; 2e-16 ***\nCgevocab          5.850e-01  2.985e-02  9.762e+03  19.597  &lt; 2e-16 ***\nCage             -6.733e-03  3.916e-03  1.031e+04  -1.719  0.08561 .  \nsenroll          -9.663e-05  2.043e-04  1.653e+02  -0.473  0.63682    \nCgevocab:senroll -1.361e-04  5.376e-05  9.840e+03  -2.532  0.01136 *  \nCgevocab:Cage     5.053e-03  1.749e-03  1.029e+04   2.889  0.00388 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Cgevcb Cage   senrll Cgvcb:\nCgevocab    -0.008                            \nCage         0.002  0.019                     \nsenroll     -0.954  0.010  0.000              \nCgvcb:snrll  0.009 -0.960 -0.004 -0.011       \nCgevocab:Cg  0.012  0.012  0.205  0.001 -0.006\nfit warnings:\nSome predictor variables are on very different scales: consider rescaling\n\n\n\n\n\n\nFinch, W Holmes, Jocelyn E Bolin, 와/과 Ken Kelley. 2019. Multilevel modeling using R. Crc Press.\n\n\nNakagawa, Shinichi, Paul C. D. Johnson, 와/과 Holger Schielzeth. 2017. “The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded”. Journal of The Royal Society Interface 14 (134): 20170213. https://doi.org/10.1098/rsif.2017.0213.\n\n\nNakagawa, Shinichi, 와/과 Holger Schielzeth. 2013. “A general and simple method for obtaining R2 from generalized linear mixed‐effects models”. Methods in Ecology and Evolution 4 (2): 133–42. https://doi.org/10.1111/j.2041-210x.2012.00261.x.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>반복측정자료 실습 2</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#필요한-패키지와-함수",
    "href": "notes/random_effect_sim.html#필요한-패키지와-함수",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.1 필요한 패키지와 함수",
    "text": "15.1 필요한 패키지와 함수\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(faraway)\nlibrary(alr4)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(brms)\n# ggplot2 에서 한글의 사용\nlibrary(showtext)\nfont_add_google(\"Nanum Pen Script\", \"nanum\")\nshowtext_auto()",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#모의실험의-유용성",
    "href": "notes/random_effect_sim.html#모의실험의-유용성",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.2 모의실험의 유용성",
    "text": "15.2 모의실험의 유용성\n통계적 모형은 데이터를 분석하여 관심있는 모수에 대한 정보를 얻고 중요한 가설을 검정하는데 사용된다. 이러한 분석 과정에서 다양한 통계적 추론 방법(점추정, 구간추정,통계적 가설검정)이 사용된다.\n통계학에서 분석을 위한 새로운 추정 방법이 제안되면 방법의 통계적 특성을 파악하기 위하여 추정량의 이론적 특성과 경험적 특성을 동시에 제시한다. 예를 들어 새로운 통계적 가설 검정법이 제안되면 정확한 또는 점근적 검정력(exact or asymptotic power) 또는 size 등 이론적인 성질(theoritical propooerties)을 통하여 방법의 유효성을 보여준다. 이러한 이론적인 성질이 실제로 표본의 개수가 작거나 모형에 대한 가정의 위배되는 상황이 벌어질 때 자 적절하게 유지되는지 알아보기 위하여 모의실험(simulation)을 통한 경험적 성질(empirical pproperties)도 제시된다.\n모의실험 방법은 통계적 방법의 다양한 특성을 경험적으로 파악할 수 있는 도구일뿐만 아니라 복잡한 모형의 구조를 쉽게 이해할 수 있는 도구이기도 한다. 즉, 모형은 데이터가 생성되는 확률적 과정(data generating process)으로 볼 수 있기 때문에 모형을 이용한 모의실험은 자료의 구조적 특성과 확률적 특성을 이해할 수 있는 중요한 도구이다.",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#단순회귀-모형의-자료-생성",
    "href": "notes/random_effect_sim.html#단순회귀-모형의-자료-생성",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.3 단순회귀 모형의 자료 생성",
    "text": "15.3 단순회귀 모형의 자료 생성\n이제 단순한 선형회귀모형에 대한 모의 실험에 대하여 알아보자.\n일단 앞 절에서 사용한 sleepstudy 모형 식 7.10 와 유사한 단순회귀직선에 대한 모의실험을 고혀하자.\n아래 모형은 반응시간 \\(y\\)의 평균이 시간 \\(t\\)의 선형함수로 나타나는 형태이다.\n\\[ E(y|t) = \\beta_0 + \\beta_1 t\\] 위의 식만으로는 모의실험을 위한 데이터를 만들 수 없다.\n\n15.3.1 자료 생성 모형\n모의실험은 가정한 통계적 모형에서 데이터를 만들수 있는 자세한 데이터의 생성과정에 대한 모형이 필요하다.\n이제 시간 \\(t\\) 에서 반응시간 \\(y\\) 가 어떻게 생성되는지 아래와 같은구체적인 모형을 고려하자. 아래 모형은 \\(n\\) 개의 관측값이 모두 독립인 단순회귀직선 모형이다.\n\\[ y_i = \\beta_0 +\\beta_1 x_i + e_i, \\quad e_i \\sim_{iid} N(0, \\sigma^2) \\quad \\text{ for } i=1,2,\\dots,n  \\tag{15.1}\\] 위의 식에서 자료를 생성하려면 한 가지 정보가 더 필요하다. 설명변수 \\(x\\) 가 어떤 범위를 가지는지 혹은 어떤 분포를 가지는지에 대한 정보가 있어야 \\(n\\) 개의 \\((x_i,y_i)\\) 데이터를 생성할 수 있다. 보통 설명변수는 다음과 같은 두 형태로 나타난다.\n\n설명변수가 실험 계획에 의해 값들이 고정된 경우(주어진 시간, 온도, 무게 등 )\n설명변수가 확률적 분포를 가진다고 가능할 수 있는 경우(키, 몸무게 등)\n\n\n\n15.3.2 자료의 구조\n먼저 자료의 구조에 대한 정보를 알아보자.\n\n## 독립변수 측정 시간 \nx &lt;- unique(sleepstudy$Days)\nxp &lt;- length(x)\n\n# 자료의 구조 정보 \nsubj &lt;- unique(sleepstudy$Subject)\nnp &lt;- length(subj)\n\n# 독립변수\nDays &lt;- rep(x,np)\nSubject &lt;-rep(subj, each=xp)\n\n\n\n15.3.3 모수의 결정\n자료 생성의 다음단계는 가정된 모형에 관련된 모수의 값을 설정하고 최종적으로 정해야 한다.\n앞 장에서 고려한 sleepstudy 자료에서 나타난 모수를 이용하여 모형 식 15.1 에서 모수에 대한 정보를 얻으려고 한다.\n\nmfsim1 &lt;- lm(Reaction ~ 1 + Days , sleepstudy)\nsummary(mfsim1)\n\n\nCall:\nlm(formula = Reaction ~ 1 + Days, data = sleepstudy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-110.848  -27.483    1.546   26.142  139.953 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.610  38.033  &lt; 2e-16 ***\nDays          10.467      1.238   8.454 9.89e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47.71 on 178 degrees of freedom\nMultiple R-squared:  0.2865,    Adjusted R-squared:  0.2825 \nF-statistic: 71.46 on 1 and 178 DF,  p-value: 9.894e-15\n\n\n위의 분석 결과에서 원자료를 모형 식 15.1 을 적합한 결과로 부터 모수의 값을얻는다.\n\n# 모수 \n## 회귀계수\nbeta0 &lt;- mfsim1$coefficients[1]\nbeta1 &lt;- mfsim1$coefficients[2]\n\n## 오차항의 표준편차\ns &lt;- sigma(mfsim1)\nn &lt;- dim(sleepstudy)[1]\n\n\n\n15.3.4 자료 생성\n이제 원자료로 부터 얻은 정보를 이용하여 데이터를 만들어 보자\n\nset.seed(1234321)\n\nerror &lt;- rnorm(n,0,s)\n\nReaction&lt;- beta0 + beta1*Days + error\nsleepstudy_syn &lt;- data.frame(Reaction, Days, Subject)\n\nhead(sleepstudy_syn)\n\n  Reaction Days Subject\n1 310.4238    0     308\n2 336.3848    1     308\n3 360.1166    2     308\n4 297.9480    3     308\n5 344.4011    4     308\n6 249.0607    5     308\n\n\n위에서 만든 새로운 자료는 sleepstudy 자료와 동일한 구조를 가지지만 모든 레코드가 독립적으로 생성된 점이 원자료와 구별되는 큰 차이이다.\n\nmfsim1_1 &lt;- lm(Reaction ~ 1 + Days , sleepstudy_syn)\nsummary(mfsim1_1)\n\n\nCall:\nlm(formula = Reaction ~ 1 + Days, data = sleepstudy_syn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-107.927  -33.498    0.485   34.338  114.637 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  246.670      6.280   39.28   &lt;2e-16 ***\nDays          12.357      1.176   10.51   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 45.33 on 178 degrees of freedom\nMultiple R-squared:  0.3827,    Adjusted R-squared:  0.3792 \nF-statistic: 110.3 on 1 and 178 DF,  p-value: &lt; 2.2e-16\n\n\n\nggplot(sleepstudy_syn, aes(x=Days, y=Reaction)) + geom_point(size=0.7)\n\n\n\n\n\n\n\n\n\nggplot(sleepstudy_syn, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.5) + \n  stat_smooth(method = \"lm\",se=F,linewidth=0.5)+ \n  facet_wrap(\"Subject\", labeller = label_both)+ \n  theme_bw() \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n위의 그림에서 알수 있듯이 모든 관측치가 독립이고 개인차에 대한 임의효과를 고려하지 않은 모형이기 떄문에 생성된 자료에서 개체별(Subject)로 절편과 기울기가 유사하다.\n만약 위와 같이 독립적으로 자료에 선형혼합모형을 적합시키면 어떤 결과가 나타날까?\n\nmfsim1_wrong &lt;- lmer(Reaction ~ 1 + Days + (1+Days|Subject) , sleepstudy_syn)\n\nboundary (singular) fit: see help('isSingular')\n\nsummary(mfsim1_wrong)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: sleepstudy_syn\n\nREML criterion at convergence: 1874\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.44838 -0.70648  0.00083  0.74218  2.43218 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n Subject  (Intercept)  212.5   14.577        \n          Days           1.4    1.183   -1.00\n Residual             1962.0   44.295        \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  246.670      7.033  22.941   35.07  &lt; 2e-16 ***\nDays          12.357      1.183  68.185   10.45 8.59e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.830\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#선형-혼합-모형의-자료-생성",
    "href": "notes/random_effect_sim.html#선형-혼합-모형의-자료-생성",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.4 선형 혼합 모형의 자료 생성",
    "text": "15.4 선형 혼합 모형의 자료 생성\n이제 다음과 같이 각 개체별로 절편과 기울기가 다른 선형혼합 모형에서 생성된 자료를 만들어 보자.\n\\[ y_{ij} = (\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i}) t_j + e_{ij},   \\quad \\text{ for } i=1,2,\\dots,I, ~~ j=1,2,\\dots,J \\]\n\\[\ne_{ij} \\sim_{iid} N(0, \\sigma^2),\n\\quad\n{\\pmb b}_i =\n\\begin{bmatrix}\nb_{0i} \\\\\nb_{1i} \\\\\n\\end{bmatrix} \\sim\nN \\left (\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n,\n\\begin{bmatrix}\n\\sigma^2_{b1} & \\rho \\sigma_{b1} \\sigma_{b2}\\\\\n\\rho \\sigma_{b1} \\sigma_{b2} & \\sigma^2_{b2} \\\\\n\\end{bmatrix}\n\\right ), \\quad \\text{ for } i=1,2,\\dots,I, ~~ j=1,2,\\dots,J\n\\tag{15.2}\\]\n\n15.4.1 자료의 구조\n먼저 자료의 구조는 원자료와 동일한 정보를 사용한다.\n\n## 독립변수 측정 시간 \nx &lt;- unique(sleepstudy$Days)\nxp &lt;- length(x)\n\n# 자료의 구조 정보 \nsubj &lt;- unique(sleepstudy$Subject)\nnp &lt;- length(subj)\n\n# 독립변수\nDays &lt;- rep(x,np)\nSubject &lt;-rep(subj, each=xp)\n\n\n\n15.4.2 모수의 결정\n임의효과를 생성하기 위해서는 각 분산성분에 대한 모수의 값이 필요하므로 원자료 sleepstudy 에서 추정된 분산성분의 값들을 이용하여 자료를 생성해 보자.\n\nfm1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy)\nsummary(fm1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  &lt; 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n\n\n이제 분산성분에 대한 정보를 얻기 위하여 VarCorr 함수를 이용하여 다음과 같이 분산성분에 대한 정보를 얻을 수 있다.\n\nvc_df &lt;- data.frame(VarCorr(fm1))\nvc_df\n\n       grp        var1 var2       vcov       sdcor\n1  Subject (Intercept) &lt;NA&gt; 612.100158 24.74065800\n2  Subject        Days &lt;NA&gt;  35.071714  5.92213766\n3  Subject (Intercept) Days   9.604409  0.06555124\n4 Residual        &lt;NA&gt; &lt;NA&gt; 654.940008 25.59179572\n\n\n위의 결과로 부터 다음과 같이 모수의 값을 얻을 수 있다. getME 함수는 lmer 모형의 결과로 부터 모수의 값을 얻기 위한 함수이다.\n\nbeta0 &lt;- getME(fm1, \"fixef\")['(Intercept)']\nbeta1 &lt;- getME(fm1, \"fixef\")['Days']\n\ns0 &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% dplyr::filter(var1 == '(Intercept)') %&gt;% dplyr::filter( is.na(var2)) %&gt;% dplyr::select(sdcor) %&gt;% as.numeric()\n\ns1 &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% dplyr::filter(var1 == 'Days') %&gt;% dplyr::filter( is.na(var2)) %&gt;% dplyr::select(sdcor) %&gt;% as.numeric()\n\nrho &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% dplyr::filter(var1 == '(Intercept)') %&gt;% dplyr::filter( var2 == 'Days') %&gt;% dplyr::select(sdcor) %&gt;% as.numeric()\n\ns_new &lt;- vc_df %&gt;% dplyr::filter(grp== 'Residual') %&gt;% dplyr::select(sdcor) %&gt;% as.numeric()\n                                                          \nc(beta0, beta1, s0,s1,rho,s_new)\n\n (Intercept)         Days                                                     \n251.40510485  10.46728596  24.74065800   5.92213766   0.06555124  25.59179572 \n\n\n\n\n15.4.3 자료의 생성\n이제 다변량 정규분포에서 임의효과를 생성하기 위하여 mvrnorm 함수를 이용하여 임의효과를 생성하는 함수를 만들어 보자.\n\nr_bi_norm &lt;- function(ns, mean_vector, std1, std2, rho) {\n  # Construct the covariance matrix\n  covariance_matrix &lt;- matrix(c(std1^2, rho*std1*std2, \n                                rho*std1*std2, std2^2), \n                              nrow = 2)\n  \n  # Generate one sample (n=1) of the bivariate distribution\n  random_vector &lt;- mvrnorm(n = ns, mu = mean_vector, Sigma = covariance_matrix)\n  return(random_vector)\n}\n\n이제 위의 함수 r_bi_norm 을 이용하여 임의효과를 생성해 보자.\n\nran_effs &lt;- r_bi_norm(np, mean_vector = c(0,0), std1 = s0, std2 = s1, rho = rho)\nran_effs\n\n            [,1]       [,2]\n [1,]  30.108338 -0.9355999\n [2,]  17.504742 -4.6341232\n [3,]  -1.330282  7.5845073\n [4,]   3.358948 16.1184479\n [5,]   4.231729 -0.4456519\n [6,]   3.289291  4.0881619\n [7,] -26.682068 -0.9959717\n [8,]  -8.854692  4.9162480\n [9,]  36.497594 -0.7459951\n[10,]  14.362823 -0.9640035\n[11,]  12.526351 -6.9512455\n[12,]  14.023122  2.2740462\n[13,] -53.009525 10.9097123\n[14,]  -8.929866 -1.6975231\n[15,]   1.884529 -1.9111229\n[16,]   4.931168 -3.1983164\n[17,]  55.498306  9.0992849\n[18,]   4.768608 -8.3479651\n\n\n이제 임의효과를 이용하여 자료를 생성해 보자. 각 개체별로 절편과 기울기가 다른 선형혼합 모형에서 생성된 자료를 만들어 보자.\n\nset.seed(32123)\nerror_new &lt;- rnorm(n,0,s_new)\n\nReaction &lt;- (beta0 + rep(ran_effs[,1],each=xp)) + (beta1 + rep(ran_effs[,2],each=xp)) * Days + error_new\nsleepstudy_syn2 &lt;- data.frame(Reaction, Days, Subject)\n\nhead(sleepstudy_syn2)\n\n  Reaction Days Subject\n1 270.3672    0     308\n2 292.2138    1     308\n3 273.1029    2     308\n4 326.6899    3     308\n5 303.9597    4     308\n6 359.8793    5     308\n\n\n이제 새로 생성한 자료를 이용하여 다음과 같이 선형혼합모형을 적합해 보자.\n\nfm1_1 &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy_syn2)\nsummary(fm1_1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: sleepstudy_syn2\n\nREML criterion at convergence: 1760.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.65295 -0.60321 -0.01403  0.59278  2.23300 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n Subject  (Intercept) 725.50   26.935        \n          Days         66.68    8.166   -0.37\n Residual             692.66   26.318        \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)  254.919      7.321  17.004  34.820  &lt; 2e-16 ***\nDays          11.548      2.042  17.001   5.654 2.86e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.441\n\n\n\nggplot(sleepstudy_syn2, aes(x=Days, y=Reaction)) + geom_point(size=0.7)\n\n\n\n\n\n\n\n\n\nggplot(sleepstudy_syn2, aes(x=Days, y=Reaction)) + \n  geom_point(size=0.5) + \n  stat_smooth(method = \"lm\",se=F,linewidth=0.5)+ \n  facet_wrap(\"Subject\", labeller = label_both)+ \n  theme_bw() \n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#함수를-이용한-자료의-생성",
    "href": "notes/random_effect_sim.html#함수를-이용한-자료의-생성",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.5 함수를 이용한 자료의 생성",
    "text": "15.5 함수를 이용한 자료의 생성\n이제 sleepstudy 와 유사한 구조를 가지는 자료를 생성하는 함수를 만들어 보자.\n\n## 자료의 생성 함수\n## num_subjec : 개체의 수\n## time_vec : 시간 벡터\n## beta0 : 선형 함수의 절편\n## beta1 : 선형 함수의 기울기\n## s0 : 절편 임의효과의 표준편차\n## s1 : 기울기 임의효과의 표준편차 \n## rho : 두 임의 효과의 상관계수 \n## s : 오차항의 표준편차\n\nmake_sim_data &lt;- function( num_subject, time_vec, beta0, beta1, s0, s1, rho, s, myseed= 123411) {\n  \n  # random number generation 초기값 \n  set.seed(myseed)\n  \n  # 자료의 구조 정보 \n  ## 시간의 길이\n  xp &lt;- length(time)\n  ## 개체의 ID\n  subj &lt;- as.character(1:num_subject)\n  Subject &lt;-rep(subj, each=xp)\n  ## 개체의 수\n  np &lt;- length(subj)\n  \n  # 독립변수\n  ## 시간\n  Days &lt;- rep(time,np)\n  \n    # 임의효과 생성\n  ran_effs &lt;- r_bi_norm(np, mean_vector = c(0,0), std1 = s0, std2 = s1, rho = rho)\n  \n  # 오차항 생성\n  error &lt;- rnorm(np*xp,0,s)\n  \n  # 반응변수 생성\n  Reaction &lt;- (beta0 + rep(ran_effs[,1],each=xp)) + (beta1 + rep(ran_effs[,2],each=xp)) * Days + error\n  \n  # 자료의 구조 생성\n  sleepstudy_syn &lt;- data.frame(Reaction, Days, Subject)\n  \n  return(sleepstudy_syn)\n  \n}\n\n이제 자신이 정한 저료의 구조와 모수를 이용하여 자료를 생성해 보자.\n\nnum_subject &lt;- 10\ntime &lt;- 0:5\nbeta0 &lt;- 100\nbeta1 &lt;- 5\ns0 &lt;- 10\ns1 &lt;- 5\nrho &lt;- -0.4\ns &lt;- 10\n\nnew_data &lt;- make_sim_data(num_subject, time, beta0, beta1, s0, s1, rho, s)\nhead(new_data)\n\n  Reaction Days Subject\n1 104.6845    0       1\n2 127.8396    1       1\n3 105.4228    2       1\n4 110.5512    3       1\n5 115.4780    4       1\n6 114.6757    5       1\n\n\n이제 새로운 자료를 이용하여 선형혼합모형을 적합해 보자.\n\nfm1_new &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), new_data)\nsummary(fm1_new)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ 1 + Days + (1 + Days | Subject)\n   Data: new_data\n\nREML criterion at convergence: 472.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.60496 -0.28530  0.05965  0.51495  2.04955 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n Subject  (Intercept) 76.98    8.774         \n          Days        24.71    4.971    -0.27\n Residual             99.98    9.999         \nNumber of obs: 60, groups:  Subject, 10\n\nFixed effects:\n            Estimate Std. Error     df t value Pr(&gt;|t|)    \n(Intercept)   94.780      3.596  9.000  26.354 7.88e-10 ***\nDays           3.199      1.744  9.000   1.834   0.0998 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.413",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "notes/random_effect_sim.html#모의실험",
    "href": "notes/random_effect_sim.html#모의실험",
    "title": "15  반복측정자료의 모의실험",
    "section": "15.6 모의실험",
    "text": "15.6 모의실험\n이제 위에서 고려한 자료의 구조와 모수를 이용하여 모의실험을 해 보자.\n모의실험의 목적은 다양하게 있을 수 있다. 먼저 절편에 대한 임의효과의 분산성분이 어떻게 추정되는지 알아보자.\n모의실험의 횟수는 100으로 하자.\n아래 코드에서 모의실험의 각 단계에서 생성된 자료를 이용하여 선형혼합모형을 적합하고 그 결과를 sim_result 에 저장한다. 각 던계에서 random number 의 초기값을 다르게 하기 위하여 myseed 를 i 로 지정하였다.값을 지정하지 않으면 myseed 는 123411 로 고정되어 같은 자료가 반복된다.\n\nNsim &lt;- 100\nsim_result &lt;- 1:Nsim\n\n\nnum_subject &lt;- 10\ntime &lt;- 0:5\nbeta0 &lt;- 100\nbeta1 &lt;- 5\ns0 &lt;- 10\ns1 &lt;- 5\nrho &lt;- -0.4\ns &lt;- 10\n\nfor (i in 1:Nsim){\n  \n  new_data &lt;- make_sim_data(num_subject, time, beta0, beta1, s0, s1, rho, s, myseed= i)\n  \n  fm_sim &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), new_data)\n  \n  vc_df &lt;- as.data.frame(VarCorr(fm_sim))\n  \n  sim_result[i] &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% \n    dplyr::filter(var1 == '(Intercept)') %&gt;% \n    dplyr::filter( is.na(var2)) %&gt;% \n    dplyr::select(sdcor) %&gt;% \n    as.numeric()\n}\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nWarning: Model failed to converge with 1 negative eigenvalue: -7.3e-01\n\n\nboundary (singular) fit: see help('isSingular')\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0429527 (tol = 0.002, component 1)\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00336574 (tol = 0.002, component 1)\n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nWarning: Model failed to converge with 1 negative eigenvalue: -1.4e-02\n\nsim_result\n\n  [1]  4.5104272 10.7928386  1.2510866 11.2097911 15.8315602 11.0013372\n  [7] 16.8417848  6.9968852  0.0000000  8.6375532  7.2211732 12.3890737\n [13]  8.8479840  9.0583386 12.5977973 12.6849906  9.8448045 17.0851686\n [19]  4.8525604 10.3195860  9.2289773 11.2474301  5.6254630  0.7368366\n [25] 11.3850486 12.7842622  7.9874688 12.1613683 12.1041299  7.1669089\n [31] 15.4452869  7.3236654 10.9178291  4.1892993  9.9788300  8.9754129\n [37]  0.2453693  5.2784006  9.3666501 12.0666036  9.6182587  8.1041298\n [43]  5.8444702 10.5233360 13.3228895  3.4941746 15.8464350 14.7126852\n [49]  9.8815540 11.5058712 11.7672784 11.9355399  9.9171284 13.2954695\n [55] 10.1767173  2.5387015 14.7584548  8.9042018 13.9218244 14.2231910\n [61] 10.2541862 13.0167785 14.6410595 13.0064790  6.9646687  5.9965459\n [67]  7.1727323  3.0830984  8.1308466  9.6908465  7.8681998  2.0979475\n [73] 14.0085168 15.6220555 12.3882945  9.0397649  5.3211165  9.7760203\n [79] 13.4566586  3.7874034  4.1688551 13.6758526 15.4283062  8.1636770\n [85]  8.2791360  5.5697856  9.4299839 12.7644355 14.4888236  6.6387578\n [91] 17.1341837 12.8631983  7.6903545 10.2534477 12.2308844  9.6491583\n [97]  8.3055860  0.8810941  4.7477393  3.0036543\n\n\n결과를 보면 많은 경고가 나타나는 것을 알 수 있다. 이 경고는 최대가능도 추정법을 이용하여 모수를 추정할 때 최적화 과정에서 발생하는 문제이다.\n이제 절편에 대한 임의효과의 분산성분의 추정값의 분포를 살펴보자. 절편에 대한 임의효과의 표준편차는 10으로 설정하였는데 100번의 추정에서 100개의 추정값의 평균값이 실제 모수의 값 10에 가깝게 나타나는 것을 알 수 있다.\n결과에서 주의할 점은 절편에 대한 임의효과의 표준편차에 대한 추정값이 0으로 나타나는 경우가 있다는 것이다.\n\nsummary(sim_result)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   7.124   9.810   9.512  12.620  17.134 \n\n\n\nboxplot(sim_result)\n\n\n\n\n\n\n\n\n\n# density plot with ggplot2 with xlim (-10, 20)\nggplot(data.frame(sim_result), aes(x=sim_result)) + \n  geom_density(fill=\"blue\", alpha=0.2) + \n  xlim(-10, 20) + \n  ggtitle(\"Density plot of random effects standard deviation\") +\n  xlab(\"Random effects standard deviation\")\n\n\n\n\n\n\n\n\n다음으로 좀 더 추정하기 어려운 두 임의효과의 상관계수에 대한 모의실험을 해 보자. 앞에서 실행한 경과, 즉 절편 임의효과의 표분편차에 대한 추정량도 같이 구해보자.\n\nNsim &lt;- 100\nsim_result &lt;- data.frame(s0 = 1:Nsim, rho = 1:Nsim)\n\n\nnum_subject &lt;- 10\ntime &lt;- 0:5\nbeta0 &lt;- 100\nbeta1 &lt;- 5\ns0 &lt;- 10\ns1 &lt;- 5\nrho &lt;- -0.4\ns &lt;- 10\n\nfor (i in 1:Nsim){\n  \n  new_data &lt;- make_sim_data(num_subject, time, beta0, beta1, s0, s1, rho, s, myseed= i)\n  \n  fm_sim &lt;- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), new_data)\n  \n  vc_df &lt;- as.data.frame(VarCorr(fm_sim))\n  \n  sim_result[i,1] &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% \n    dplyr::filter(var1 == '(Intercept)') %&gt;% \n    dplyr::filter( is.na(var2)) %&gt;% \n    dplyr::select(sdcor) %&gt;% \n    as.numeric()\n  \n  sim_result[i,2] &lt;- vc_df %&gt;% dplyr::filter(grp== 'Subject') %&gt;% \n    dplyr::filter(var1 == '(Intercept)') %&gt;% \n    dplyr::filter(var2 == 'Days') %&gt;% \n    dplyr::select(sdcor) %&gt;% \n    as.numeric()\n}\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nWarning: Model failed to converge with 1 negative eigenvalue: -7.3e-01\n\n\nboundary (singular) fit: see help('isSingular')\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0429527 (tol = 0.002, component 1)\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00336574 (tol = 0.002, component 1)\n\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\n\nWarning: Model failed to converge with 1 negative eigenvalue: -1.4e-02\n\nhead(sim_result,10)\n\n          s0        rho\n1   4.510427 -0.5514223\n2  10.792839 -0.3881303\n3   1.251087  1.0000000\n4  11.209791 -0.9464929\n5  15.831560 -0.8350045\n6  11.001337 -0.4460145\n7  16.841785 -0.7299049\n8   6.996885 -0.2903759\n9   0.000000        NaN\n10  8.637553 -0.1362379\n\n\n\nsummary(sim_result$rho)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-1.0000 -0.6861 -0.4460 -0.3294 -0.1382  1.0000       1 \n\n\n\nboxplot(sim_result$rho)\n\n\n\n\n\n\n\n\n\n# density plot with ggplot2 with xlim (-1, 1)\nggplot(data.frame(sim_result), aes(x=sim_result$rho)) + \n  geom_density(fill=\"blue\", alpha=0.2) + \n  xlim(-1, 1) + \n  ggtitle(\"Density plot of correlation of two random effects\") +\n  xlab(\"correlation\")\n\nWarning: Use of `sim_result$rho` is discouraged.\nℹ Use `rho` instead.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).",
    "crumbs": [
      "실습",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>반복측정자료의 모의실험</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agresti, Alan. 2007. An Introduction to Categorical Data\nAnalysis. John Wiley & Sons, Ltd.\n\n\n———. 2012. Categorical Data Analysis. Vol. 792. John Wiley\n& Sons.\n\n\nButler-Laporte, Guillaume, Alexander Lawandi, Ian Schiller, Mandy Yao,\nNandini Dendukuri, Emily G McDonald, and Todd C Lee. 2021.\n“Comparison of Saliva and Nasopharyngeal Swab Nucleic Acid\nAmplification Testing for Detection of SARS-CoV-2: A Systematic Review\nand Meta-Analysis.” JAMA Intern Med 181 (3): 353–58.\n\n\nFaraway, Julian J. 2016. Extending the Linear Model with r:\nGeneralized Linear, Mixed Effects and Nonparametric Regression\nModels. CRC press.\n\n\nFinch, W Holmes, Jocelyn E Bolin, and Ken Kelley. 2019. Multilevel\nModeling Using r. Crc Press.\n\n\nJaewon Lee, Hanna Yu, Mira Park. 2005. 생명과학연구를 위한 통계적\n방법. 1st ed. 자유아카데미.\n\n\nNakagawa, Shinichi, Paul C. D. Johnson, and Holger Schielzeth. 2017.\n“The coefficient of determination R2 and\nintra-class correlation coefficient from generalized linear\nmixed-effects models revisited and expanded.” Journal\nof The Royal Society Interface 14 (134): 20170213. https://doi.org/10.1098/rsif.2017.0213.\n\n\nNakagawa, Shinichi, and Holger Schielzeth. 2013. “A general and simple method for obtaining R2 from\ngeneralized linear mixed‐effects models.” Methods in\nEcology and Evolution 4 (2): 133–42. https://doi.org/10.1111/j.2041-210x.2012.00261.x.\n\n\nWeisberg, Sanford. 2014. Applied Linear Regression. Fourth.\nHoboken NJ: Wiley. http://z.umn.edu/alr4ed.",
    "crumbs": [
      "References"
    ]
  }
]